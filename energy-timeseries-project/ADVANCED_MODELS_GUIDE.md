# ğŸš€ Advanced Models Guide - Erweiterte Modelle

**Datum**: 1. Februar 2026  
**Status**: âœ… Bereit fÃ¼r Experimente

---

## ğŸ“‹ Ãœbersicht

Dieses Dokument beschreibt die **erweiterten Modellierungs-AnsÃ¤tze** fÃ¼r die Energiezeitreihen-Prognose, die Ã¼ber die Basis-Modelle (RF, LSTM, XGBoost) hinausgehen.

---

## ğŸ¯ Neue Notebooks

### 1. ğŸ”¥ **Extended Deep Learning (Google Colab GPU)**
**File**: `scripts/LSTM_Optimization_Extended_Colab.ipynb`

**Modelle**:
- âœ… **GRU** - Gated Recurrent Unit (schneller als LSTM!)
- âœ… **Bi-LSTM** - Bidirectional LSTM
- âœ… **Autoencoder** - Dimensionsreduktion + Forecasting
- âœ… **VAE** - Variational Autoencoder (UnsicherheitsschÃ¤tzung)
- âœ… **N-BEATS** - Neural Basis Expansion (State-of-the-Art)
- âœ… **N-HiTS** - Hierarchical Interpolation
- âœ… **DeepAR** - Amazon's probabilistisches Modell
- âœ… **TFT** - Temporal Fusion Transformer (Google Research)
- âš ï¸ **TimeGAN** - Generative Adversarial Network (optional, experimentell)

**Rechenzeit (GPU T4)**:
- Schnell (<5 min): LSTM, GRU, Bi-LSTM, Autoencoder, VAE
- Mittel (5-15 min): N-BEATS, N-HiTS, DeepAR
- Langsam (15-45 min): TFT, TimeGAN

**Setup**:
```python
# In Colab: Runtime â†’ Change runtime type â†’ GPU (T4 empfohlen)
SERIES_NAME = 'solar'  # Ã„ndern fÃ¼r andere Zeitreihen

# Model Selection
RUN_BASIC = True          # LSTM, GRU, Bi-LSTM
RUN_GENERATIVE = True     # Autoencoder, VAE
RUN_GAN = False           # TimeGAN (experimentell)
RUN_ADVANCED = True       # N-BEATS, N-HiTS
RUN_PROBABILISTIC = True  # DeepAR
RUN_TFT = False           # TFT (30-45 min!)
```

**Output**: `results/metrics/deep_learning_extended_{series_name}.csv`

---

### 2. ğŸ“Š **Multivariate Zeitreihenanalyse (Codespace)**
**File**: `notebooks/multivariate_VAR_VECM_analysis.ipynb`

**Modelle**:
- âœ… **VAR** - Vector Autoregression (Standard)
- âœ… **VECM** - Vector Error Correction Model (bei Kointegration)
- âœ… **VARMA** - Vector ARMA (mit MA-Komponente)
- âœ… **Granger Causality Tests** - KausalitÃ¤tsanalyse

**Tests**:
- ğŸ§ª StationaritÃ¤tstests (ADF, KPSS)
- ğŸ§ª Kointegrations-Test (Johansen)
- ğŸ§ª Granger Causality Matrix

**Warum multivariate Verfahren?**
Unsere Energiezeitreihen sind **stark gekoppelt**:
- â˜€ï¸ Solar â†’ ğŸ’° Price (viel Sonne = niedriger Preis)
- ğŸ’¨ Wind â†’ ğŸ’° Price (viel Wind = niedriger Preis)
- â˜€ï¸ Solar + ğŸ’¨ Wind â†’ ğŸ­ Consumption

**VAR/VECM** modellieren diese **Cross-Effects**!

**Vorteile**:
- ğŸ“Š Modelliert interdependenzen
- ğŸ” KausalitÃ¤t testbar
- ğŸ’¡ Ã–konomisch interpretierbar
- ğŸ¯ Gut fÃ¼r Policy-Analysen

**Setup**:
```bash
# Im Codespace ausfÃ¼hren (CPU reicht)
# Keine GPU nÃ¶tig!
```

---

### 3. ğŸŒŠ **Zeitreihen-spezifische Notebooks (Colab)**

Vorbereitet fÃ¼r alle Zeitreihen:
- `scripts/LSTM_Optimization_Colab_wind_offshore.ipynb` âœ…
- `scripts/LSTM_Optimization_Colab_wind_onshore.ipynb` (in Arbeit)
- `scripts/LSTM_Optimization_Colab_price.ipynb` (in Arbeit)
- `scripts/LSTM_Optimization_Colab_consumption.ipynb` (in Arbeit)

**Gleiche Modelle wie Extended Edition**, aber optimiert fÃ¼r spezifische Zeitreihe.

---

## ğŸ“Š Ergebnisse: Solar (Google Colab)

| Modell | RÂ² | RMSE (MW) | MAE (MW) | Training Zeit |
|--------|-----|-----------|----------|---------------|
| **Bi-LSTM** âœ… | **0.9955** | - | - | ~30s |
| **Baseline LSTM** | **0.9934** | - | - | ~25s |
| **Autoencoder** | **0.9515** | - | - | ~40s |
| **VAE** | **0.9255** | - | - | ~60s |
| **N-BEATS** âš ï¸ | -18.93 | 23,316 | 16,348 | ~977s |
| **N-HiTS** âš ï¸ | -4.22 | 11,930 | 8,211 | ~138s |

**Erkenntnisse**:
- âœ… **Bi-LSTM** erreicht beste Performance (RÂ²=0.9955)
- âœ… **GPU-Beschleunigung**: 30-50x schneller als CPU
- âš ï¸ **N-BEATS/N-HiTS** zeigen negative RÂ² - mÃ¶glicherweise Skalierungsprobleme
- ğŸ’¡ **Random Forest (RÂ²=0.9994)** bleibt dennoch bestes Gesamtmodell

---

## ğŸ”„ Workflow-Empfehlung

### Phase 1: Basis-Experimente (Colab)
1. Starte mit **Extended Colab Notebook**
2. Aktiviere nur schnelle Modelle:
   ```python
   RUN_BASIC = True          # LSTM, GRU, Bi-LSTM
   RUN_GENERATIVE = True     # Autoencoder, VAE
   RUN_ADVANCED = True       # N-BEATS, N-HiTS
   RUN_TFT = False           # ZunÃ¤chst Ã¼berspringen
   ```
3. Laufzeit: ~10-15 Minuten
4. Evaluiere Ergebnisse

### Phase 2: State-of-the-Art (Colab)
1. Falls Zeit/Ressourcen verfÃ¼gbar:
   ```python
   RUN_TFT = True            # Temporal Fusion Transformer
   RUN_GAN = True            # TimeGAN (experimentell)
   ```
2. Laufzeit: +30-45 Minuten
3. Vergleiche mit Basis-Modellen

### Phase 3: Multivariate Analyse (Codespace)
1. FÃ¼hre `multivariate_VAR_VECM_analysis.ipynb` aus
2. Analysiere Granger-KausalitÃ¤ten
3. Teste VAR vs. VECM
4. Laufzeit: ~5-10 Minuten

### Phase 4: Vergleich & Dokumentation
1. Vergleiche alle AnsÃ¤tze:
   - **Univariate** (RF, LSTM, GRU)
   - **Advanced DL** (N-BEATS, TFT, DeepAR)
   - **Multivariate** (VAR, VECM)
2. Dokumentiere in `PHASE2_EVALUATION_SUMMARY.md`
3. Erstelle finale Empfehlungen

---

## ğŸ¯ Modell-Auswahl-Matrix

| Kriterium | Empfohlenes Modell | BegrÃ¼ndung |
|-----------|-------------------|------------|
| **HÃ¶chste Genauigkeit** | Random Forest, Bi-LSTM | RÂ² > 0.99 |
| **Schnellste Inferenz** | GRU, Linear Regression | <1ms pro Vorhersage |
| **UnsicherheitsschÃ¤tzung** | DeepAR, VAE | Probabilistische Outputs |
| **Interpretierbarkeit** | VAR, VECM | Ã–konomisch klar |
| **KausalitÃ¤tsanalyse** | VAR + Granger Tests | Cross-Series Effects |
| **State-of-the-Art** | TFT, N-BEATS | Neueste Forschung |
| **Anomalieerkennung** | Autoencoder, VAE | Reconstruction Error |
| **Produktionsreife** | Random Forest, LightGBM | Robust, schnell, stabil |

---

## ğŸ” Fehlende Modelle & Limitationen

### Noch nicht implementiert:
- âŒ **Chronos** - Zu groÃŸ (mehrere GB), benÃ¶tigt viel RAM
- âŒ **TimeGAN** - Sehr experimentell, komplex
- âŒ **Informer** - Transformer fÃ¼r lange Sequenzen
- âŒ **PatchTST** - State-of-the-Art (2023)

### Machbar, aber nicht priorisiert:
- âš ï¸ **Prophet** - Facebook's Tool (bereits getestet, schlecht performt)
- âš ï¸ **ARCH/GARCH** - FÃ¼r VolatilitÃ¤t, nicht Forecasting
- âš ï¸ **Wavelet Transform** - Feature Engineering, kein Modell

---

## ğŸ’¡ Wichtige Erkenntnisse

### 1. GPU-Beschleunigung ist kritisch
- LSTM/GRU: **30-50x** schneller auf GPU
- N-BEATS/N-HiTS: Nur auf GPU praktikabel
- TFT: GPU **essentiell** (sonst Stunden!)

### 2. Multivariate â‰  Bessere Accuracy
- VAR/VECM haben oft **niedrigere RÂ²** als univariate RF
- **ABER**: Modellieren KausalitÃ¤ten, Ã¶konomisch wertvoller!

### 3. KomplexitÃ¤t â‰  Performance
- Einfache Modelle (RF, GRU) oft **besser** als komplexe (N-BEATS)
- Problem: Daten-Skalierung, Hyperparameter-Tuning

### 4. Negative RÂ² bei N-BEATS/N-HiTS
- Wahrscheinliche Ursachen:
  - Falsche Daten-Skalierung
  - Zu kleine Trainingsdaten
  - Hyperparameter nicht optimal
- **Fix**: Mehr Tuning, andere Scaler (MinMaxScaler?)

---

## ğŸ“š Referenzen & Literatur

### Papers:
1. **N-BEATS**: Oreshkin et al. (2019) - "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting"
2. **TFT**: Lim et al. (2021) - "Temporal Fusion Transformers for interpretable multi-horizon time series forecasting"
3. **DeepAR**: Salinas et al. (2020) - "DeepAR: Probabilistic forecasting with autoregressive recurrent networks"
4. **VAR**: Sims (1980) - "Macroeconomics and Reality"
5. **VECM**: Johansen (1988) - "Statistical analysis of cointegration vectors"

### Code/Tools:
- **Darts**: https://github.com/unit8co/darts
- **GluonTS**: https://ts.gluon.ai/
- **statsmodels**: https://www.statsmodels.org/
- **PyTorch Forecasting**: https://pytorch-forecasting.readthedocs.io/

---

## âœ… Next Steps

1. âœ… **Solar Extended Colab** - Ergebnisse in PHASE2_EVALUATION_SUMMARY.md âœ…
2. ğŸ”„ **Alle Zeitreihen** - Extended Colab fÃ¼r Wind/Price/Consumption ausfÃ¼hren
3. ğŸ“Š **Multivariate Analyse** - VAR/VECM im Codespace testen
4. ğŸ“ˆ **Vergleichstabelle** - Alle Modelle Ã¼ber alle Zeitreihen
5. ğŸ¯ **Produktionsempfehlung** - Finale Model Selection

---

**Viel Erfolg mit den Advanced Models! ğŸš€**
