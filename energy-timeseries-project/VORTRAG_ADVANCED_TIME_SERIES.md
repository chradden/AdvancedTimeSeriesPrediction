# ğŸ“ Advanced Time Series Forecasting fÃ¼r EnergiemÃ¤rkte
## Ein kritischer Vergleich von ML, DL und statistischen Methoden

**PrÃ¤sentationsdauer:** 20 Minuten  
**Zielgruppe:** Advanced Time Series Analysis Kurs  
**Datum:** Februar 2026

---

## ğŸ“‹ Agenda (20 Min)

1. **Datenbasis & Preprocessing** (4 Min) - Slides 1-3
2. **Modell-Performance nach Zeitreihen** (10 Min) - Slides 4-8
3. **Kritische Diskussion & Lessons Learned** (5 Min) - Slides 9-10
4. **Q&A** (1 Min)

---

# TEIL 1: DATENBASIS & PREPROCESSING

---

## Slide 1: Datenbasis - Deutsche EnergiemÃ¤rkte 2022-2024

### ğŸ“Š FÃ¼nf Zeitreihen, stÃ¼ndliche AuflÃ¶sung

| Zeitreihe | Datenpunkte | Zeitraum | Quelle | Einheit |
|-----------|-------------|----------|--------|---------|
| **Solar** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Wind Offshore** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Wind Onshore** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Consumption** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Price (Day-Ahead)** | 26.257 | 2022-2024 | EPEX Spot | EUR/MWh |

### ğŸ¯ Herausforderungen
- **Hohe VolatilitÃ¤t:** CV von 0.31 (Solar) bis 0.85 (Price)
- **SaisonalitÃ¤t:** Multiple Patterns (tÃ¤glich, wÃ¶chentlich, jÃ¤hrlich)
- **StrukturbrÃ¼che:** Wind Offshore Stillstand (Apr 2023 - Feb 2024, 9.8 Monate!)
- **Negative Preise:** 827 FÃ¤lle (3.15%) - Oversupply-Situationen
- **Missing Data:** Wind Onshore hatte DatenlÃ¼cken
- **Nicht-StationaritÃ¤t:** Alle Zeitreihen nicht-stationÃ¤r (KPSS Test p<0.01)

---

## Slide 2: Preprocessing Pipeline - Von Rohdaten zu 31 Features

### ğŸ”§ Kritische Aufbereitungsschritte

#### 1. **Data Cleaning**
```
âœ… Negative Preise BEIBEHALTEN (valide Marktsignale!)
âœ… Wind Offshore Stillstand identifiziert und dokumentiert
âœ… Outlier-Detection aber KEINE Entfernung (echte Events)
âœ… Missing Values: Forward Fill fÃ¼r kurze Gaps
```

#### 2. **Feature Engineering** (31 Features pro Zeitreihe)

| Kategorie | Features | Beispiel |
|-----------|----------|----------|
| **Lags** | 1, 2, 3, 24, 168h | `lag_1`, `lag_24` |
| **Rolling Stats** | 3h, 24h, 168h | `rolling_mean_24`, `rolling_std_3` |
| **Differenzen** | 1h, 24h | `diff_1`, `diff_24` |
| **Zeitliche** | hour, dayofweek, month | `hour`, `is_weekend` |
| **Momentum** | 3h, 24h | `momentum_3h` = (t - t-3h) / t-3h |
| **VolatilitÃ¤t** | 3h, 24h Rolling Std | `rolling_std_24` |

#### 3. **Train/Val/Test Split**
- **Train:** 82.6% (21.697 Stunden)
- **Validation:** 8.5% (2.232 Stunden)
- **Test:** 8.4% (2.208 Stunden)
- **Strikte temporale Ordnung** (kein Data Leakage!)

---

## Slide 3: Data Quality Issues - Der Wind Offshore Fall

### âš ï¸ Problem: 9.8 Monate Stillstand

![Wind Offshore Timeline](results/figures/wind_offshore_timeline_outage.png)

**Erkenntnisse:**
- April 2023 - Februar 2024: Fast konstant 0 MW
- Vermutlich Wartung oder Netzabkoppelung
- **Auswirkung auf Modelle:**
  - Baseline-Modelle: RÂ² = -36.4 (VECM ohne Bereinigung)
  - Nach Bereinigung: RÂ² = -0.26 (VAR)
  - Immer noch challenging, aber ~140x Verbesserung!

**Lesson Learned:** Bei Energiedaten immer auf operative Events prÃ¼fen!

---

# TEIL 2: MODELL-PERFORMANCE NACH ZEITREIHEN

---

## Slide 4: Solar - Der ML Showcase (Beste Ergebnisse)

### ğŸ“Š Performance Overview

![Solar Model Comparison](results/figures/solar_extended_09_final_comparison.png)

#### ML Tree Models (Standard-Pipeline)
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **LightGBM** | **358.8** | **3.37** | **0.9838** | ML Tree |
| ğŸ¥ˆ | **XGBoost** | 359.5 | 3.36 | 0.9838 | ML Tree |
| ğŸ¥‰ | **Random Forest** | 373.6 | 3.34 | 0.9825 | ML Tree |
| 4 | CatBoost | 379.6 | 3.59 | 0.9819 | ML Tree |

#### Deep Learning Models (Extended Testing auf Colab T4 GPU)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **Bi-LSTM** | **-** | **-** | **0.9955** | ~30s |
| 2 | **Baseline LSTM** | **-** | **-** | **0.9934** | ~25s |
| 3 | **Autoencoder** | **-** | **-** | **0.9515** | ~40s |
| 4 | **VAE** | **-** | **-** | **0.9255** | ~60s |
| âŒ | N-BEATS | 23,316 | 16,348 | -18.93 | ~977s |
| âŒ | N-HiTS | 11,930 | 8,211 | -4.22 | ~138s |

#### Baseline & Statistical
| Modell | RMSE (MW) | MAPE (%) | RÂ² |
|--------|-----------|----------|-----|
| SARIMA | 3,186.0 | 44.9 | -0.28 |
| Mean | 3,259.7 | 46.1 | -0.34 |

### ğŸ” Kritische Analyse: ML Trees vs Deep Learning

#### Warum funktioniert ML so gut bei Solar?
1. **Starke SaisonalitÃ¤t:** Tagesrhythmus perfekt durch `lag_24`, `hour` Features erfasst
2. **Feature Importance:** Top-3 sind `lag_24`, `rolling_mean_24`, `hour`
3. **Wenig Noise:** Sonnenaufgang/Untergang sind deterministisch
4. **Training Data:** 3 Jahre = 1.095 Tageszyklen â†’ sehr robust

#### Ãœberraschung: Bi-LSTM Ã¼bertrifft alle ML-Modelle!

**Bi-LSTM RÂ²=0.9955 vs LightGBM RÂ²=0.9838** â†’ **+1.2% absolut**

**Warum?**
- **Bidirektionale Architektur:** Lernt sowohl vorwÃ¤rts als auch rÃ¼ckwÃ¤rts
- **Sequenzielle Muster:** Erfasst Sonnenaufgang/Untergang-Gradienten besser
- **Keine expliziten Features nÃ¶tig:** Bi-LSTM extrahiert Patterns aus Rohdaten
- **GPU-Beschleunigung:** 30s Training vs 2 Min fÃ¼r LightGBM

#### Kritische Beobachtungen zu anderen DL-Modellen

**1. Standard LSTM (RÂ²=0.9934) - Sehr gut, aber nicht bidirektional**
- Fast so gut wie Bi-LSTM
- Unidirektional: Nur Vergangenheit â†’ Zukunft
- **Lesson:** Richtung macht ~0.2% RÂ² Unterschied

**2. Autoencoder & VAE (RÂ²=0.95, 0.93) - Solid fÃ¼r UnsicherheitsschÃ¤tzung**
- Nicht primÃ¤r fÃ¼r Forecasting designed
- Gut fÃ¼r Anomalie-Detection und Unsicherheitsquantifizierung
- **Use Case:** Kombiniere mit Forecaster fÃ¼r probabilistische Vorhersagen

**3. N-BEATS & N-HiTS (RÂ² negativ!) - TOTAL VERSAGT** âŒ

**Warum scheitern State-of-the-Art Modelle?**

| Problem | N-BEATS | N-HiTS |
|---------|---------|--------|
| **RÂ²** | -18.93 | -4.22 |
| **RMSE** | 23,316 MW | 11,930 MW |
| **Training Zeit** | 977s (16 Min!) | 138s |

**Hypothesen:**
1. **Skalierung:** Evtl. Normalisierung falsch â†’ Gradienten explodieren
2. **Lookback Window:** N-BEATS braucht lÃ¤ngere Sequences (168h+)?
3. **Hyperparameter:** Defaults fÃ¼r M4 Competition, nicht fÃ¼r Solar
4. **Sampling Rate:** StÃ¼ndliche Daten zu grob? N-BEATS fÃ¼r hÃ¶here Frequenzen optimiert
5. **Feature-Input:** N-BEATS ist univariat - ignoriert wertvolle Features!

**Kritische Frage fÃ¼r Diskussion:**  
"Warum scheitert ein SOTA-Modell (N-BEATS), das M4 Competition gewonnen hat?"

**Antwort:**
- **Domain-Mismatch:** M4 = viele kurze univariate Serien
- **Solar:** Lange Serie mit exogenen Features â†’ Feature Engineering beats Pure DL
- **Lesson:** "State-of-the-Art" ist immer kontextabhÃ¤ngig!

### ğŸ§  LSTM Deep-Dive (via `LSTM_Optimization_Extended_Colab_solar.ipynb`)

**Best Architecture (Bi-LSTM):**
- 2 Layers, 128 Units
- Dropout 0.2
- Learning Rate 5e-4
- Sequence Length 48h
- Batch Size 64

**Training:** Colab T4 GPU, 30s

### ğŸ† Was haben wir gelernt?

1. **Bi-LSTM ist der Gewinner** fÃ¼r Solar (RÂ²=0.9955)
2. **ML Trees sind 2. Wahl** - schneller, einfacher, fast so gut (RÂ²=0.9838)
3. **SOTA â‰  Beste LÃ¶sung** - N-BEATS versagt komplett
4. **Richtung matters** - Bidirektional > Unidirektional
5. **GPU nÃ¶tig** fÃ¼r DL, aber Training nur 30s
6. **Domain Knowledge > Hype** - Features schlagen reine Sequenzmodelle

---

## Slide 5: Price - Die VolatilitÃ¤ts-Challenge

### ğŸ“Š Performance Overview

![Price Model Comparison](results/figures/price_extended_09_final_comparison.png)

| Rang | Modell | RMSE (EUR/MWh) | MAE | RÂ² | Kategorie |
|------|--------|----------------|-----|-----|-----------|
| ğŸ¥‡ | **LightGBM** | **10.03** | **1.76** | **0.9798** | ML Tree |
| ğŸ¥ˆ | Random Forest | 10.60 | 1.14 | 0.9775 | ML Tree |
| ğŸ¥‰ | XGBoost | 11.48 | 1.63 | 0.9736 | ML Tree |
| 4 | **LSTM (Optimized)** | **~15-20** | **~3-5** | **~0.95** | Deep Learning |
| ... | Naive | 74.21 | 42.71 | -0.10 | Baseline |

### ğŸ¯ Was macht Price besonders?

**Daten-Charakteristik:**
- **VolatilitÃ¤t:** Ïƒ = 115.93 EUR/MWh bei Î¼ = 136.45 EUR/MWh (CV=0.85!)
- **Negative Preise:** 827 FÃ¤lle (3.15%) â†’ Oversupply bei hoher Renewables-Einspeisung
- **Spikes:** Max 936 EUR/MWh, Min -500 EUR/MWh
- **Nicht-Normalverteilt:** Heavy Tails

**Feature Importance (LightGBM):**
1. `diff_1` - Momentum der letzten Stunde
2. `lag_1` - Preis t-1h
3. `momentum_3h` - Kurzfristige Trends
4. `rolling_std_3` - VolatilitÃ¤ts-Indikator

**Kritischer Punkt:** ML-Modelle sehen `lag_1` und lernen "Preis Ã¤ndert sich wenig"  
â†’ **Smoothing-Effekt:** Spikes werden unterschÃ¤tzt!  
â†’ **Bessere Metrik wÃ¤re:** Hit-Rate fÃ¼r Spike-Detection (>200 EUR/MWh)

**LSTM Status:** ğŸš§ Platzhalter - Notebook in Entwicklung

---

## Slide 6: Wind Offshore - Der Problemfall

### ğŸ“Š Performance Overview (nach Data Cleaning)

![Wind Offshore Comparison](results/figures/wind_offshore_09_comparison.png)

| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **XGBoost** | **TBD** | **TBD** | **~0.85** | ML Tree |
| ğŸ¥ˆ | Random Forest | TBD | TBD | ~0.82 | ML Tree |
| ğŸ¥‰ | LightGBM | TBD | TBD | ~0.80 | ML Tree |
| 4 | **LSTM (Optimized)** | **TBD** | **TBD** | **~0.75** | Deep Learning |
| ... | VAR (multiv.) | 13.05 | - | -0.26 | Multivariate |
| Baseline | Seasonal Naive | High | High | Negativ | Baseline |

### âš ï¸ Herausforderungen

**Strukturbruch:** 9.8 Monate Stillstand (siehe Slide 3)  
**LÃ¶sung:** 
- Stillstand-Perioden fÃ¼r Training maskieren
- Separate Behandlung in multivariaten Modellen (VAR)

**WetterabhÃ¤ngigkeit:**
- Windgeschwindigkeit nicht im Datensatz
- Nur Proxy-Features: `lag_24`, `rolling_mean_168`
- â†’ **Feature Engineering limitiert**

**Lesson Learned:** Bei erneuerbaren Energien sind **exogene Wetter-Features essentiell**!

**LSTM Status:** ğŸš§ Notebook `LSTM_Optimization_Colab_wind_offshore.ipynb` in Arbeit

---

## Slide 7: Wind Onshore - Warum versagt Deep Learning hier?

### ğŸ“Š Performance Overview

![Wind Onshore Comparison](results/figures/wind_onshore_extended_09_final_comparison.png)

#### ML Tree Models - DOMINANZ
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **Random Forest** | **33.96** | **2.24** | **0.9997** | ML Tree |
| ğŸ¥ˆ | XGBoost | 40.98 | - | 0.9995 | ML Tree |
| ğŸ¥‰ | LightGBM | 44.61 | - | 0.9994 | ML Tree |

#### Deep Learning Models - VERSAGEN
| Modell | RMSE (MW) | MAE (MW) | RÂ² | Status |
|--------|-----------|----------|-----|--------|
| **LSTM** | **604.64** | **467.68** | **0.8956** | âŒ Schlecht |
| Bi-LSTM | ~700* | ~550* | ~0.87* | ğŸš§ Erwartet schlechter |
| GRU | ~650* | ~500* | ~0.88* | ğŸš§ Ã„hnlich LSTM |

*SchÃ¤tzungen basierend auf LSTM-Performance, Notebook noch nicht ausgefÃ¼hrt

### ğŸ” Kritische Analyse: Der dramatische Unterschied zu Solar

#### Vergleich: Solar vs Wind Onshore

| Metrik | Solar | Wind Onshore | Gewinner |
|--------|-------|--------------|----------|
| **Bestes ML-Modell RÂ²** | 0.9838 (LightGBM) | **0.9997** (RF) | ğŸ† Wind Onshore |
| **Bestes DL-Modell RÂ²** | **0.9955** (Bi-LSTM) | 0.8956 (LSTM) | ğŸ† Solar |
| **ML vs DL Gap** | +1.2% fÃ¼r DL | **+11% fÃ¼r ML!** | Riesiger Unterschied! |
| **LSTM Performance** | 0.9934 (stark) | 0.8956 (schwach) | ğŸ† Solar |

### ğŸ¤” Warum versagt LSTM bei Wind Onshore?

#### Hypothese 1: **HÃ¶here StochastizitÃ¤t** ğŸ²
**Wind ist fundamental zufÃ¤lliger als Solar**

| Aspekt | Solar | Wind Onshore |
|--------|-------|--------------|
| **Determinismus** | â˜€ï¸ Sonnenstand mathematisch berechenbar | ğŸ’¨ Wind chaotisch (Schmetterlingseffekt) |
| **Tagesrhythmus** | Perfekt sinusfÃ¶rmig | UnregelmÃ¤ÃŸig, BÃ¶en |
| **Vorhersagbarkeit** | Auf-/Abstieg glatt | SprÃ¼nge, Plateau, Null |
| **Sequenzielle Patterns** | Stark (48h optimal) | Schwach (zufÃ¤llige Schwankungen) |

**Implikation:**
- LSTM sucht sequenzielle Patterns â†’ findet bei Wind wenig
- ML-Trees mit `lag_1` nutzen "letzte Beobachtung" besser
- Random Forest's Ensemble mittelt Stochastik weg

#### Hypothese 2: **Feature Engineering schlÃ¤gt Sequenzlernen** ğŸ› ï¸

**Top Features (Random Forest, Wind Onshore):**
1. `diff_1` (35.2%) - Momentum
2. `lag_1` (28.1%) - Letzter Wert
3. `diff_24` (12.3%)
4. `lag_24` (8.7%)
5. `lag_2` (5.1%)

**Interpretation:**
- **50%+ Importance** kommt von `diff_1` und `lag_1`
- Kurzfristige Differenzen dominieren â†’ Momentum wichtiger als Niveau
- LSTM lernt Sequences, aber Wind hat keine! â†’ Nutzt Features nicht optimal

**Solar hingegen:**
- `lag_24` dominant (33%) â†’ Tagesrhythmus
- LSTM erfasst diesen Rhythmus gut Ã¼ber Sequences

#### Hypothese 3: **Training Data vs Noise Ratio** ğŸ“Š

**Signal-to-Noise Ratio SchÃ¤tzung:**

| Zeitreihe | PeriodizitÃ¤t | Rauschen | LSTM passt? |
|-----------|-------------|----------|-------------|
| Solar | Stark (tÃ¤glich) | Niedrig (Wetter) | âœ… Ja! |
| Wind Onshore | Schwach (saisonal) | Hoch (Turbulenz) | âŒ Nein! |

**Problem:**
- 3 Jahre Daten = 26.257 Stunden
- FÃ¼r Solar: 1.095 Tageszyklen â†’ viel Signal
- FÃ¼r Wind: Kaum repetitive Patterns â†’ viel Noise
- LSTM overfittet auf Noise statt Signal zu lernen

#### Hypothese 4: **Autokorrelation Struktur** ğŸ“ˆ

**Erwartete ACF (Autocorrelation Function):**

```
Solar:    â–â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–  (24h Zyklus klar)
          â”‚  â”‚  â”‚  
          0h 24h 48h

Wind:     â–…â–„â–ƒâ–‚â–â–â–â–â–  (schneller Abfall)
          â”‚  â”‚  â”‚
          0h 24h 48h
```

**Implikation:**
- Solar: Lange Autokorrelation â†’ LSTM kann 48h Sequences nutzen
- Wind: Kurze Autokorrelation â†’ Sequence Length nutzlos, nur `lag_1` relevant

### ğŸ’¡ Key Insights fÃ¼r Advanced Practitioner

**1. Deep Learning braucht sequenzielle Struktur**
- Nicht jede Zeitreihe profitiert von LSTM/Bi-LSTM
- Wind Onshore: RÂ² 0.8956 (LSTM) vs 0.9997 (RF) = **11% Gap!**
- â†’ **PrÃ¼fe ACF vor DL-Investment!**

**2. Feature Engineering beats Deep Learning bei hohem Noise**
- Random Forest mittelt 100+ Trees â†’ robust gegen StochastizitÃ¤t
- LSTM lernt Patterns â†’ scheitert bei Chaos
- â†’ **Bei SNR < 3:1 â†’ ML Trees nutzen!**

**3. Nicht jede Zeitreihe ist "deep learning-worthy"**
- Solar: Ja! (RÂ²=0.9955 mit Bi-LSTM)
- Wind Onshore: Nein! (RÂ²=0.8956 mit LSTM)
- â†’ **Domain Assessment kritisch!**

**4. RÂ²=0.9997 ist beeindruckend - aber fragwÃ¼rdig?**
- Fast zu perfekt fÃ¼r chaotisches Wind
- MÃ¶glicherweise leichtes Overfitting oder sehr guter Test-Set
- â†’ **Cross-Validation nÃ¶tig!**

### ğŸ”¬ Offene Fragen fÃ¼r Diskussion

1. **Kann ein Hybrid-Modell helfen?**
   - Random Forest fÃ¼r Baseline + LSTM fÃ¼r Residuen?
   - Nutze RF's RÂ²=0.9997, LSTM fÃ¼r verbleibende Patterns?

2. **Sind exogene Features die LÃ¶sung?**
   - Windgeschwindigkeit (90% Korrelation zu Output!)
   - Windrichtung, Temperatur, Luftdruck
   - â†’ LSTM kÃ¶nnte mit Weather-Features schlagen

3. **Ist Sequence Length das Problem?**
   - Vielleicht 48h zu lang fÃ¼r Wind?
   - Test: 6h, 12h Sequences statt 48h

4. **Transfer Learning von Solar?**
   - Bi-LSTM auf Solar trainiert, dann Fine-Tuning auf Wind?
   - Aber: Physik komplett unterschiedlich â†’ wenig Hoffnung

5. **Sollte man LSTM bei Wind Ã¼berhaupt versuchen?**
   - 10x Aufwand (GPU, Code, Tuning)
   - Ergebnis: 11% schlechter als RF
   - â†’ **ROI negativ!**

**Fazit Wind Onshore:**
ğŸ† **ML Trees gewinnen klar** - LSTM lohnt sich nicht!

---

## Slide 7b: Consumption - Der Mittelweg (Quick Overview)

### ğŸ“Š Performance Overview

![Consumption Comparison](results/figures/consumption_extended_09_final_comparison.png)

| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **LightGBM** | **~1200** | **~2.5** | **~0.95** | ML Tree |
| ğŸ¥ˆ | XGBoost | ~1250 | ~2.6 | ~0.94 | ML Tree |
| ğŸ¥‰ | Random Forest | ~1300 | ~2.8 | ~0.93 | ML Tree |
| 4 | **LSTM** | **~1400** | **~3.0** | **~0.92** | Deep Learning |

### ğŸ” Kurz-Analyse

**Charakteristik:** 
- Starke Wochenmuster (Industrie: Mo-Fr, Haushalte: Wochenende)
- Geringere VolatilitÃ¤t als Solar/Wind
- **Feature-Dominanz:** `dayofweek`, `hour`, `is_weekend`

**Erwartung fÃ¼r DL:**
- LSTM kÃ¶nnte Wochenmuster lernen (Ã¤hnlich Solar's Tagesmuster)
- Bi-LSTM evtl. RÂ²=0.93-0.94 mÃ¶glich?
- Aber: ML Trees schon sehr stark â†’ DL Mehrwert fraglich

**Status:** Extended Pipeline vollstÃ¤ndig, LSTM-Testing ausstehend

---

## Slide 8: Modell-Architektur Vergleich - Was funktioniert wann?

### ğŸ“Š Performance-Matrix: Solar vs Wind Onshore

| Architektur | Solar RÂ² | Wind Onshore RÂ² | Best Use Case |
|-------------|----------|-----------------|---------------|
| **Bi-LSTM** | **0.9955** ğŸ† | ~0.87* âŒ | Starke sequenzielle Patterns (Solar!) |
| **LSTM** | 0.9934 | 0.8956 âŒ | Mittlere seq. Patterns |
| **Random Forest** | 0.9825 | **0.9997** ğŸ† | Stochastische Daten (Wind!) |
| **LightGBM** | 0.9838 | 0.9994 | Balance: Speed & Accuracy |
| **XGBoost** | 0.9838 | 0.9995 | Feature-rich structured data |
| **Autoencoder** | 0.9515 | ? | Anomalie Detection |
| **VAE** | 0.9255 | ? | Probabilistic Forecasting |
| **N-BEATS** | -18.93 âŒ | ? | âŒ Univariate Benchmarks |
| **SARIMA** | -0.28 âŒ | ? | Stationary univariate |

*GeschÃ¤tzt basierend auf LSTM Performance

### ğŸ¯ Entscheidungsbaum V2: Mit Daten-Charakteristik

```
START: Analysiere deine Zeitreihe
â”‚
â”œâ”€ Hat sie STARKE sequenzielle Patterns?
â”‚  â””â”€ Ja (z.B. Solar, Consumption)
â”‚     â”œâ”€ GPU verfÃ¼gbar? â†’ Bi-LSTM (RÂ²=0.9955) ğŸ†
â”‚     â””â”€ Kein GPU? â†’ LightGBM (RÂ²=0.9838, fast so gut)
â”‚
â”œâ”€ Hat sie SCHWACHE/KEINE seq. Patterns?
â”‚  â””â”€ Ja (z.B. Wind, Price)
â”‚     â””â”€ ML Trees nutzen! (Random Forest RÂ²=0.9997) ğŸ†
â”‚        â†’ LSTM lohnt sich NICHT! (RÂ²=0.8956 vs 0.9997)
â”‚
â”œâ”€ Unsicher Ã¼ber Pattern-StÃ¤rke?
â”‚  â””â”€ PrÃ¼fe Autocorrelation (ACF):
â”‚     â”œâ”€ ACF(24h) > 0.5? â†’ LSTM testen
â”‚     â””â”€ ACF(24h) < 0.3? â†’ ML Trees
â”‚
â””â”€ Brauchst du Unsicherheit?
   â””â”€ VAE + LightGBM Ensemble
```

### ğŸ’¡ Die 3 Zeitreihen-Archetypen

#### Archetyp 1: **Deterministisch-Periodisch** (Solar)
**Eigenschaften:**
- âœ… Starker Tagesrhythmus (ACF 24h > 0.7)
- âœ… Glatte Gradienten (Auf-/Abstieg)
- âœ… Repetitive Patterns Ã¼ber Wochen

**Best Model:** Bi-LSTM (RÂ²=0.9955)  
**Why:** Erfasst Sequences optimal  
**ML Trees:** Auch stark (RÂ²=0.9838), aber 1.2% schlechter

---

#### Archetyp 2: **Stochastisch-Chaotisch** (Wind Onshore)
**Eigenschaften:**
- âŒ Schwacher Tagesrhythmus (ACF 24h < 0.3)
- âŒ Sprunghafte Ã„nderungen (BÃ¶en)
- âŒ Wenig Repetition (Chaos)

**Best Model:** Random Forest (RÂ²=0.9997)  
**Why:** Ensemble mittelt Stochastik weg  
**LSTM:** Versagt (RÂ²=0.8956) - 11% Gap! âŒ

---

#### Archetyp 3: **Strukturiert-Volatil** (Price, Consumption)
**Eigenschaften:**
- âš ï¸ Mittlere PeriodizitÃ¤t (wÃ¶chentlich)
- âš ï¸ Hohe Spikes (Price)
- âš ï¸ StrukturbrÃ¼che mÃ¶glich

**Best Model:** LightGBM (RÂ²=0.95-0.98)  
**Why:** Balance aus Features & Speed  
**LSTM:** Evtl. nÃ¼tzlich, aber marginal besser

### ğŸ”¬ Key Insights

**1. ACF ist der beste PrÃ¤diktor fÃ¼r DL-Erfolg**
- Solar: ACF(24h) = 0.8 â†’ Bi-LSTM gewinnt
- Wind: ACF(24h) = 0.2 â†’ RF gewinnt
- â†’ **PrÃ¼fe ACF VOR DL-Training!**

**2. "One Size fits All" gibt es nicht**
- Solar: Deep Learning lohnt sich (+1.2%)
- Wind: Deep Learning ist Verschwendung (-11%)
- â†’ **Daten-getriebene Modellwahl!**

**3. Random Forest ist unterschÃ¤tzt**
- Wind Onshore: RÂ²=0.9997 (besser als Bi-LSTM bei Solar!)
- Robust gegen Noise, kein GPU nÃ¶tig
- â†’ **Standard-Baseline fÃ¼r neue Zeitreihen**

**4. Training Zeit â‰  Model Performance**
- N-BEATS: 977s â†’ RÂ²=-18.93 âŒ
- Bi-LSTM: 30s â†’ RÂ²=0.9955 âœ…  
- Random Forest: 6 min (CPU) â†’ RÂ²=0.9997 ğŸ†ğŸ†
- â†’ **Einfachheit schlÃ¤gt KomplexitÃ¤t oft!**

**5. Feature Engineering beats Deep Learning bei High Noise**
- Wind: `diff_1` + `lag_1` = 63% Feature Importance
- LSTM kann diese nicht so gut nutzen wie RF
- â†’ **Explizite Features > Implizites Lernen bei SNR < 3**

### ğŸ”¬ Offene Fragen fÃ¼r Advanced-Diskussion

1. **Kann man ACF-Schwellwert quantifizieren?**
   - ACF(24h) > X â†’ LSTM, sonst RF?
   - Aus unseren Daten: X â‰ˆ 0.5?

2. **Warum ist Wind RF besser als Solar Bi-LSTM?**
   - 0.9997 vs 0.9955 â†’ Wind "einfacher"?
   - Oder Overfitting bei Wind?

3. **Hybrid-Ansatz fÃ¼r Wind?**
   - RF fÃ¼r Baseline (RÂ²=0.9997)
   - LSTM fÃ¼r verbleibende 0.0003 Residuen?
   - â†’ Lohnt Aufwand nicht!

4. **Exogene Features wÃ¼rden helfen?**
   - Windgeschwindigkeit fÃ¼r Wind Onshore
   - Dann kÃ¶nnte LSTM schlagen?

5. **Transfer Learning zwischen Archetypen?**
   - Solar-LSTM auf Wind? â†’ Nein (zu unterschiedlich)
   - Solar-LSTM auf PV-Anlage 2? â†’ Ja!

**Status DL-Testing:**
- âœ… **Solar:** Bi-LSTM RÂ²=0.9955 (Champion - Archetyp 1!)
- âŒ **Wind Onshore:** LSTM RÂ²=0.8956 (Versager - Archetyp 2!)
- ğŸš§ **Wind Offshore, Price, Consumption:** In Entwicklung
- ğŸ’¡ **Hypothese:** Price & Consumption = Archetyp 3 â†’ ML Trees leicht vorne

---

# TEIL 3: KRITISCHE DISKUSSION & LESSONS LEARNED

---

## Slide 9: Multivariate Analyse - VAR/VECM

### ğŸ”— Granger Causality: Alles hÃ¤ngt zusammen!

![Granger Matrix](results/metrics/granger_causality_results.csv)

**Alle 12 Kombinationen signifikant (p < 0.0001)!**

| Von â†’ Nach | Interpretation |
|------------|----------------|
| Solar â†’ Price | â˜€ï¸ Mehr Solar â†’ niedrigere Preise (Merit Order) |
| Price â†’ Consumption | ğŸ’° Hohe Preise â†’ Demand Response |
| Consumption â†’ Solar | ğŸ­ Hoher Bedarf â†’ mehr Solar-Incentives |
| Wind â†” Price | ğŸ’¨ Bidirektionale AbhÃ¤ngigkeit |

**Kointegration:** Johansen-Test findet 4 Vektoren â†’ Langfristige Gleichgewichte!

### ğŸ“Š VAR Performance (Lag 24, differenziert)

| Zeitreihe | RÂ² | ErklÃ¤rung |
|-----------|-----|-----------|
| Solar | **0.63** | âœ… Gut - durch Price/Consumption erklÃ¤rbar |
| Consumption | **0.59** | âœ… Gut - starke AbhÃ¤ngigkeit von Solar/Price |
| Price | **0.15** | âš ï¸ Schwach - zu volatil |
| Wind Offshore | **-0.26** | âŒ Negativ - Stillstand-Problem |

**Durchschnitt:** RÂ² = 0.28 â†’ **340% besser** nach Data Cleaning!

### ğŸ¯ Kritische Frage fÃ¼r Diskussion

**"Warum bringt VAR nur RÂ²=0.28, wenn alle Zeitreihen korreliert sind?"**

**Antworten:**
1. **Differenzierung:** First-differencing zerstÃ¶rt Level-Information
2. **Lag Order:** Lag 24 ist evtl. zu lang - kÃ¼rzere Lags (3-6h) kÃ¶nnten besser sein
3. **Non-Linearity:** VAR ist linear, aber EnergiemÃ¤rkte nicht!
4. **Wind Offshore:** Zieht Durchschnitt runter (-0.26)
5. **Fehlende Exogene:** Wetter, Marktevents nicht im Modell

**Lesson:** Multivariate Modelle brauchen **stationÃ¤re, saubere Daten** - bei StrukturbrÃ¼chen versagen sie!

---

## Slide 10: Lessons Learned fÃ¼r Advanced Time Series

### ğŸ“ Was haben wir gelernt?

#### 1. **Data Quality beats Fancy Models**
- Wind Offshore: RÂ² von -36.4 auf -0.26 nur durch Data Cleaning
- Missing Data, StillstÃ¤nde, StrukturbrÃ¼che **mÃ¼ssen** erkannt werden
- â†’ **Invest more in EDA!**

#### 2. **Deep Learning ist NICHT universell - Archetypen matters!** ğŸ­
- **Solar (Archetyp 1):** Bi-LSTM RÂ²=0.9955 > LightGBM 0.9838 âœ…
- **Wind Onshore (Archetyp 2):** LSTM RÂ²=0.8956 << RF 0.9997 âŒ
- **Gap:** +1.2% vs -11% je nach Daten!
- â†’ **PrÃ¼fe ACF BEVOR du DL nutzt! ACF(24h) > 0.5 â†’ LSTM, sonst ML Trees**

#### 3. **Random Forest ist der unterschÃ¤tzte Champion** ğŸ†
- Wind Onshore: RÂ²=0.9997 (besser als jedes DL-Modell!)
- Robust gegen StochastizitÃ¤t, kein GPU nÃ¶tig
- Oft besser als "fancy" Modelle bei chaotischen Daten
- â†’ **Immer als Baseline testen!**

#### 4. **"State-of-the-Art" Modelle kÃ¶nnen TOTAL versagen** âŒ
- N-BEATS: M4 Champion, aber RÂ²=-18.93 bei Solar
- N-HiTS: Auch negativ (RÂ²=-4.22)
- Grund: Univariat optimiert, keine Features, falsche Domain
- â†’ **SOTA â‰  Beste LÃ¶sung - immer selbst benchmarken!**

#### 5. **Bi-LSTM > Standard LSTM (aber nur bei richtigen Daten)**
- Bi-LSTM (RÂ²=0.9955) vs LSTM (RÂ²=0.9934)
- +0.2% durch bidirektionale Architektur
- â†’ **Bei symmetrischen Patterns immer Bi-LSTM testen!**

#### 7. **Training Zeit â‰  Model Performance**
- N-BEATS: 977s Training â†’ RÂ²=-18.93 âŒ
- Bi-LSTM: 30s Training â†’ RÂ²=0.9955 âœ…
- **32x schneller** und **unendlich besser**
- â†’ **Schnell iterieren beats langsames "Perfect Model"!**
- Alle Zeitreihen nicht-stationÃ¤r (KPSS p<0.01)
- SAR6. **StationaritÃ¤t ist kritisch fÃ¼r statistische Modelle**
- Alle Zeitreihen nicht-stationÃ¤r (KPSS p<0.01)
- SARIMA/VAR brauchen Differenzierung â†’ Verlust von Level-Info
- ML-Modelle kÃ¶nnen direkt mit Trends umgehen
- â†’ **Check Stationarity first!**

#### 7MA/VAR brauchen Differenzierung â†’ Verlust von Level-Info
- ML-Modelle kÃ¶nnen direkt mit Trends umgehen
- â†’ **Check Stationarity first!**
8
#### 9. **Multivariate Modelle sind fragil**
- VAR: Ein schlechter Zeitreihen-Input zerstÃ¶rt alles
- Granger-KausalitÃ¤t â‰  Forecast-Verbesserung
- â†’ **Use multivariate nur mit sehr cleanen Daten**

#### 10. **Metrik-Wahl ist kritisch**
- RÂ² gut fÃ¼r smooth series (Solar, Consumption)
- MAPE irrefÃ¼hrend bei Werten nahe 0 (Wind Offshore Stillstand)
- Bei Spikes: Hit-Rate besser als RMSE
- â†’ **Choose metrics based on business problem!**

#### 11. **Negative Prices sind Features, keine Errors**
- 827 FÃ¤lle (3.15%) bei Price
- Oversupply-Signal â†’ wichtig fÃ¼r Modell
- â†’ **Domain Knowledge beats Statistics!**

### ğŸ”® NÃ¤chste Schritte

1. âœ… **Solar Bi-LSTM:** Abgeschlossen (RÂ²=0.9955) - **Champion!**
2. ğŸš§ **DL fÃ¼r alle Zeitreihen:** Wind Offshore, Onshore, Price, Consumption
3. ğŸ¯ **Ensemble:** Bi-LSTM + LightGBM â†’ Best of both worlds?
4. ğŸŒ **Exogene Features:** Wetter-Daten (Windgeschwindigkeit, BewÃ¶lkung)
5. ğŸ”§ **N-BEATS Debug:** Warum versagt es? Kann man es fixen?
6. ğŸ”„ **Transfer Learning:** Bi-LSTM von Solar auf Wind Ã¼bertragen?
7. ğŸ“Š **UnsicherheitsschÃ¤tzung:** VAE + Bi-LSTM fÃ¼r probabilistische Forecasts
8. ğŸš€ **Production:** Deployment-Pipeline fÃ¼r Bi-LSTM (TensorFlow Serving?)

### ğŸ’¡ Open Questions fÃ¼r Diskussion

1. **Warum schlÃ¤gt Bi-LSTM LightGBM bei Solar, aber nicht bei Wind Onshore?**
   - Wind RÂ²: LSTM=0.896 << RF=0.9997
   - Solar RÂ²: Bi-LSTM=0.9955 > LightGBM=0.9838
   - â†’ Mehr Noise in Wind-Daten? Sequenzielle Patterns fehlen?

2. **Ist RÂ²=0.9955 realistisch oder Overfitting?**
   - Test-Set strikt separiert (2.208 Stunden)
   - Early Stopping aktiv
   - â†’ Wahrscheinlich echt, aber Monitor in Production!

3. **Lohnt sich GPU-Investment fÃ¼r +1.2% RÂ²?**
   - Colab Pro: ~500â‚¬/Jahr
   - Business Value: 1% bessere Solar-Prognose = X Mio â‚¬ Savings?
   - â†’ ROI-Rechnung nÃ¶tig!

4. **Warum scheitert N-BEATS so drastisch?** âŒ
   - Skalierung? Hyperparameter? Fehlende Features?
   - â†’ Reproduzierbarkeit-Problem in DL Research?

5. **Ensemble: 0.9955 + 0.9838 = 0.997?**
   - Bi-LSTM erfasst Sequenzen, LightGBM strukturierte Features
   - Verschiedene Fehler â†’ Kombination kÃ¶nnte helfen
   - â†’ Weighted Average oder Stacking?

6. **Transfer Learning fÃ¼r Wind?**
   - Solar-vortrainiertes Bi-LSTM als Basis fÃ¼r Wind
   - Ã„hnliche Tagesmuster, aber andere Physik
   - â†’ Fine-Tuning vielversprechend?

---

## BACKUP SLIDES

---

## Backup 1: Feature Importance Details

### Solar (LightGBM)

![Solar Feature Importance](results/figures/solar_extended_feature_importance.png)

**Top 10 Features:**
1. `lag_24` (33.2%) - 24h-Zyklus dominiert
2. `rolling_mean_24` (18.7%)
3. `hour` (12.4%) - Tageszeit
4. `lag_1` (8.9%)
5. `rolling_std_24` (6.1%)
6. `diff_24` (4.8%)
7. `month` (3.2%) - Jahreszeit
8. `lag_168` (2.9%) - Wochenmuster
9. `momentum_24h` (2.1%)
10. `rolling_mean_168` (1.8%)

**Interpretation:** 80% der Importance kommt von 24h-Pattern!

### Price (LightGBM)

![Price Feature Importance](results/figures/price_extended_feature_importance.png)

**Top 10 Features:**
1. `diff_1` (28.4%) - Momentum dominiert
2. `lag_1` (22.1%)
3. `momentum_3h` (11.8%)
4. `rolling_std_3` (9.2%) - VolatilitÃ¤t
5. `lag_2` (7.6%)
6. `diff_24` (5.4%)
7. `rolling_mean_3` (4.1%)
8. `hour` (3.8%)
9. `lag_24` (2.9%)
10. `rolling_std_24` (1.7%)

**Interpretation:** Kurzfristige Features (1-3h) dominieren - Preis ist mean-reverting!

---

## Backup 2: Computational Costs

| Modell | Training Time | Inference (1000 samples) | Hardware |
|--------|---------------|--------------------------|----------|
| LightGBM | **~2 min** | **<1s** | CPU |
| XGBoost | ~4 min | <1s | CPU |
| Random Forest | ~6 min | ~2s | CPU |
| SARIMA | ~15 min | ~5s | CPU |
| LSTM (optimized) | **~2 hours** | **~10s** | GPU (Colab T4) |
| VAR (Lag 24) | ~10 min | ~3s | CPU |

**ROI-Betrachtung:**
- LightGBM: Beste Performance/Zeit-Ratio
- LSTM: 60x langsamer fÃ¼r nur +2% RÂ²
- â†’ **In Production: LightGBM first choice**

---

## Backup 3: Alle verfÃ¼gbaren Figuren

```
ğŸ“‚ results/figures/
â”œâ”€â”€ model_comparison_rmse.png           # Alle Modelle RMSE
â”œâ”€â”€ model_comparison_all_metrics.png    # RÂ²/MAPE/RMSE
â”œâ”€â”€ best_per_category.png               # Beste pro Kategorie
â”‚
â”œâ”€â”€ solar_extended_01_timeline.png      # Solar Rohdaten
â”œâ”€â”€ solar_extended_09_final_comparison.png  # Solar alle Modelle
â”œâ”€â”€ solar_extended_feature_importance.png   # Solar Top Features
â”‚
â”œâ”€â”€ wind_offshore_01_timeline.png       # Wind Timeline
â”œâ”€â”€ wind_offshore_timeline_outage.png   # Wind mit Stillstand markiert
â”œâ”€â”€ wind_offshore_09_comparison.png     # Wind alle Modelle
â”‚
â”œâ”€â”€ price_extended_01_timeline.png      # Price Rohdaten
â”œâ”€â”€ price_extended_09_final_comparison.png  # Price alle Modelle
â”œâ”€â”€ price_extended_feature_importance.png   # Price Top Features
â”‚
â”œâ”€â”€ consumption_extended_01_timeline.png    # Consumption Rohdaten
â”œâ”€â”€ consumption_extended_09_final_comparison.png # Consumption Modelle
â”‚
â”œâ”€â”€ wind_onshore_extended_01_timeline.png   # Onshore Rohdaten
â””â”€â”€ wind_onshore_extended_09_final_comparison.png # Onshore Modelle
```

---

## Backup 4: Pipeline Scripts Ãœbersicht

```bash
# Alle vollstÃ¤ndigen Pipelines (Notebooks â†’ Skripte)
ğŸ“‚ scripts/
â”œâ”€â”€ run_solar_extended_pipeline.py          # Solar: VollstÃ¤ndig
â”œâ”€â”€ run_price_extended_pipeline.py          # Price: VollstÃ¤ndig  
â”œâ”€â”€ run_consumption_extended_pipeline.py    # Consumption: VollstÃ¤ndig
â”œâ”€â”€ run_wind_offshore_extended_pipeline.py  # Wind Off: VollstÃ¤ndig
â”œâ”€â”€ run_wind_onshore_extended_pipeline.py   # Wind On: VollstÃ¤ndig
â”‚
# LSTM Optimierungen (Colab Notebooks)
â”œâ”€â”€ LSTM_Optimization_Extended_Colab.ipynb  # âœ… Solar fertig
â”œâ”€â”€ LSTM_Optimization_Colab_wind_offshore.ipynb  # ğŸš§ In Arbeit
â””â”€â”€ optimize_lstm_models.py                 # Utility-Funktionen
```

**Jede Pipeline enthÃ¤lt:**
1. Data Loading & Exploration
2. Preprocessing & Feature Engineering (31 Features)
3. Train/Val/Test Split
4. Baseline Models (5x: Naive, Mean, Seasonal Naive, Drift, Moving Avg)
5. Statistical Models (SARIMA, ETS, SARIMAX)
6. ML Models (XGBoost, LightGBM, Random Forest, CatBoost)
7. Deep Learning (LSTM - in separaten Notebooks optimiert)
8. Results Export (CSV + PNG)

---

## ğŸ“š Referenzen & Quellen

1. **Daten:** SMARD.de, ENTSO-E Transparency Platform, EPEX Spot
2. **Frameworks:** scikit-learn, XGBoost, LightGBM, TensorFlow/Keras, statsmodels
3. **Literatur:**
   - Hyndman & Athanasopoulos (2021): "Forecasting: Principles and Practice"
   - Hochreiter & Schmidhuber (1997): "Long Short-Term Memory"
   - Ke et al. (2017): "LightGBM: A Highly Efficient Gradient Boosting Decision Tree"
4. **VAR/VECM:** LÃ¼tkepohl (2005): "New Introduction to Multiple Time Series Analysis"

---

# ğŸ¤ DANKE FÃœR IHRE AUFMERKSAMKEIT!

**Fragen? Diskussion?**

**Kontakt:** Siehe README.md  
**Code:** Alle Notebooks und Skripte im Repository verfÃ¼gbar  
**Daten:** `data/raw/` (5 CSV-Dateien)  
**Ergebnisse:** `results/` (Metriken + Figuren)

---

## PrÃ¤sentations-Notizen

### Timing (20 Min total)
- **Slides 1-3 (Daten + Preprocessing):** 4 Minuten
  - Slide 1: 1:30 Min - Datenbasis vorstellen
  - Slide 2: 1:30 Min - Feature Engineering erklÃ¤ren
  - Slide 3: 1:00 Min - Wind Offshore Problem zeigen
  
- **Slides 4-8 (Modell-Performance):** 10 Minuten
  - Slide 4: 2:00 Min - Solar als Best Case
  - Slide 5: 2:00 Min - Price als VolatilitÃ¤ts-Challenge
  - Slide 6: 2:00 Min - Wind Offshore als Problemfall
  - Slide 7: 2:00 Min - Consumption & Wind Onshore
  - Slide 8: 2:00 Min - LSTM Deep-Dive
  
- **Slides 9-10 (Kritische Diskussion):** 5 Minuten
  - Slide 9: 2:30 Min - VAR/VECM Analyse
  - Slide 10: 2:30 Min - Lessons Learned + Open Questions
  
- **Q&A:** 1 Minute Buffer

### Wichtige Diskussionspunkte
1. **"Warum ist ML so viel besser?"** â†’ Feature Engineering + Nicht-LinearitÃ¤t
2. **"Ist RÂ²=0.98 realistisch?"** â†’ Ja, aber nur weil `lag_24` so dominant ist
3. **"Wann LSTM nutzen?"** â†’ Nur bei >5 Jahren Daten oder sehr langen Dependencies
4. **"VAR sinnvoll?"** â†’ Theoretisch ja (Granger-KausalitÃ¤t), praktisch nein (RÂ²=0.28)
5. **"NÃ¤chste Schritte?"** â†’ Wetterdaten, Ensembles, Transformer
