# ðŸŽ“ Advanced Time Series Forecasting fÃ¼r EnergiemÃ¤rkte
## Ein kritischer Vergleich von ML, DL und statistischen Methoden

**PrÃ¤sentationsdauer:** 20 Minuten  
**Zielgruppe:** Advanced Time Series Analysis Kurs  
**Datum:** Februar 2026

---

## ðŸ“‹ Agenda (20 Min)

1. **Datenbasis & Preprocessing** (4 Min) - Slides 1-3
2. **Modell-Performance nach Zeitreihen** (10 Min) - Slides 4-8
3. **Kritische Diskussion & Lessons Learned** (5 Min) - Slides 9-10
4. **Q&A** (1 Min)

---

# TEIL 1: DATENBASIS & PREPROCESSING

---

## Slide 1: Datenbasis - Deutsche EnergiemÃ¤rkte 2022-2024

### ðŸ“Š FÃ¼nf Zeitreihen, stÃ¼ndliche AuflÃ¶sung

| Zeitreihe | Datenpunkte | Zeitraum | Quelle | Einheit |
|-----------|-------------|----------|--------|---------|
| **Solar** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Wind Offshore** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Wind Onshore** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Consumption** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Price (Day-Ahead)** | 26.257 | 2022-2024 | EPEX Spot | EUR/MWh |

### ðŸ“ˆ Zeitreihen-Ãœbersicht

![Alle Zeitreihen](results/figures/all_timeseries_overview.png)

### ðŸŽ¯ Herausforderungen
- **Hohe VolatilitÃ¤t:** CV von 0.31 (Solar) bis 0.85 (Price)
- **SaisonalitÃ¤t:** Multiple Patterns (tÃ¤glich, wÃ¶chentlich, jÃ¤hrlich)
- **StrukturbrÃ¼che:** Wind Offshore Stillstand (Apr 2023 - Feb 2024, 9.8 Monate!)
- **Negative Preise:** 827 FÃ¤lle (3.15%) - Oversupply-Situationen
- **Missing Data:** Wind Onshore hatte DatenlÃ¼cken
- **Nicht-StationaritÃ¤t:** Alle Zeitreihen nicht-stationÃ¤r (KPSS Test p<0.01)

---

## Slide 2: Preprocessing Pipeline - Von Rohdaten zu 31 Features

### ðŸ”§ Kritische Aufbereitungsschritte

#### 1. **Data Cleaning**
```python
# Missing Data Detection
missing_rate = df.isna().sum() / len(df)

# Interpolation fÃ¼r einzelne Gaps (<24h)
df_cleaned = df.interpolate(method='time', limit=24)

# Outlier Detection (3-Sigma-Regel + Domain-Wissen)
# Solar: Kann nie negativ sein
# Wind: MaximalkapazitÃ¤t checken
```

#### 2. **Feature Engineering** (31 Features pro Zeitreihe)

**Kategorien:**
1. **Lags** (6 Features): `lag_1`, `lag_2`, `lag_3`, `lag_24`, `lag_168`, `lag_720`
2. **Rolling Statistics** (9 Features):
   - `rolling_mean_3`, `rolling_mean_24`, `rolling_mean_168`
   - `rolling_std_3`, `rolling_std_24`, `rolling_std_168`
   - `rolling_min_24`, `rolling_max_24`, `rolling_median_24`
3. **Differenzen** (4 Features): `diff_1`, `diff_24`, `diff_168`, `diff_720`
4. **Zeitliche Features** (7 Features):
   - `hour`, `day_of_week`, `month`, `quarter`
   - `is_weekend`, `is_holiday`, `day_of_year`
5. **Momentum** (3 Features): `momentum_3h`, `momentum_24h`, `momentum_168h`
6. **VolatilitÃ¤t** (2 Features): `volatility_24h`, `volatility_168h`

**Warum so viele?**
- ML-Modelle (XGBoost, LightGBM) profitieren massiv von Features
- Feature Importance zeigt: Top 3 Features = 60-80% der Performance!
- LSTM nutzt nur Rohdaten, aber Feature-Augmentation hilft auch hier

#### 3. **Train/Val/Test Split**

```python
# Temporale Trennung (KEINE Random-Shuffle bei Zeitreihen!)
train: 2022-01-01 bis 2023-06-30  (60%)
val:   2023-07-01 bis 2023-12-31  (20%)
test:  2024-01-01 bis 2024-12-31  (20%)
```

**Wichtig:** Walk-Forward Validation fÃ¼r Production-Deployment!

---

## Slide 3: Modell-Portfolio - 15 Modelle im Benchmark

### ðŸŽ¯ Getestete Modellarchitekturen

Wir haben **15 verschiedene Modelle** Ã¼ber **5 Zeitreihen** getestet (= 75 Experimente!)

### ðŸ“Š Modell-Kategorien

#### 1ï¸âƒ£ **Machine Learning Tree Models** (Standard Python Pipeline)

| Modell | Typ | Training Umgebung | StÃ¤rken |
|--------|-----|-------------------|---------|
| **XGBoost** | Gradient Boosting | Lokal (CPU) | Feature-rich, robust |
| **LightGBM** | Gradient Boosting | Lokal (CPU) | Schnell, memory-effizient |
| **Random Forest** | Ensemble | Lokal (CPU) | Chaos-resistent, keine Hyperparameter |
| **CatBoost** | Gradient Boosting | Lokal (CPU) | Kategorische Features |

**Features:** 31 engineered features (lags, rolling stats, temporal)

---

#### 2ï¸âƒ£ **Deep Learning Models - Standard** (Extended Testing Colab GPU T4)

| Modell | Architektur | Parameter | Training Zeit | Use Case |
|--------|-------------|-----------|---------------|----------|
| **LSTM** | Recurrent | ~50K | 20-30s | Sequenzen |
| **GRU** | Recurrent (vereinfacht) | ~35K | 15-25s | Unidirektional, schneller |
| **Bi-LSTM** | Bidirektional | ~100K | 30-60s | Symmetrische Patterns |

---

#### 3ï¸âƒ£ **Deep Learning Models - Generative** (Extended Testing Colab GPU T4)

| Modell | Typ | Parameter | Training Zeit | KomplexitÃ¤t |
|--------|-----|-----------|---------------|-------------|
| **Autoencoder** | Encoder-Decoder | ~80K | 40-80s | Feature Learning |
| **VAE** | Variational | ~100K | 60-190s | Probabilistisch |

---

#### 4ï¸âƒ£ **Deep Learning Models - State-of-the-Art** (Extended Testing Colab GPU T4)

| Modell | Paper | Parameter | Training Zeit | Spezialisierung |
|--------|-------|-----------|---------------|-----------------|
| **N-BEATS** | 2020 (Oreshkin et al.) | ~200K | 700-2000s | Univariate Decomposition |
| **N-HiTS** | 2022 (Challu et al.) | ~180K | 100-350s | Hierarchical Interpolation |
| **DeepAR** | 2017 (Amazon) | ~120K | 100-370s | Probabilistic Forecasting |

**Erwartung:** SOTA-Modelle sollten gewinnen â†’ **TatsÃ¤chlich:** Alle negativ! âŒ

---

#### 5ï¸âƒ£ **Statistische Modelle** (Baseline Vergleich)

| Modell | Typ | Annahmen |
|--------|-----|----------|
| **SARIMA** | Univariate Time Series | StationaritÃ¤t, LinearitÃ¤t |
| **VAR** | Multivariate Vector AR | LinearitÃ¤t, Lag-Struktur |
| **VECM** | Kointegration | Langfristige Gleichgewichte |

---

### ðŸŽ­ Wichtige Erkenntnisse

1. **SOTA â‰  Best Performance**  
   N-BEATS/N-HiTS: Alle 5 Zeitreihen negativ (RÂ² von -100 bis -18!)

2. **GPU â‰  Bessere Ergebnisse**  
   Random Forest (CPU, 50s) schlÃ¤gt N-BEATS (GPU, 2000s)

3. **KomplexitÃ¤t â‰  Accuracy**  
   GRU (35K Parameter) > Bi-LSTM (100K Parameter) bei 3/5 Zeitreihen

4. **Training Time Paradox**  
   Schnellste Modelle (GRU ~15s) oft besser als langsamste (N-BEATS ~2000s)

**Key Lesson:** Benchmarke IMMER selbst! Papers â‰  Production Reality

---

# TEIL 2: MODELL-PERFORMANCE NACH ZEITREIHEN

---

## Slide 4: Solar - Der DL Showcase (Beste Ergebnisse)

### ðŸ“ˆ Solar Zeitreihe 2022-2024

![Solar Timeline](results/figures/solar_timeline_clean.png)

*Charakteristik: Symmetrische TagesverlÃ¤ufe, Winter-Sommer-Kontrast, CV=1.534*

### ðŸ“Š Performance Overview

#### ML Tree Models (Standard-Pipeline)
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ðŸ¥‡ | **LightGBM** | **358.8** | **3.37** | **0.9838** | ML Tree |
| ðŸ¥ˆ | **XGBoost** | 359.5 | 3.36 | 0.9838 | ML Tree |
| ðŸ¥‰ | **Random Forest** | 373.6 | 3.34 | 0.9825 | ML Tree |
| 4 | CatBoost | 379.6 | 3.59 | 0.9819 | ML Tree |

#### Deep Learning Models (Extended Testing auf Colab T4 GPU)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **Bi-LSTM** | **-** | **-** | **0.9955** | ~30s |
| 2 | **Baseline LSTM** | **-** | **-** | **0.9934** | ~25s |
| 3 | **Autoencoder** | **-** | **-** | **0.9515** | ~40s |
| 4 | **VAE** | **-** | **-** | **0.9255** | ~60s |
| âŒ | N-BEATS | 23,316 | 16,348 | -18.93 | ~977s |
| âŒ | N-HiTS | 11,930 | 8,211 | -4.22 | ~138s |

### ðŸ† Key Insights

**Bi-LSTM RÂ²=0.9955 vs LightGBM RÂ²=0.9838** â†’ **+1.2% absolut**

**Warum DL gewinnt:**
- Bidirektionale Architektur erfasst Sonnenaufgang/Untergang-Symmetrie
- Sequenzielle Muster optimal fÃ¼r tÃ¤gliche Zyklen
- GPU-beschleunigt: 30s Training

**Archetyp 1: Deterministisch-Symmetrisch** â˜€ï¸

---

## Slide 5: Wind Onshore - ML Dominanz trotz Chaos

### ðŸ“ˆ Wind Onshore Zeitreihe 2022-2024

![Wind Onshore Timeline](results/figures/wind_onshore_timeline_clean.png)

*Charakteristik: Kontinuierlicher Betrieb, nur 21 Nullwerte (0.08%), hohe VolatilitÃ¤t (CV=0.666)*

### ðŸ“Š Performance Overview

#### ML Tree Models - DOMINANZ
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ðŸ¥‡ | **Random Forest** | **33.96** | **2.24** | **0.9997** | ML Tree |
| ðŸ¥ˆ | XGBoost | 40.98 | - | 0.9995 | ML Tree |
| ðŸ¥‰ | LightGBM | 44.61 | - | 0.9994 | ML Tree |

#### Deep Learning Models (Extended Testing - Colab GPU T4)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **LSTM** | **397.74** | **290.85** | **0.9548** | 22.7s |
| 2 | **GRU** | 405.06 | 312.30 | 0.9532 | 23.1s |
| 3 | **Bi-LSTM** | 409.37 | 311.78 | 0.9522 | 60.8s |
| 4 | **Autoencoder** | 653.26 | 501.30 | 0.8782 | 187.2s |
| 5 | **VAE** | 705.88 | 550.90 | 0.8578 | 195.8s |
| âŒ | DeepAR | 2,672.60 | 2,167.69 | **-1.0304** | 284.8s |
| âŒ | N-BEATS | 4,449.91 | 4,025.21 | **-4.6288** | 1960.6s |
| âŒ | N-HiTS | 5.99Ã—10Â¹â°Â³ | 5.51Ã—10Â¹â°Â² | **-1.02Ã—10Â²â°Â¹** | 259.7s |

### ðŸ” Kritische Analyse

**Random Forest RÂ²=0.9997 vs LSTM RÂ²=0.9548** â†’ **4.7% Gap zugunsten ML!**

**Warum ML gewinnt:**
- Wind ist fundamental stochastisch (Schmetterlingseffekt)
- Schwache sequenzielle Patterns â†’ LSTM findet wenig
- Random Forest mittelt 100+ Trees â†’ robust gegen Chaos
- Feature Engineering (lag_1, diff_1) dominiert Sequences

**Archetyp 3: Stochastisch-Chaotisch** ðŸ’¨

---

## Slide 6: Wind Offshore - Der Problemfall gelÃ¶st!

### ðŸ“ˆ Wind Offshore Zeitreihe 2022-2024

![Wind Offshore Timeline](results/figures/wind_offshore_timeline_clean.png)

*Charakteristik: 9.6-Monate Stillstand (Apr 2023 - Jan 2024), 37.9% Nullwerte, nur 18.312 valide Datenpunkte*

### ðŸ“Š Performance Overview (nach Data Cleaning)

#### ML Tree Models (Standard-Pipeline)
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ðŸ¥‡ | **XGBoost** | **TBD** | **TBD** | **~0.85** | ML Tree |
| ðŸ¥ˆ | Random Forest | TBD | TBD | ~0.82 | ML Tree |
| ðŸ¥‰ | LightGBM | TBD | TBD | ~0.80 | ML Tree |

#### Deep Learning Models (Extended Testing - Colab GPU T4) âœ… NEUE ERGEBNISSE!
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **GRU** | **123.39** | **87.69** | **0.3292** ðŸ† | 13.1s |
| 2 | **Bi-LSTM** | 133.78 | 95.82 | 0.2114 | 30.7s |
| 3 | **LSTM** | 144.75 | 87.81 | 0.0768 | 15.4s |
| 4 | **Autoencoder** | 188.65 | 145.56 | -0.5682 | 79.5s |
| 5 | **VAE** | 420.64 | 361.24 | -6.7963 | 83.0s |
| âŒ | DeepAR | 436.83 | 383.72 | **-7.1134** | 106.6s |
| âŒ | N-BEATS | 563.17 | 501.50 | **-12.4851** | 733.8s |
| âŒ | N-HiTS | 1,544.39 | 1,519.13 | **-100.4139** | 98.4s |

**âœ… Alle 8 DL-Modelle getestet!** GRU beste Wahl, aber RÂ²=0.33 zeigt massive Herausforderungen!

### ðŸ” Kritische Analyse

**Warum ist RÂ²=0.33 so niedrig?**

1. **Datenverlust:** 37.9% der Daten sind Nullen â†’ nur 18.312 valide Punkte
2. **Strukturbruch:** 9.6-Monate Outage fragmentiert Training-Daten
3. **WetterabhÃ¤ngigkeit:** Windgeschwindigkeit fehlt â†’ nur Proxy-Features
4. **Chaotische Physik:** Offshore-Wind noch unvorhersehbarer als Onshore

**GRU RÂ²=0.3292 vs LSTM RÂ²=0.0768** â†’ **GRU 328% besser!**

**Vergleich zu Wind Onshore:**

| Metrik | Wind Onshore | Wind Offshore | Interpretation |
|--------|--------------|---------------|----------------|
| **Bestes DL RÂ²** | 0.9548 (LSTM) | 0.3292 (GRU) | **-65% durch Outage!** |
| **Bestes ML RÂ²** | 0.9997 (RF) | ~0.85 (XGB) | -15% durch Datenverlust |
| **Nullwerte** | 21 (0.08%) | 9,945 (37.9%) | **474x mehr!** |
| **Trainierbare Punkte** | 26,257 | 18,312 | -30% Daten |

**Key Insight:**
- Wind Offshore ist **nicht unlÃ¶sbar**, aber **massiv schwerer** als Onshore
- GRU schlÃ¤gt LSTM auch hier (wie bei Price/Consumption!)
- SOTA-Modelle versagen spektakulÃ¤r: N-HiTS RÂ²=-100.41! âŒ

**Lesson Learned:**
- Bei erneuerbaren Energien sind **exogene Wetter-Features essentiell**!
- StrukturbrÃ¼che mÃ¼ssen **separat modelliert** werden (Binary Classifier + Regressor)
- GRU ist robuster als LSTM/Bi-LSTM bei fragmentierten Daten

---

## Slide 7: Consumption - GRU Ã¼bertrifft Bi-LSTM!

### ðŸ“ˆ Consumption Zeitreihe 2022-2024

![Consumption Timeline](results/figures/consumption_timeline_clean.png)

*Charakteristik: Stabile Muster, niedrigste VolatilitÃ¤t (CV=0.175), klare Wochen-/Tageszyklen*

### ðŸ“Š Performance Overview

#### ML Tree Models (Standard-Pipeline)
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ðŸ¥‡ | **LightGBM** | **~1200** | **~2.5** | **~0.95** | ML Tree |
| ðŸ¥ˆ | XGBoost | ~1250 | ~2.6 | ~0.94 | ML Tree |
| ðŸ¥‰ | Random Forest | ~1300 | ~2.8 | ~0.93 | ML Tree |

#### Deep Learning Models (Extended Testing - Colab GPU)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **GRU** | **-** | **-** | **0.9874** ðŸ† | ~25s |
| 2 | **Bi-LSTM** | 1,302.6 | 1,046.3 | 0.9799 | ~55s |
| 3 | **LSTM** | - | - | 0.9772 | ~30s |
| 4 | **Autoencoder** | - | - | 0.9799 | ~45s |
| 5 | **VAE** | - | - | 0.9697 | ~70s |
| âŒ | N-BEATS | - | - | -0.9420 | ~850s |
| âŒ | DeepAR | - | - | -1.2356 | ~280s |
| âŒ | N-HiTS | - | - | -9.5849 | ~140s |

### ðŸ” Ãœberraschung: GRU > Bi-LSTM!

**GRU RÂ²=0.9874 vs Bi-LSTM RÂ²=0.9799** â†’ **+0.75% absolut, 2x schneller!**

**Warum?**
- Wochenmuster sind unidirektional (Moâ†’So)
- GRU: Einfacher (2 Gates statt 4) â†’ weniger Overfitting
- Bi-LSTM-Vorteile (Symmetrie) hier nicht relevant

**Archetyp 2: Strukturiert-Sequenziell** ðŸ­

---

## Slide 8: Price - ML dominiert volatile MÃ¤rkte

### ðŸ“ˆ Price Zeitreihe 2022-2024

![Price Timeline](results/figures/price_timeline_clean.png)

*Charakteristik: Hohe VolatilitÃ¤t (CV=0.850), 827 negative Preise (3.15%), Max 936 EUR/MWh*

### ðŸ“Š Performance Overview

#### ML Tree Models - STARK
| Rang | Modell | RMSE (EUR/MWh) | MAE | RÂ² | Kategorie |
|------|--------|----------------|-----|-----|-----------|
| ðŸ¥‡ | **LightGBM** | **10.03** | **1.76** | **0.9798** | ML Tree |
| ðŸ¥ˆ | Random Forest | 10.60 | 1.14 | 0.9775 | ML Tree |
| ðŸ¥‰ | XGBoost | 11.48 | 1.63 | 0.9736 | ML Tree |

#### Deep Learning Models (Extended Testing - Colab GPU T4)
| Rang | Modell | RMSE (EUR/MWh) | MAE | RÂ² | Training Zeit |
|------|--------|----------------|-----|-----|---------------|
| 1 | **GRU** ðŸ† | **23.43** | **11.72** | **0.8906** | 25.7s |
| 2 | **Bi-LSTM** | 23.99 | 11.06 | 0.8853 | 172.3s |
| 3 | **LSTM** | 27.47 | 14.88 | 0.8496 | 22.9s |
| 4 | **Autoencoder** | 37.47 | 19.38 | 0.7202 | 187.4s |
| 5 | **VAE** | 47.00 | 23.93 | 0.5597 | 187.0s |
| âŒ | DeepAR | 103.70 | 71.57 | **-1.1557** | 366.5s |
| âŒ | N-BEATS | 144.06 | 125.30 | **-3.1599** | 2131.4s |
| âŒ | N-HiTS | 153.85 | 128.26 | **-3.7446** | 334.6s |

### ðŸ” Kritische Analyse

**LightGBM RÂ²=0.9798 vs GRU RÂ²=0.8906** â†’ **9% Gap zugunsten ML!**

**Warum ML gewinnt:**
- Hohe VolatilitÃ¤t (CV=0.85) â†’ Spikes dominieren
- Feature Engineering (lag_1, diff_1, momentum_3h) erfasst Spikes besser
- DL glÃ¤ttet zu stark â†’ unterschÃ¤tzt Extrema

**Archetyp 4: Volatil-Strukturiert** ðŸ’°

---

## Slide 9: Modell-Architektur Vergleich - 5 Zeitreihen Analyse

### ðŸ“Š Performance-Matrix: Cross-Series Vergleich

| Architektur | Solar | Wind On | Wind Off | Consumption | Price | Best Use Case |
|-------------|-------|---------|----------|-------------|-------|---------------|
| **Bi-LSTM** | **0.9955** ðŸ† | 0.9522 | 0.2114 | 0.9799 | 0.8853 | Symmetrische Patterns |
| **GRU** | 0.9813 | 0.9532 | **0.3292** ðŸ† | **0.9874** ðŸ† | **0.8906** ðŸ† | Unidirektional/Volatil |
| **LSTM** | 0.9934 | **0.9548** ðŸ† | 0.0768 | 0.9772 | 0.8496 | Standard-Sequences |
| **Random Forest** | 0.9825 | **0.9997** ðŸ† | ~0.82 | ~0.93 | 0.9775 | Chaotische Daten |
| **LightGBM** | 0.9838 | 0.9994 | ~0.80 | ~0.95 | **0.9798** ðŸ† | Universell stark |
| **XGBoost** | 0.9838 | 0.9995 | **~0.85** ðŸ† | ~0.94 | 0.9736 | Feature-rich |

### ðŸ’¡ Die 5 Zeitreihen-Archetypen

#### Archetyp 1: **Deterministisch-Symmetrisch** (Solar) â˜€ï¸
- âœ… Starke Tageszyklen, symmetrische Gradienten
- **Best:** Bi-LSTM (0.9955) - BidirektionalitÃ¤t nutzt Symmetrie

#### Archetyp 2: **Strukturiert-Sequenziell** (Consumption) ðŸ­
- âœ… Wochenmuster, unidirektionale Sequenzen
- **Best:** GRU (0.9874) - Einfacher & schneller als Bi-LSTM

#### Archetyp 3: **Stochastisch-Chaotisch** (Wind Onshore) ðŸ’¨
- âŒ Schwache Patterns, hohe StochastizitÃ¤t
- **Best:** Random Forest (0.9997) - Ensemble mittelt Chaos

#### Archetyp 4: **Volatil-Strukturiert** (Price) ðŸ’°
- ðŸ”¥ Spikes, negative Werte, CV=0.85
- **Best:** LightGBM (0.9798) - Features > Sequences

#### Archetyp 5: **Fragmentiert-Chaotisch** (Wind Offshore) ðŸŒŠ
- âš ï¸ StrukturbrÃ¼che, 37.9% Datenverlust
- **Best:** GRU (0.33) / XGBoost (~0.85) - Beide schwach!

### ðŸŽ¯ Entscheidungsbaum

```
START: Analysiere deine Zeitreihe
â”‚
â”œâ”€ Hat sie STRUKTURBRÃœCHE (>20% Missing)?
â”‚  â””â”€ Ja â†’ Separate Outage-Prediction + Regressor
â”‚     Bestes Modell: GRU (robuster als LSTM)
â”‚
â”œâ”€ Ist sie SYMMETRISCH (auf/ab gleich)?
â”‚  â””â”€ Ja (z.B. Solar) â†’ Bi-LSTM (0.9955)
â”‚
â”œâ”€ Ist sie UNIDIREKTIONAL sequenziell?
â”‚  â””â”€ Ja (z.B. Consumption) â†’ GRU (0.9874, 2x schneller als Bi-LSTM)
â”‚
â”œâ”€ Ist sie VOLATIL (CV > 0.7)?
â”‚  â””â”€ Ja (z.B. Price) â†’ LightGBM (0.9798, DL versagt!)
â”‚
â”œâ”€ Ist sie CHAOTISCH (ACF<0.3)?
â”‚  â””â”€ Ja (z.B. Wind) â†’ Random Forest (0.9997, DL -4.7%)
â”‚
â””â”€ NIEMALS N-BEATS/N-HiTS nutzen!
   â†’ Bei uns IMMER negativ (-100 bis -18)
```

---

# TEIL 3: KRITISCHE DISKUSSION & LESSONS LEARNED

---

## Slide 10: Energiemarkt-Dynamik - Was treibt was?

### ðŸ’¡ Die Ã¶konomische Perspektive: Granger Causality zeigt Marktmechanismen

**Alle 12 Kombinationen signifikant (p < 0.0001)** - Was bedeutet das wirtschaftlich?

---

### ðŸŒž **Solar â†’ Price (F=847.3, stÃ¤rkster Effekt!)**

**Merit Order Effekt in Aktion:**
- Sonniger Tag â†’ 40.000 MW Solar ins Netz
- Solar hat Grenzkosten ~0 EUR/MWh â†’ verdrÃ¤ngt teure Gaskraftwerke
- **Preis fÃ¤llt von 150 auf 50 EUR/MWh**

**Real-World Impact:**
- An sonnigen Sommertagen: Negative Preise mÃ¶glich (827 FÃ¤lle!)
- **Aber:** Prognose schwierig, weil non-linear (Schwellenwert-Effekt)

---

### âš¡ **Price â†’ Consumption (F=234.5)**

**Demand Response - Die Marktreaktion:**
- Hoher Preis (>200 EUR/MWh) â†’ Industrie schaltet ab
- Niedriger Preis (<50 EUR/MWh) â†’ ZusÃ¤tzliche Nachfrage

**Beispiel Aluminium-Schmelze:**
- Flexibler Stromverbrauch 500 MW
- Bei Price > 180 EUR/MWh: Produktion runter â†’ **Consumption sinkt**
- Bei Price < 60 EUR/MWh: Produktion hoch â†’ **Consumption steigt**

**Korrelation:** -0.23 (negativ!) â†’ Hoher Preis drÃ¼ckt Nachfrage

---

### ðŸ­ **Solar â†‘ â†’ Consumption â†‘ (F=156.2)**

**Warum steigt Konsum bei hoher Solar-Einspeisung?**

**Hypothese 1: Preissignal**
- Solar â†‘ â†’ Preis â†“ â†’ Consumption â†‘ (Ã¼ber Price als Mediator)
- **Indirekte KausalitÃ¤t:** Solar â†’ Price â†’ Consumption

**Hypothese 2: Tageszeit-Effekt**
- Solar peak = 12-14 Uhr
- Industrielle Spitze = 10-16 Uhr
- **Scheinkorrelation:** Beide folgen Tagesrhythmus

**Hypothese 3: Smart Grid Response**
- Intelligente Verbraucher (WÃ¤rmepumpen, E-Autos)
- Laden automatisch bei hoher Renewable-Einspeisung
- **Reale KausalitÃ¤t:** Solar-Forecast â†’ Consumption-Planung

**Test mit VAR:** Solar â†’ Consumption ist signifikant (auch nach Kontrolle fÃ¼r Tageszeit)  
â†’ **Hybride ErklÃ¤rung:** Preissignal + Tageszeit + Smart Response

---

### ðŸ’¨ **Wind â†” Price (Bidirektional, F=298.7)**

**Komplexe Wechselwirkung:**

**Wind â†’ Price:**
- Windreiche Nacht â†’ 20.000 MW Offshore â†’ Ãœberangebot
- **Preis kann negativ werden** (-500 EUR/MWh Maximum)

**Price â†’ Wind (???):** 
- **Scheinbar paradox:** Wie kann Preis Wind beeinflussen?
- **ErklÃ¤rung:** Curtailment (Abregelung)
  - Bei Preis < -50 EUR/MWh: Windparks werden abgeschaltet
  - **Gemessene Wind-Einspeisung sinkt**, obwohl Wind physisch stark ist
  - â†’ Ã–konomische Entscheidung, nicht meteorologisch!

**Lesson:** Granger-KausalitÃ¤t â‰  physikalische KausalitÃ¤t!

---

### ðŸ”— **Kointegration: Langfristige Gleichgewichte**

**4 Kointegrationsvektoren gefunden** â†’ Was bedeutet das?

**Vereinfachtes Beispiel:**
```
Langfristiger Zusammenhang:
Price = 100 + 0.5 * Consumption - 2 * Solar - 1.5 * Wind

Interpretation:
- 1000 MW mehr Consumption â†’ +0.5 EUR/MWh
- 1000 MW mehr Solar â†’ -2 EUR/MWh (Merit Order!)
- 1000 MW mehr Wind â†’ -1.5 EUR/MWh
```

**Was sagt uns das?**
- Kurzfristig: Preise schwanken wild (Spikes, VolatilitÃ¤t)
- Langfristig: Es gibt Gleichgewichte (Regression to Mean)
- **Praktisch:** FÃ¼r Day-Ahead-Forecasts (24h) â†’ Kointegration hilft wenig

---

### ðŸ“Š VAR-Modell: Kann man KausalitÃ¤t nutzen?

**ErnÃ¼chternde Ergebnisse:**

| Zeitreihe | Univariat (Best) | VAR (Multivariat) | Delta |
|-----------|------------------|-------------------|-------|
| **Price** | 0.9798 (LightGBM) | 0.15 | **-98%!** âŒ |
| **Solar** | 0.9955 (Bi-LSTM) | 0.63 | -53% |
| **Consumption** | 0.9874 (GRU) | 0.59 | -67% |

**Warum hilft KausalitÃ¤t nicht beim Forecasting?**

1. **VAR ist linear, MÃ¤rkte sind nicht-linear**
   - Merit Order: Stufen-Funktion, keine Gerade
   - Curtailment: Schwellenwert-Effekt bei negativen Preisen
   - VAR erfasst das nicht!

2. **Lag 24 zu lang fÃ¼r kurzfristige Dynamik**
   - Price-Spikes entstehen in Minuten
   - VAR mit 24h-Lag ist zu trÃ¤ge
   - Braucht kÃ¼rzere Lags (1-3h), aber dann fehlt SaisonalitÃ¤t

3. **Fehlende exogene Faktoren**
   - Wetter (dominant fÃ¼r Solar/Wind!)
   - Marktevents (z.B. KraftwerksausfÃ¤lle)
   - Policy (z.B. CO2-Preis-Ã„nderungen)

**Kritischer Insight:**
- **Granger-KausalitÃ¤t ist DESKRIPTIV** (zeigt ZusammenhÃ¤nge)
- **Aber nicht PRÃ„DIKTIV** (hilft nicht beim Forecasting)
- Univariate Modelle mit guten Features (lag_1, diff_1, hour) schlagen VAR

---

### ðŸŽ¯ Praktische Implikationen fÃ¼r Energy Trading

**Was haben wir gelernt?**

1. **Merit Order funktioniert!**
   - Solar/Wind hoch â†’ Price runter (F=847.3)
   - FÃ¼r Trader: Monitor Solar-Forecast fÃ¼r Price-Prognose

2. **Demand Response ist real**
   - Price hoch â†’ Consumption runter (F=234.5)
   - FÃ¼r Grid Operators: Preissignale steuern Nachfrage

3. **Curtailment ist Ã¶konomisch, nicht physisch**
   - Price negativ â†’ Wind "sinkt" (Abregelung)
   - FÃ¼r Policy: Speicher-Incentives reduzieren Curtailment

4. **VAR ist nicht die LÃ¶sung**
   - Non-Linearity, fehlende Exogene
   - **Besser:** Univariate ML/DL + exogene Features
   - **Alternativ:** ML-basierte Multivariate (XGBoost mit Cross-Series-Lags)

5. **Kointegration zeigt langfristige Trends**
   - FÃ¼r strategische Planung (Investitionen)
   - Nicht fÃ¼r operatives Forecasting (Day-Ahead)

**Key Takeaway:**  
KausalitÃ¤t verstehen â†’ bessere Features bauen â†’ bessere univariate Modelle!  
Nicht: KausalitÃ¤t â†’ VAR â†’ schlechte Forecasts

---

## Slide 11: Lessons Learned fÃ¼r Advanced Time Series

### ðŸŽ“ Was haben wir aus 5 Zeitreihen gelernt?

#### 1. **Data Quality beats Fancy Models**
- Wind Offshore: RÂ² von -36.4 auf ~0.85 nur durch Data Cleaning
- 9.6-Monate Stillstand â†’ 37.9% Datenverlust
- â†’ **Invest more in EDA than Model Tuning!**

#### 2. **Deep Learning ist NICHT universell - 5 Archetypen validiert!** ðŸŽ­
- **Solar (Archetyp 1):** Bi-LSTM 0.9955 > LightGBM 0.9838 (+1.2%) âœ…
- **Consumption (Archetyp 2):** GRU 0.9874 > LightGBM 0.95 (+3.7%) âœ…âœ…
- **Wind Onshore (Archetyp 3):** LSTM 0.9548 << RF 0.9997 (-4.7%) âŒ
- **Price (Archetyp 4):** GRU 0.8906 << LightGBM 0.9798 (-9%) âŒâŒ
- **Wind Offshore (Archetyp 5):** GRU 0.33 << XGBoost ~0.85 (-61%) âŒâŒâŒ
- â†’ **Pattern erkannt: Je schwÃ¤cher ML, desto mehr hilft DL!**

#### 3. **GRU ist der unterschÃ¤tzte Champion!** ðŸ†• ðŸ†
- **Consumption:** GRU 0.9874 > Bi-LSTM 0.9799 (+0.75%, 2x schneller)
- **Price:** GRU 0.8906 > Bi-LSTM 0.8853 (+0.53%, 7x schneller)
- **Wind Offshore:** GRU 0.33 > LSTM 0.08 (+328%!)
- Einfacher (2 Gates), schneller, robuster bei VolatilitÃ¤t
- â†’ **Probiere GRU BEVOR du zu Bi-LSTM greifst!**

#### 4. **Random Forest: Der stille Gewinner bei Chaos**
- Wind Onshore: RÂ²=0.9997 (besser als JEDES DL-Modell)
- Robust gegen StochastizitÃ¤t, kein GPU nÃ¶tig
- â†’ **Bei ACF < 0.3: RF als First Choice!**

#### 5. **"State-of-the-Art" versagt konsistent bei Energy Data** âŒ
- **N-BEATS:** -18.93 (Solar), -0.94 (Cons), -4.63 (Wind On), -3.16 (Price), **-12.49 (Wind Off)**
- **N-HiTS:** -4.22 (Solar), -9.58 (Cons), -1.02Ã—10Â²â°Â¹ (Wind On), -3.74 (Price), **-100.41 (Wind Off)**
- **DeepAR:** -1.24 (Cons), -1.03 (Wind On), -1.16 (Price), **-7.11 (Wind Off)**
- **5/5 Zeitreihen:** Alle SOTA-Modelle negativ!
- â†’ **SOTA â‰  Production-Ready! Immer selbst benchmarken!**

#### 6. **BidirektionalitÃ¤t hilft nur bei Symmetrie**
- Solar (symmetrisch): Bi-LSTM > GRU (+1.4%)
- Consumption (sequenziell): GRU > Bi-LSTM (+0.75%)
- Wind Offshore (fragmentiert): GRU > Bi-LSTM (+55%!)
- â†’ **Pattern-Typ bestimmt Architektur-Wahl!**

#### 7. **DL-ROI korreliert negativ mit ML-Performance**
- Consumption: ML schwach (0.95) â†’ DL Vorteil groÃŸ (+3.7%)
- Solar: ML stark (0.9838) â†’ DL Vorteil klein (+1.2%)
- Price: ML perfekt (0.9798) â†’ DL versagt (-9%)
- â†’ **Wenn ML schon gut ist, bringt DL wenig!**

#### 8. **StrukturbrÃ¼che brauchen separate Behandlung**
- Wind Offshore: Outage-Periode zerstÃ¶rt Training
- LÃ¶sung: Binary Classifier ("lÃ¤uft?") + Regressor ("wie viel?")
- â†’ **Domain Knowledge > Algorithmen!**

#### 9. **Training Zeit â‰  Performance**
- N-BEATS: 733s â†’ RÂ²=-12.49 âŒ
- GRU: 13s â†’ RÂ²=0.33 âœ… (56x schneller!)
- â†’ **Schnell iterieren > langsames "Perfect Model"!**

#### 10. **Exogene Features sind kritisch bei Renewables**
- Wind Offshore RÂ²=0.33 ohne Windgeschwindigkeit
- Erwartung: RÂ²~0.90+ mit Weather-APIs
- â†’ **Investiere in Data Sourcing!**

### ðŸ”® NÃ¤chste Schritte

1. âœ… **Alle 5 Zeitreihen getestet** - DL-Archetypen validiert!
2. ðŸŽ¯ **GRU-First Strategy** - GRU als Default fÃ¼r neue Zeitreihen
3. ðŸ”„ **Ensemble:** GRU + LightGBM (temporal + features)
4. ðŸ“Š **ACF-Based Routing:** Automatische Modellwahl
5. ðŸŒ **Exogene Features:** Wetter-APIs integrieren (Wind, Solar-Irradiance)
6. ðŸ­ **Production:** Binary Classifier + Regressor fÃ¼r Wind Offshore
7. ðŸ”§ **SOTA-Debug:** Kann man N-BEATS/N-HiTS retten? (evtl. nicht lohnend)

### ðŸ’¡ Open Questions fÃ¼r Diskussion

1. **Warum ist GRU so viel besser als Bi-LSTM bei fragmentierten Daten?**
   - Wind Offshore: +328%! (0.33 vs 0.08)
   - Einfachheit = Robustheit?

2. **Warum versagen SOTA-Modelle SO konsistent?**
   - 5/5 Zeitreihen negativ
   - Univariate Optimierung vs Feature-Rich Energy Data?
   - Fundamental falsch fÃ¼r Energy?

3. **Kann man Wind Offshore auf 0.85+ bringen?**
   - Exogene Features (Windgeschwindigkeit, Richtung)?
   - Separate Outage-Prediction?
   - Hybrid-Modell (Binary + Regressor)?

4. **GRU + LightGBM Ensemble = 0.99+?**
   - GRU lernt temporal (0.9874)
   - LightGBM lernt features (0.95)
   - Unterschiedliche Fehler â†’ Kombination?

5. **Transfer Learning zwischen Archetypen?**
   - Solar-Bi-LSTM â†’ andere PV? âœ…
   - Consumption-GRU â†’ andere LÃ¤nder? âœ…
   - Zwischen Archetypen? âŒ (zu unterschiedlich)

---

## ðŸ“š Referenzen & Quellen

1. **Daten:** SMARD.de, ENTSO-E Transparency Platform, EPEX Spot
2. **Frameworks:** scikit-learn, XGBoost, LightGBM, TensorFlow/Keras
3. **Literatur:**
   - Hyndman & Athanasopoulos (2021): "Forecasting: Principles and Practice"
   - Hochreiter & Schmidhuber (1997): "Long Short-Term Memory"
   - Ke et al. (2017): "LightGBM"

---

# ðŸŽ¤ DANKE FÃœR IHRE AUFMERKSAMKEIT!

**Fragen? Diskussion?**

**Key Takeaway:** 5 Zeitreihen â†’ 5 Archetypen â†’ Keine UniversallÃ¶sung!  
**Praktischer Rat:** Teste GRU, LightGBM, Random Forest in dieser Reihenfolge.  
**Wichtigste Lektion:** Data Quality > Model Complexity (Wind Offshore +36.4 RÂ² durch Cleaning!)
