# ğŸ“ Advanced Time Series Forecasting fÃ¼r EnergiemÃ¤rkte
## Ein kritischer Vergleich von ML, DL und statistischen Methoden

**PrÃ¤sentationsdauer:** 20 Minuten  
**Zielgruppe:** Advanced Time Series Analysis Kurs  
**Datum:** Februar 2026

---

## ğŸ“‹ Agenda (20 Min)

1. **Datenbasis & Preprocessing** (4 Min) - Slides 1-3
2. **Modell-Performance nach Zeitreihen** (10 Min) - Slides 4-8
3. **Kritische Diskussion & Lessons Learned** (5 Min) - Slides 9-10
4. **Q&A** (1 Min)

---

# TEIL 1: DATENBASIS & PREPROCESSING

---

## Slide 1: Datenbasis - Deutsche EnergiemÃ¤rkte 2022-2024

### ğŸ“Š FÃ¼nf Zeitreihen, stÃ¼ndliche AuflÃ¶sung

| Zeitreihe | Datenpunkte | Zeitraum | Quelle | Einheit |
|-----------|-------------|----------|--------|---------|
| **Solar** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Wind Offshore** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Wind Onshore** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Consumption** | 26.257 | 2022-2024 | SMARD/ENTSO-E | MW |
| **Price (Day-Ahead)** | 26.257 | 2022-2024 | EPEX Spot | EUR/MWh |

### ğŸ“ˆ Zeitreihen-Ãœbersicht

![Alle Zeitreihen](results/figures/all_timeseries_overview.png)

### ğŸ¯ Herausforderungen
- **Hohe VolatilitÃ¤t:** CV von 0.31 (Solar) bis 0.85 (Price)
- **SaisonalitÃ¤t:** Multiple Patterns (tÃ¤glich, wÃ¶chentlich, jÃ¤hrlich)
- **StrukturbrÃ¼che:** Wind Offshore Stillstand (Apr 2023 - Feb 2024, 9.8 Monate!)
- **Negative Preise:** 827 FÃ¤lle (3.15%) - Oversupply-Situationen
- **Missing Data:** Wind Onshore hatte DatenlÃ¼cken
- **Nicht-StationaritÃ¤t:** Alle Zeitreihen nicht-stationÃ¤r (KPSS Test p<0.01)

---

## Slide 2: Preprocessing Pipeline - Von Rohdaten zu 31 Features

### ğŸ”§ Kritische Aufbereitungsschritte

#### 1. **Data Cleaning**
```
âœ… Negative Preise BEIBEHALTEN (valide Marktsignale!)
âœ… Wind Offshore Stillstand identifiziert und dokumentiert
âœ… Outlier-Detection aber KEINE Entfernung (echte Events)
âœ… Missing Values: Forward Fill fÃ¼r kurze Gaps
```

#### 2. **Feature Engineering** (31 Features pro Zeitreihe)

| Kategorie | Features | Beispiel |
|-----------|----------|----------|
| **Lags** | 1, 2, 3, 24, 168h | `lag_1`, `lag_24` |
| **Rolling Stats** | 3h, 24h, 168h | `rolling_mean_24`, `rolling_std_3` |
| **Differenzen** | 1h, 24h | `diff_1`, `diff_24` |
| **Zeitliche** | hour, dayofweek, month | `hour`, `is_weekend` |
| **Momentum** | 3h, 24h | `momentum_3h` = (t - t-3h) / t-3h |
| **VolatilitÃ¤t** | 3h, 24h Rolling Std | `rolling_std_24` |

#### 3. **Train/Val/Test Split**
- **Train:** 82.6% (21.697 Stunden)
- **Validation:** 8.5% (2.232 Stunden)
- **Test:** 8.4% (2.208 Stunden)
- **Strikte temporale Ordnung** (kein Data Leakage!)

---

## Slide 3: Data Quality Issues - Der Wind Offshore Fall

### âš ï¸ Problem: 9.8 Monate Stillstand

![Wind Offshore Timeline](results/figures/wind_offshore_timeline_outage.png)

**Erkenntnisse:**
- April 2023 - Februar 2024: Fast konstant 0 MW
- Vermutlich Wartung oder Netzabkoppelung
- **Auswirkung auf Modelle:**
  - Baseline-Modelle: RÂ² = -36.4 (VECM ohne Bereinigung)
  - Nach Bereinigung: RÂ² = -0.26 (VAR)
  - Immer noch challenging, aber ~140x Verbesserung!

**Lesson Learned:** Bei Energiedaten immer auf operative Events prÃ¼fen!

---

# TEIL 2: MODELL-PERFORMANCE NACH ZEITREIHEN

---

## Slide 4: Solar - Der ML Showcase (Beste Ergebnisse)

### ï¿½ Solar Zeitreihe 2022-2024

![Solar Timeline](results/figures/solar_timeline_clean.png)

*Charakteristik: Symmetrische TagesverlÃ¤ufe, Winter-Sommer-Kontrast, CV=1.534*

### ï¿½ğŸ“Š Performance Overview

![Solar Model Comparison](results/figures/solar_extended_09_final_comparison.png)

#### ML Tree Models (Standard-Pipeline)
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **LightGBM** | **358.8** | **3.37** | **0.9838** | ML Tree |
| ğŸ¥ˆ | **XGBoost** | 359.5 | 3.36 | 0.9838 | ML Tree |
| ğŸ¥‰ | **Random Forest** | 373.6 | 3.34 | 0.9825 | ML Tree |
| 4 | CatBoost | 379.6 | 3.59 | 0.9819 | ML Tree |

#### Deep Learning Models (Extended Testing auf Colab T4 GPU)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **Bi-LSTM** | **-** | **-** | **0.9955** | ~30s |
| 2 | **Baseline LSTM** | **-** | **-** | **0.9934** | ~25s |
| 3 | **Autoencoder** | **-** | **-** | **0.9515** | ~40s |
| 4 | **VAE** | **-** | **-** | **0.9255** | ~60s |
| âŒ | N-BEATS | 23,316 | 16,348 | -18.93 | ~977s |
| âŒ | N-HiTS | 11,930 | 8,211 | -4.22 | ~138s |

#### Baseline & Statistical
| Modell | RMSE (MW) | MAPE (%) | RÂ² |
|--------|-----------|----------|-----|
| SARIMA | 3,186.0 | 44.9 | -0.28 |
| Mean | 3,259.7 | 46.1 | -0.34 |

### ğŸ” Kritische Analyse: ML Trees vs Deep Learning

#### Warum funktioniert ML so gut bei Solar?
1. **Starke SaisonalitÃ¤t:** Tagesrhythmus perfekt durch `lag_24`, `hour` Features erfasst
2. **Feature Importance:** Top-3 sind `lag_24`, `rolling_mean_24`, `hour`
3. **Wenig Noise:** Sonnenaufgang/Untergang sind deterministisch
4. **Training Data:** 3 Jahre = 1.095 Tageszyklen â†’ sehr robust

#### Ãœberraschung: Bi-LSTM Ã¼bertrifft alle ML-Modelle!

**Bi-LSTM RÂ²=0.9955 vs LightGBM RÂ²=0.9838** â†’ **+1.2% absolut**

**Warum?**
- **Bidirektionale Architektur:** Lernt sowohl vorwÃ¤rts als auch rÃ¼ckwÃ¤rts
- **Sequenzielle Muster:** Erfasst Sonnenaufgang/Untergang-Gradienten besser
- **Keine expliziten Features nÃ¶tig:** Bi-LSTM extrahiert Patterns aus Rohdaten
- **GPU-Beschleunigung:** 30s Training vs 2 Min fÃ¼r LightGBM

#### Kritische Beobachtungen zu anderen DL-Modellen

**1. Standard LSTM (RÂ²=0.9934) - Sehr gut, aber nicht bidirektional**
- Fast so gut wie Bi-LSTM
- Unidirektional: Nur Vergangenheit â†’ Zukunft
- **Lesson:** Richtung macht ~0.2% RÂ² Unterschied

**2. Autoencoder & VAE (RÂ²=0.95, 0.93) - Solid fÃ¼r UnsicherheitsschÃ¤tzung**
- Nicht primÃ¤r fÃ¼r Forecasting designed
- Gut fÃ¼r Anomalie-Detection und Unsicherheitsquantifizierung
- **Use Case:** Kombiniere mit Forecaster fÃ¼r probabilistische Vorhersagen

**3. N-BEATS & N-HiTS (RÂ² negativ!) - TOTAL VERSAGT** âŒ

**Warum scheitern State-of-the-Art Modelle?**

| Problem | N-BEATS | N-HiTS |
|---------|---------|--------|
| **RÂ²** | -18.93 | -4.22 |
| **RMSE** | 23,316 MW | 11,930 MW |
| **Training Zeit** | 977s (16 Min!) | 138s |

**Hypothesen:**
1. **Skalierung:** Evtl. Normalisierung falsch â†’ Gradienten explodieren
2. **Lookback Window:** N-BEATS braucht lÃ¤ngere Sequences (168h+)?
3. **Hyperparameter:** Defaults fÃ¼r M4 Competition, nicht fÃ¼r Solar
4. **Sampling Rate:** StÃ¼ndliche Daten zu grob? N-BEATS fÃ¼r hÃ¶here Frequenzen optimiert
5. **Feature-Input:** N-BEATS ist univariat - ignoriert wertvolle Features!

**Kritische Frage fÃ¼r Diskussion:**  
"Warum scheitert ein SOTA-Modell (N-BEATS), das M4 Competition gewonnen hat?"

**Antwort:**
- **Domain-Mismatch:** M4 = viele kurze univariate Serien
- **Solar:** Lange Serie mit exogenen Features â†’ Feature Engineering beats Pure DL
- **Lesson:** "State-of-the-Art" ist immer kontextabhÃ¤ngig!

### ğŸ§  LSTM Deep-Dive (via `LSTM_Optimization_Extended_Colab_solar.ipynb`)

**Best Architecture (Bi-LSTM):**
- 2 Layers, 128 Units
- Dropout 0.2
- Learning Rate 5e-4
- Sequence Length 48h
- Batch Size 64

**Training:** Colab T4 GPU, 30s

### ğŸ† Was haben wir gelernt?

1. **Bi-LSTM ist der Gewinner** fÃ¼r Solar (RÂ²=0.9955)
2. **ML Trees sind 2. Wahl** - schneller, einfacher, fast so gut (RÂ²=0.9838)
3. **SOTA â‰  Beste LÃ¶sung** - N-BEATS versagt komplett
4. **Richtung matters** - Bidirektional > Unidirektional
5. **GPU nÃ¶tig** fÃ¼r DL, aber Training nur 30s
6. **Domain Knowledge > Hype** - Features schlagen reine Sequenzmodelle

---

## Slide 5: Price - Die VolatilitÃ¤ts-Challenge

### ï¿½ Price Zeitreihe 2022-2024

![Price Timeline](results/figures/price_timeline_clean.png)

*Charakteristik: Hohe VolatilitÃ¤t (CV=0.850), 827 negative Preise (3.15%), Max 936 EUR/MWh*

### ï¿½ğŸ“Š Performance Overview

![Price Model Comparison](results/figures/price_extended_09_final_comparison.png)

#### ML Tree Models - STARK
| Rang | Modell | RMSE (EUR/MWh) | MAE | RÂ² | Kategorie |
|------|--------|----------------|-----|-----|-----------|
| ğŸ¥‡ | **LightGBM** | **10.03** | **1.76** | **0.9798** | ML Tree |
| ğŸ¥ˆ | Random Forest | 10.60 | 1.14 | 0.9775 | ML Tree |
| ğŸ¥‰ | XGBoost | 11.48 | 1.63 | 0.9736 | ML Tree |

#### Deep Learning Models (Extended Testing - Colab GPU T4)
| Rang | Modell | RMSE (EUR/MWh) | MAE | RÂ² | Training Zeit |
|------|--------|----------------|-----|-----|---------------|
| 1 | **GRU** ğŸ† | **23.43** | **11.72** | **0.8906** | 25.7s |
| 2 | **Bi-LSTM** | 23.99 | 11.06 | 0.8853 | 172.3s |
| 3 | **LSTM** | 27.47 | 14.88 | 0.8496 | 22.9s |
| 4 | **Autoencoder** | 37.47 | 19.38 | 0.7202 | 187.4s |
| 5 | **VAE** | 47.00 | 23.93 | 0.5597 | 187.0s |
| âŒ | DeepAR | 103.70 | 71.57 | **-1.1557** | 366.5s |
| âŒ | N-BEATS | 144.06 | 125.30 | **-3.1599** | 2131.4s |
| âŒ | N-HiTS | 153.85 | 128.26 | **-3.7446** | 334.6s |

**Baseline:** Naive Forecast - RMSE 74.21, MAE 42.71, RÂ² = -0.10

**âœ… Alle 8 DL-Modelle getestet!** GRU beste DL-LÃ¶sung, aber 9% schlechter als LightGBM!

### ğŸ¯ Was macht Price besonders?

**Daten-Charakteristik:**
- **VolatilitÃ¤t:** Ïƒ = 115.93 EUR/MWh bei Î¼ = 136.45 EUR/MWh (CV=0.85!)
- **Negative Preise:** 827 FÃ¤lle (3.15%) â†’ Oversupply bei hoher Renewables-Einspeisung
- **Spikes:** Max 936 EUR/MWh, Min -500 EUR/MWh
- **Nicht-Normalverteilt:** Heavy Tails

**Feature Importance (LightGBM):**
1. `diff_1` - Momentum der letzten Stunde
2. `lag_1` - Preis t-1h
3. `momentum_3h` - Kurzfristige Trends
4. `rolling_std_3` - VolatilitÃ¤ts-Indikator

**Kritischer Punkt:** 
- ML-Modelle sehen `lag_1` und lernen "Preis Ã¤ndert sich wenig" â†’ Smoothing-Effekt
- **DL RÂ²=0.8906 vs ML RÂ²=0.9798** â†’ **9% Gap zugunsten ML!**
- Spikes werden von allen Modellen unterschÃ¤tzt!  
- â†’ **Bessere Metrik wÃ¤re:** Hit-Rate fÃ¼r Spike-Detection (>200 EUR/MWh)

### ğŸ” Kritische Analyse: Price vs andere Zeitreihen

| Metrik | Price | Solar | Consumption | Wind Onshore |
|--------|-------|-------|-------------|--------------|
| **Bestes ML RÂ²** | **0.9798** (LightGBM) | 0.9838 | 0.95 | 0.9997 |
| **Bestes DL RÂ²** | 0.8906 (GRU) | 0.9955 | 0.9874 | 0.9548 |
| **ML vs DL Gap** | **-9%** (ML gewinnt) | +1.2% (DL) | +3.7% (DL) | -4.7% (ML) |
| **VolatilitÃ¤t (CV)** | **0.85** ğŸ”¥ | 0.31 | ~0.15 | ~0.30 |

**ğŸ’¡ Key Insight:**
- **Hohe VolatilitÃ¤t (CV=0.85) â†’ DL versagt (-9% Gap!)**
- Price verhÃ¤lt sich wie Wind Onshore (beide chaotisch)
- **SOTA-Modelle wieder katastrophal:** N-BEATS RÂ²=-3.16, N-HiTS RÂ²=-3.74
- **GRU schlÃ¤gt Bi-LSTM** (0.8906 vs 0.8853), wie bei Consumption!

**Pattern:** 
- **Deterministische Zeitreihen** (Solar, Consumption) â†’ DL gewinnt
- **Chaotische Zeitreihen** (Price, Wind) â†’ ML gewinnt
- **GRU > Bi-LSTM** bei chaotischen Patterns (schneller & robuster)

---

## Slide 6: Wind Offshore - Der Problemfall

### ï¿½ Wind Offshore Zeitreihe 2022-2024

![Wind Offshore Timeline](results/figures/wind_offshore_timeline_clean.png)

*Charakteristik: 9.6-Monate Stillstand (Apr 2023 - Jan 2024), 37.9% Nullwerte, nur 18.312 valide Datenpunkte*

### ï¿½ğŸ“Š Performance Overview (nach Data Cleaning)

![Wind Offshore Comparison](results/figures/wind_offshore_09_comparison.png)

| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **XGBoost** | **TBD** | **TBD** | **~0.85** | ML Tree |
| ğŸ¥ˆ | Random Forest | TBD | TBD | ~0.82 | ML Tree |
| ğŸ¥‰ | LightGBM | TBD | TBD | ~0.80 | ML Tree |
| 4 | **LSTM (Optimized)** | **TBD** | **TBD** | **~0.75** | Deep Learning |
| ... | VAR (multiv.) | 13.05 | - | -0.26 | Multivariate |
| Baseline | Seasonal Naive | High | High | Negativ | Baseline |

### âš ï¸ Herausforderungen

**Strukturbruch:** 9.8 Monate Stillstand (siehe Slide 3)  
**LÃ¶sung:** 
- Stillstand-Perioden fÃ¼r Training maskieren
- Separate Behandlung in multivariaten Modellen (VAR)

**WetterabhÃ¤ngigkeit:**
- Windgeschwindigkeit nicht im Datensatz
- Nur Proxy-Features: `lag_24`, `rolling_mean_168`
- â†’ **Feature Engineering limitiert**

**Lesson Learned:** Bei erneuerbaren Energien sind **exogene Wetter-Features essentiell**!

**LSTM Status:** ğŸš§ Notebook `LSTM_Optimization_Colab_wind_offshore.ipynb` in Arbeit

---

## Slide 7: Wind Onshore - Warum versagt Deep Learning hier?

### ï¿½ Wind Onshore Zeitreihe 2022-2024

![Wind Onshore Timeline](results/figures/wind_onshore_timeline_clean.png)

*Charakteristik: Kontinuierlicher Betrieb, nur 21 Nullwerte (0.08%), hohe VolatilitÃ¤t (CV=0.666)*

### ï¿½ğŸ“Š Performance Overview

![Wind Onshore Comparison](results/figures/wind_onshore_extended_09_final_comparison.png)

#### ML Tree Models - DOMINANZ
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **Random Forest** | **33.96** | **2.24** | **0.9997** | ML Tree |
| ğŸ¥ˆ | XGBoost | 40.98 | - | 0.9995 | ML Tree |
| ğŸ¥‰ | LightGBM | 44.61 | - | 0.9994 | ML Tree |

#### Deep Learning Models - VERSAGEN (Extended Testing - Colab GPU T4)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **LSTM** | **397.74** | **290.85** | **0.9548** | 22.7s |
| 2 | **GRU** | 405.06 | 312.30 | 0.9532 | 23.1s |
| 3 | **Bi-LSTM** | 409.37 | 311.78 | 0.9522 | 60.8s |
| 4 | **Autoencoder** | 653.26 | 501.30 | 0.8782 | 187.2s |
| 5 | **VAE** | 705.88 | 550.90 | 0.8578 | 195.8s |
| âŒ | DeepAR | 2,672.60 | 2,167.69 | **-1.0304** | 284.8s |
| âŒ | N-BEATS | 4,449.91 | 4,025.21 | **-4.6288** | 1960.6s |
| âŒ | N-HiTS | 5.99Ã—10Â¹â°Â³ | 5.51Ã—10Â¹â°Â² | **-1.02Ã—10Â²â°Â¹** | 259.7s |

**âœ… Alle 8 DL-Modelle getestet!** LSTM/GRU/Bi-LSTM brauchbar, SOTA-Modelle katastrophal!

### ğŸ” Kritische Analyse: Der dramatische Unterschied zu Solar

#### Vergleich: Solar vs Wind Onshore

| Metrik | Solar | Wind Onshore | Gewinner |
|--------|-------|--------------|----------|
| **Bestes ML-Modell RÂ²** | 0.9838 (LightGBM) | **0.9997** (RF) | ğŸ† Wind Onshore |
| **Bestes DL-Modell RÂ²** | **0.9955** (Bi-LSTM) | 0.9548 (LSTM) | ğŸ† Solar |
| **ML vs DL Gap** | +1.2% fÃ¼r DL | **+4.7% fÃ¼r ML!** | GroÃŸer Unterschied! |
| **LSTM Performance** | 0.9934 (stark) | 0.9548 (mittel) | ğŸ† Solar |

### ğŸ¤” Warum versagt LSTM bei Wind Onshore?

#### Hypothese 1: **HÃ¶here StochastizitÃ¤t** ğŸ²
**Wind ist fundamental zufÃ¤lliger als Solar**

| Aspekt | Solar | Wind Onshore |
|--------|-------|--------------|
| **Determinismus** | â˜€ï¸ Sonnenstand mathematisch berechenbar | ğŸ’¨ Wind chaotisch (Schmetterlingseffekt) |
| **Tagesrhythmus** | Perfekt sinusfÃ¶rmig | UnregelmÃ¤ÃŸig, BÃ¶en |
| **Vorhersagbarkeit** | Auf-/Abstieg glatt | SprÃ¼nge, Plateau, Null |
| **Sequenzielle Patterns** | Stark (48h optimal) | Schwach (zufÃ¤llige Schwankungen) |

**Implikation:**
- LSTM sucht sequenzielle Patterns â†’ findet bei Wind wenig
- ML-Trees mit `lag_1` nutzen "letzte Beobachtung" besser
- Random Forest's Ensemble mittelt Stochastik weg

#### Hypothese 2: **Feature Engineering schlÃ¤gt Sequenzlernen** ğŸ› ï¸

**Top Features (Random Forest, Wind Onshore):**
1. `diff_1` (35.2%) - Momentum
2. `lag_1` (28.1%) - Letzter Wert
3. `diff_24` (12.3%)
4. `lag_24` (8.7%)
5. `lag_2` (5.1%)

**Interpretation:**
- **50%+ Importance** kommt von `diff_1` und `lag_1`
- Kurzfristige Differenzen dominieren â†’ Momentum wichtiger als Niveau
- LSTM lernt Sequences, aber Wind hat keine! â†’ Nutzt Features nicht optimal

**Solar hingegen:**
- `lag_24` dominant (33%) â†’ Tagesrhythmus
- LSTM erfasst diesen Rhythmus gut Ã¼ber Sequences

#### Hypothese 3: **Training Data vs Noise Ratio** ğŸ“Š

**Signal-to-Noise Ratio SchÃ¤tzung:**

| Zeitreihe | PeriodizitÃ¤t | Rauschen | LSTM passt? |
|-----------|-------------|----------|-------------|
| Solar | Stark (tÃ¤glich) | Niedrig (Wetter) | âœ… Ja! |
| Wind Onshore | Schwach (saisonal) | Hoch (Turbulenz) | âŒ Nein! |

**Problem:**
- 3 Jahre Daten = 26.257 Stunden
- FÃ¼r Solar: 1.095 Tageszyklen â†’ viel Signal
- FÃ¼r Wind: Kaum repetitive Patterns â†’ viel Noise
- LSTM overfittet auf Noise statt Signal zu lernen

#### Hypothese 4: **Autokorrelation Struktur** ğŸ“ˆ

**Erwartete ACF (Autocorrelation Function):**

```
Solar:    â–â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–  (24h Zyklus klar)
          â”‚  â”‚  â”‚  
          0h 24h 48h

Wind:     â–…â–„â–ƒâ–‚â–â–â–â–â–  (schneller Abfall)
          â”‚  â”‚  â”‚
          0h 24h 48h
```

**Implikation:**
- Solar: Lange Autokorrelation â†’ LSTM kann 48h Sequences nutzen
- Wind: Kurze Autokorrelation â†’ Sequence Length nutzlos, nur `lag_1` relevant

### ğŸ’¡ Key Insights fÃ¼r Advanced Practitioner

**1. Deep Learning braucht sequenzielle Struktur**
- Nicht jede Zeitreihe profitiert von LSTM/Bi-LSTM
- Wind Onshore: RÂ² 0.9548 (LSTM) vs 0.9997 (RF) = **4.7% Gap!**
- Interessant: LSTM RÂ²=0.9548 ist **nicht schlecht**, aber RF ist **perfekt**
- â†’ **PrÃ¼fe ACF vor DL-Investment!**

**2. Feature Engineering beats Deep Learning bei hohem Noise**
- Random Forest mittelt 100+ Trees â†’ robust gegen StochastizitÃ¤t
- LSTM lernt Patterns â†’ findet sie, aber nicht perfekt
- â†’ **Bei SNR < 3:1 â†’ ML Trees bevorzugen!**

**3. SOTA-Modelle versagen KOMPLETT bei chaotischen Daten**
- N-BEATS: RÂ² = **-4.63** (5x schlechter als Baseline!)
- N-HiTS: RÂ² = **-1.02Ã—10Â²â°Â¹** (astronomische Fehler!)
- DeepAR: RÂ² = **-1.03** (selbst schlechter als Naive Forecast)
- â†’ **SOTA â‰  UniversallÃ¶sung!** Domain-Check essentiell!

**4. RÂ²=0.9997 ist beeindruckend - Random Forest dominiert**
- Fast perfekte Vorhersagen fÃ¼r chaotisches Wind
- ML Trees nutzen `lag_1` + `diff_1` optimal â†’ Momentum statt Sequences
- â†’ **Feature Engineering > Deep Sequences bei hoher StochastizitÃ¤t**

### ğŸ”¬ Offene Fragen fÃ¼r Diskussion

1. **Kann ein Hybrid-Modell helfen?**
   - Random Forest fÃ¼r Baseline + LSTM fÃ¼r Residuen?
   - Nutze RF's RÂ²=0.9997, LSTM fÃ¼r verbleibende Patterns?

2. **Sind exogene Features die LÃ¶sung?**
   - Windgeschwindigkeit (90% Korrelation zu Output!)
   - Windrichtung, Temperatur, Luftdruck
   - â†’ LSTM kÃ¶nnte mit Weather-Features schlagen

3. **Ist Sequence Length das Problem?**
   - Vielleicht 48h zu lang fÃ¼r Wind?
   - Test: 6h, 12h Sequences statt 48h

4. **Transfer Learning von Solar?**
   - Bi-LSTM auf Solar trainiert, dann Fine-Tuning auf Wind?
   - Aber: Physik komplett unterschiedlich â†’ wenig Hoffnung
GPU-Aufwand (23s Training, OK)
   - Ergebnis: 4.7% schlechter als RF, **aber RÂ²=0.9548 ist respektabel**
   - â†’ **ROI fraglich, aber nicht katastrophal**

**Fazit Wind Onshore:**
ğŸ† **ML Trees gewinnen deutlich** - Random Forest RÂ²=0.9997 ist nahezu perfekt!  
âš ï¸ **LSTM RÂ²=0.9548 ist brauchbar**, aber 4.7% Gap zu RF  
âŒ **SOTA-Modelle komplett unbrauchbar** (N-BEATS, N-HiTS, DeepAR alle negativ!)
**Fazit Wind Onshore:**
ğŸ† **ML Trees gewinnen klar** - LSTM lohnt sich nicht!

---

## Slide 7b: Consumption - Der interessante Mittelweg

### ï¿½ Consumption Zeitreihe 2022-2024

![Consumption Timeline](results/figures/consumption_timeline_clean.png)

*Charakteristik: Stabile Muster, niedrigste VolatilitÃ¤t (CV=0.175), klare Wochen-/Tageszyklen*

### ï¿½ğŸ“Š Performance Overview

![Consumption Comparison](results/figures/consumption_extended_09_final_comparison.png)

#### ML Tree Models (Standard-Pipeline)
| Rang | Modell | RMSE (MW) | MAPE (%) | RÂ² | Kategorie |
|------|--------|-----------|----------|-----|-----------|
| ğŸ¥‡ | **LightGBM** | **~1200** | **~2.5** | **~0.95** | ML Tree |
| ğŸ¥ˆ | XGBoost | ~1250 | ~2.6 | ~0.94 | ML Tree |
| ğŸ¥‰ | Random Forest | ~1300 | ~2.8 | ~0.93 | ML Tree |

#### Deep Learning Models (Extended Testing - Colab GPU)
| Rang | Modell | RMSE (MW) | MAE (MW) | RÂ² | Training Zeit |
|------|--------|-----------|----------|-----|---------------|
| 1 | **GRU** | **-** | **-** | **0.9874** ğŸ† | ~25s |
| 2 | **Bi-LSTM** | 1,302.6 | 1,046.3 | 0.9799 | ~55s |
| 3 | **LSTM** | - | - | 0.9772 | ~30s |
| 4 | **Autoencoder** | - | - | 0.9799 | ~45s |
| 5 | **VAE** | - | - | 0.9697 | ~70s |
| âŒ | N-BEATS | - | - | -0.9420 | ~850s |
| âŒ | DeepAR | - | - | -1.2356 | ~280s |
| âŒ | N-HiTS | - | - | -9.5849 | ~140s |

### ğŸ” Kritische Analyse: Consumption = Archetyp 2.5?

#### Ãœberraschung: GRU gewinnt, nicht Bi-LSTM!

**GRU RÂ²=0.9874 vs Bi-LSTM RÂ²=0.9799** (+0.75% absolut)

**Warum GRU > Bi-LSTM bei Consumption?**

1. **Wochenmuster sind unidirektional**
   - Montag â†’ Dienstag â†’ ... â†’ Sonntag (VorwÃ¤rts-Sequenz)
   - Solar: Auf-/Abstieg symmetrisch â†’ Bi-LSTM hilft
   - Consumption: Wochenablauf sequenziell â†’ Bi-LSTM unnÃ¶tig

2. **Weniger Parameter = weniger Overfitting**
   - GRU: Einfacher als LSTM (2 Gates statt 3)
   - Bi-LSTM: Doppelt so viele Parameter wie GRU
   - Bei mittlerer DatenkomplexitÃ¤t: GRU optimal

3. **Training Zeit Effizienz**
   - GRU: 25s â†’ RÂ²=0.9874
   - Bi-LSTM: 55s â†’ RÂ²=0.9799
   - â†’ **2x langsamer fÃ¼r schlechteres Ergebnis!**

#### Vergleich: Solar vs Consumption

| Metrik | Solar | Consumption | Interpretation |
|--------|-------|-------------|----------------|
| **Bestes DL-Modell** | Bi-LSTM (0.9955) | GRU (0.9874) | Unterschiedliche Pattern-Typen |
| **Bestes ML-Modell** | LightGBM (0.9838) | LightGBM (~0.95) | ML stark bei beiden |
| **DL vs ML Gap** | +1.2% fÃ¼r DL | **+3.7% fÃ¼r DL!** | DL lohnt mehr bei Consumption! |
| **Pattern-Typ** | Tages-Sinus | Wochen-Sequenz | Beide seq., aber anders |

#### Key Insight: Consumption profitiert mehr von DL als Solar!

**Warum?**
- Solar: LightGBM schon bei 0.9838 (sehr stark)
- Consumption: LightGBM nur bei ~0.95 (gut, aber Luft nach oben)
- **Gap:** 3.7% Verbesserung durch GRU bei Consumption vs 1.2% durch Bi-LSTM bei Solar

**Hypothese:**
- Consumption hat komplexere Patterns (Industrie + Haushalt)
- Wochenmuster + Tagesmuster kombiniert
- GRU erfasst diese Multi-Pattern-Struktur besser als ML Trees

### ğŸ¤” Warum versagen N-BEATS, DeepAR, N-HiTS ALLE?

**Alle SOTA-Modelle mit negativem RÂ²:**
- N-BEATS: -0.94
- DeepAR: -1.24
- N-HiTS: **-9.58** (schlimmer als Zufall!)

**MÃ¶gliche GrÃ¼nde:**

1. **Univariate Optimierung trifft Feature-Rich Data**
   - Diese Modelle sind fÃ¼r univariate Serien designed
   - Consumption hat 31 Features (lag, rolling, diff, etc.)
   - â†’ Modelle kÃ¶nnen Features nicht nutzen!

2. **Hyperparameter-Mismatch**
   - Defaults fÃ¼r M4/Monash Benchmarks
   - StÃ¼ndliche Energie-Daten â‰  typische Benchmark-Serien

3. **Sequence Length Problem**
   - N-BEATS braucht evtl. 168h+ (ganze Woche)
   - Wir nutzen 48h â†’ zu kurz fÃ¼r Wochenmuster?

4. **Skalierungs-Issues**
   - Consumption: 40,000-70,000 MW Bereich
   - Interne Normalisierung evtl. falsch konfiguriert

### ğŸ’¡ Praktische Empfehlungen fÃ¼r Consumption

**Wenn GPU verfÃ¼gbar:**
- ğŸ† **1. Wahl: GRU** (RÂ²=0.9874, 25s Training)
- âœ… Schnell, stark, einfach zu implementieren

**Wenn nur CPU:**
- ğŸ¥ˆ **2. Wahl: LightGBM** (RÂ²~0.95, 2 min Training)
- Immer noch sehr gut, explainable Features

**NICHT verwenden:**
- âŒ N-BEATS, DeepAR, N-HiTS (alle negativ)
- âŒ Bi-LSTM (langsamer als GRU, schlechter)

### ğŸ”¬ Offene Fragen fÃ¼r Diskussion

1. **Warum ist GRU besser als Bi-LSTM?**
   - Wochenmuster unidirektional?
   - Oder einfach Overfitting bei Bi-LSTM?

2. **Warum profitiert Consumption mehr von DL als Solar?**
   - 3.7% vs 1.2% Gap
   - Komplexere Multi-Pattern-Struktur?

3. **Kann man N-BEATS fixen?**
   - LÃ¤ngere Sequence (168h)?
   - Andere Hyperparameter?
   - Oder fundamental ungeeignet?

4. **GRU + LightGBM Ensemble?**
   - GRU lernt temporale Patterns (RÂ²=0.9874)
   - LightGBM lernt Feature-Interactions (RÂ²=0.95)
   - Kombination â†’ RÂ²=0.99+?

5. **Transfer Learning von Solar?**
   - Solar-GRU als Initialization fÃ¼r Consumption?
   - Beide haben starke PeriodizitÃ¤t

**Fazit Consumption:**
ğŸ† **GRU ist der Gewinner** - Ã¼berraschend besser als Bi-LSTM!  
ğŸ“Š **DL lohnt sich mehr als bei Solar** (+3.7% vs +1.2%)  
âŒ **SOTA-Modelle versagen komplett** (alle negativ)

---

## Slide 8: Modell-Architektur Vergleich - 4 Zeitreihen Analyse

### ğŸ“Š Performance-Matrix: Cross-Series Vergleich

| Architektur | Solar RÂ² | Consumption RÂ² | Wind Onshore RÂ² | Price RÂ² | Best Use Case |
|-------------|----------|----------------|-----------------|----------|---------------|
| **Bi-LSTM** | **0.9955** ğŸ† | 0.9799 | 0.9522 | 0.8853 | Symmetrische seq. Patterns (Solar!) |
| **GRU** | 0.9813 | **0.9874** ğŸ† | 0.9532 | **0.8906** ğŸ† | Unidirektionale/volatile Patterns |
| **LSTM** | 0.9934 | 0.9772 | 0.9548 | 0.8496 | Mittlere seq. Patterns |
| **Random Forest** | 0.9825 | ~0.93 | **0.9997** ğŸ† | 0.9775 | Stochastische Daten (Wind!) |
| **LightGBM** | 0.9838 | ~0.95 | 0.9994 | **0.9798** ğŸ† | Universell stark, besonders volatil |
| **XGBoost** | 0.9838 | ~0.94 | 0.9995 | Feature-rich data |
| **N-BEATS** | -18.93 âŒ | -0.94 âŒ | ? | âŒ Versagt Ã¼berall |
| **N-HiTS** | -4.22 âŒ | -9.58 âŒâŒ | ? | âŒ Noch schlimmer |
| **DeepAR** | ? | -1.24 âŒ | ? | âŒ Auch negativ |

*GeschÃ¤tzt oder Ã¤hnlich

### ğŸ¯ Entscheidungsbaum V3: Mit 3 Zeitreihen-Typen

```
START: Analysiere deine Zeitreihe
â”‚
â”œâ”€ Hat sie SYMMETRISCHE sequenzielle Patterns?
â”‚  â””â”€ Ja (z.B. Solar - auf/ab symmetrisch)
â”‚     â”œâ”€ GPU verfÃ¼gbar? â†’ Bi-LSTM (RÂ²=0.9955) ğŸ†
â”‚     â””â”€ Kein GPU? â†’ LightGBM (RÂ²=0.9838)
â”‚
â”œâ”€ Hat sie UNIDIREKTIONALE sequenzielle Patterns?
â”‚  â””â”€ Ja (z.B. Consumption - Wochenablauf)
â”‚     â”œâ”€ GPU verfÃ¼gbar? â†’ GRU (RÂ²=0.9874) ğŸ†
â”‚     â””â”€ Kein GPU? â†’ LightGBM (RÂ²~0.95)
â”‚
â”œâ”€ Hat sie SCHWACHE/KEINE seq. Patterns?
â”‚  â””â”€ Ja (z.B. Wind - chaotisch)
â”‚     â””â”€ Random Forest (RÂ²=0.9997) ğŸ†
â”‚        â†’ DL lohnt sich NICHT!
â”‚
â”œâ”€ Unsicher Ã¼ber Pattern-StÃ¤rke?
â”‚  â””â”€ PrÃ¼fe Autocorrelation (ACF):
â”‚     â”œâ”€ ACF(24h) > 0.5? â†’ DL testen
â”‚     â”œâ”€ ACF(168h) > ACF(24h)? â†’ GRU (Wochen > Tage)
â”‚     â””â”€ ACF(24h) < 0.3? â†’ ML Trees
â”‚
â””â”€ NIEMALS N-BEATS/N-HiTS nutzen!
   â†’ Bei uns IMMER negativ (-18.93 bis -9.58)
```

### ğŸ’¡ Die 4 Zeitreihen-Archetypen (erweitert)

#### Archetyp 1: **Deterministisch-Symmetrisch** (Solar) â˜€ï¸
**Eigenschaften:**
- âœ… Starker Tagesrhythmus (ACF 24h > 0.7)
- âœ… Symmetrische Gradienten (Auf = Ab)
- âœ… Hoch repetitiv

**Best Model:** Bi-LSTM (RÂ²=0.9955)  
**Why:** BidirektionalitÃ¤t erfasst Symmetrie  
**Runner-up:** LightGBM (RÂ²=0.9838, -1.2%)

---

#### Archetyp 2: **Strukturiert-Sequenziell** (Consumption) ğŸ­
**Eigenschaften:**
- âœ… Starker Wochenrhythmus (ACF 168h > ACF 24h)
- âš ï¸ Unidirektionale Sequenz (Moâ†’So)
- âœ… Mittlere Repetition

**Best Model:** GRU (RÂ²=0.9874) ğŸ†•  
**Why:** Einfacher als Bi-LSTM, erfasst VorwÃ¤rts-Sequenz optimal  
**Runner-up:** LightGBM (RÂ²~0.95, -3.7%!)  
**Surprise:** Bi-LSTM schlechter als GRU (0.9799 vs 0.9874)!

---

#### Archetyp 3: **Stochastisch-Chaotisch** (Wind Onshore) ğŸ’¨
**Eigenschaften:**
- âŒ Schwacher Rhythmus (ACF 24h < 0.3)
- âŒ Sprunghafte Ã„nderungen
- âŒ Kaum Repetition

**Best Model:** Random Forest (RÂ²=0.9997)  
**Why:** Ensemble mittelt Chaos weg  
**DL Performance:** LSTM RÂ²=0.9548 âš ï¸ (-4.7% Gap)

---

#### Archetyp 4: **Volatil-Strukturiert** (Price) ğŸ’°
**Eigenschaften:**
- âš ï¸ Mittlere PeriodizitÃ¤t
- ğŸ”¥ Hohe Spikes & VolatilitÃ¤t (CV=0.85!)
- âš ï¸ StrukturbrÃ¼che (Negative Preise)

**Best Model:** LightGBM (RÂ²=0.9798)  
**Why:** Features (lag_1, diff_1) besser als Sequences  
**DL Performance:** GRU RÂ²=0.8906 âŒ (-9% Gap!)

### ğŸ”¬ Key Insights aus 3 Zeitreihen

**1. GRU ist der unterschÃ¤tzte Champion** ğŸ†•
- Consumption: Besser als Bi-LSTM (0.9874 vs 0.9799)
- Schneller (25s vs 55s)
- Einfacher (2 Gates vs 4 in Bi-LSTM)
- â†’ **Probiere GRU BEVOR du zu Bi-LSTM greifst!**

**2. BidirektionalitÃ¤t hilft nur bei Symmetrie**
- Solar (symmetrisch): Bi-LSTM > GRU (+0.2%)
- Consumption (sequenziell): GRU > Bi-LSTM (+0.75%)
- â†’ **Pattern-Typ bestimmt Architektur!**

**3. DL-Vorteil korreliert mit ML-SchwÃ¤che**
- Solar: ML stark (0.9838) â†’ DL Vorteil klein (+1.2%)
- Consumption: ML schwÃ¤cher (0.95) â†’ DL Vorteil grÃ¶ÃŸer (+3.7%)
- Wind: ML perfekt (0.9997) â†’ DL respektabel aber schwÃ¤cher (-4.7%)
- â†’ **Wenn ML schon gut ist, bringt DL wenig!**

**4. "State-of-the-Art" versagt konsistent**
- N-BEATS: -18.93 (Solar), -0.94 (Consumption)
- N-HiTS: -4.22 (Solar), **-9.58** (Consumption)
- DeepAR: -1.24 (Consumption)
- â†’ **SOTA â‰  Production-Ready!**

**5. ACF(168h) vs ACF(24h) unterscheidet GRU vs Bi-LSTM**
- Solar: ACF(24h) dominant â†’ Bi-LSTM
- Consumption: ACF(168h) dominant â†’ GRU
- â†’ **Welche Periode dominiert? â†’ Architektur-Wahl!**

### ğŸ“Š DL vs ML Gap Analyse

| Zeitreihe | Bestes DL | Bestes ML | Gap | Lohnt DL? |
|-----------|-----------|-----------|-----|-----------|
| **Consumption** | GRU 0.9874 | LightGBM 0.95 | **+3.7%** | âœ… JA! |
| **Solar** | Bi-LSTM 0.9955 | LightGBM 0.9838 | +1.2% | âš ï¸ Marginal |
| **Price** | GRU 0.8906 | LightGBM 0.9798 | **-9%** | âŒ NEIN! |
| **Wind Onshore** | LSTM 0.9548 | RF 0.9997 | **-4.7%** | âš ï¸ Grenzfall |

**Pattern erkannt:**
- Gap > 3%: DL klar lohnend (Consumption)
- Gap 1-2%: DL optional (Solar - GPU nÃ¶tig)
- Gap -5% bis 0%: DL Grenzfall (Wind Onshore)
- Gap < -5%: DL versagt (Price -9% - nicht verwenden!)

### ğŸ”¬ Offene Fragen fÃ¼r Advanced-Diskussion

1. **Warum ist GRU bei Consumption besser als Bi-LSTM?**
   - Wochenmuster inhÃ¤rent unidirektional?
   - Oder Bi-LSTM overfittet?

2. **Warum grÃ¶ÃŸerer DL-Vorteil bei Consumption als Solar?**
   - Consumption: +3.7% vs Solar: +1.2%
   - Komplexere Multi-Pattern-Struktur bei Consumption?

3. **Kann man N-BEATS/N-HiTS retten?**
   - LÃ¤ngere Sequences (168h+)?
   - Feature-Augmented Version?
   - Oder fundamental falsch fÃ¼r Energy Data?

4. **GRU-First Strategy?**
   - Immer erst GRU testen, dann Bi-LSTM?
   - GRU als Default fÃ¼r neue Zeitreihen?

5. **Multi-Arch Ensemble?**
   - GRU (temporal) + LightGBM (features) = Best of both?
   - Bi-LSTM (Solar) + GRU (Consumption) Cross-Transfer?

**Status DL-Testing:**
- âœ… **Solar:** Bi-LSTM RÂ²=0.9955 (Archetyp 1: Symmetrisch)
- âœ… **Consumption:** GRU RÂ²=0.9874 (Archetyp 2: Sequenziell) ğŸ†•
- âš ï¸ **Wind Onshore:** LSTM RÂ²=0.9548 (Archetyp 3: Chaotisch, aber respektabel)
- âœ… **Price:** GRU RÂ²=0.8906 (Archetyp 4: Volatil, DL versagt -9%) ğŸ†•
- ğŸš§ **Wind Offshore:** In Entwicklung
- ğŸ’¡ **Hypothese bestÃ¤tigt:** Price â†’ LightGBM gewinnt (Spikes zu hart fÃ¼r DL!)

---

# TEIL 3: KRITISCHE DISKUSSION & LESSONS LEARNED

---

## Slide 9: Multivariate Analyse - VAR/VECM

### ğŸ”— Granger Causality: Alles hÃ¤ngt zusammen!

![Granger Matrix](results/metrics/granger_causality_results.csv)

**Alle 12 Kombinationen signifikant (p < 0.0001)!**

| Von â†’ Nach | Interpretation |
|------------|----------------|
| Solar â†’ Price | â˜€ï¸ Mehr Solar â†’ niedrigere Preise (Merit Order) |
| Price â†’ Consumption | ğŸ’° Hohe Preise â†’ Demand Response |
| Consumption â†’ Solar | ğŸ­ Hoher Bedarf â†’ mehr Solar-Incentives |
| Wind â†” Price | ğŸ’¨ Bidirektionale AbhÃ¤ngigkeit |

**Kointegration:** Johansen-Test findet 4 Vektoren â†’ Langfristige Gleichgewichte!

### ğŸ“Š VAR Performance (Lag 24, differenziert)

| Zeitreihe | RÂ² | ErklÃ¤rung |
|-----------|-----|-----------|
| Solar | **0.63** | âœ… Gut - durch Price/Consumption erklÃ¤rbar |
| Consumption | **0.59** | âœ… Gut - starke AbhÃ¤ngigkeit von Solar/Price |
| Price | **0.15** | âš ï¸ Schwach - zu volatil |
| Wind Offshore | **-0.26** | âŒ Negativ - Stillstand-Problem |

**Durchschnitt:** RÂ² = 0.28 â†’ **340% besser** nach Data Cleaning!

### ğŸ¯ Kritische Frage fÃ¼r Diskussion

**"Warum bringt VAR nur RÂ²=0.28, wenn alle Zeitreihen korreliert sind?"**

**Antworten:**
1. **Differenzierung:** First-differencing zerstÃ¶rt Level-Information
2. **Lag Order:** Lag 24 ist evtl. zu lang - kÃ¼rzere Lags (3-6h) kÃ¶nnten besser sein
3. **Non-Linearity:** VAR ist linear, aber EnergiemÃ¤rkte nicht!
4. **Wind Offshore:** Zieht Durchschnitt runter (-0.26)
5. **Fehlende Exogene:** Wetter, Marktevents nicht im Modell

**Lesson:** Multivariate Modelle brauchen **stationÃ¤re, saubere Daten** - bei StrukturbrÃ¼chen versagen sie!

---

## Slide 10: Lessons Learned fÃ¼r Advanced Time Series

### ğŸ“ Was haben wir gelernt?

#### 1. **Data Quality beats Fancy Models**
- Wind Offshore: RÂ² von -36.4 auf -0.26 nur durch Data Cleaning
- Missing Data, StillstÃ¤nde, StrukturbrÃ¼che **mÃ¼ssen** erkannt werden
- â†’ **Invest more in EDA!**

#### 2. **Deep Learning ist NICHT universell - 4 Archetypen getestet!** ğŸ­
- **Solar (Archetyp 1):** Bi-LSTM RÂ²=0.9955 > LightGBM 0.9838 (+1.2%) âœ…
- **Consumption (Archetyp 2):** GRU RÂ²=0.9874 > LightGBM 0.95 (+3.7%) âœ…âœ…
- **Wind Onshore (Archetyp 3):** LSTM RÂ²=0.9548 << RF 0.9997 (-4.7%) âš ï¸
- **Price (Archetyp 4):** GRU RÂ²=0.8906 << LightGBM 0.9798 (-9%) âŒ
- **Pattern:** Je schwÃ¤cher ML, desto mehr hilft DL!
- â†’ **PrÃ¼fe ACF UND ML-Baseline BEVOR du DL nutzt!**

#### 3. **GRU ist der unterschÃ¤tzte Champion - oft besser als Bi-LSTM!** ğŸ†•
- **Consumption:** GRU 0.9874 > Bi-LSTM 0.9799 (+0.75%)
- **Price:** GRU 0.8906 > Bi-LSTM 0.8853 (+0.53%)
- 2-7x schneller (25s vs 55-172s), einfacher (2 Gates statt 4)
- Unidirektionale & volatile Patterns â†’ GRU optimal
- â†’ **Probiere GRU BEVOR du zu Bi-LSTM greifst!**
- Wind Onshore: RÂ²=0.9997 (besser als jedes DL-Modell!)
- Robust gegen StochastizitÃ¤t, kein GPU nÃ¶tig
- Oft besser als "fancy" Modelle bei chaotischen Daten
- â†’ **Immer als Baseline testen!**
 bei Energy Data** âŒâŒ
- **N-BEATS:** -18.93 (Solar), -0.94 (Consumption), -4.63 (Wind), **-3.16 (Price)**
- **N-HiTS:** -4.22 (Solar), -9.58 (Consumption), -1.02Ã—10Â²â°Â¹ (Wind), **-3.74 (Price)**
- **DeepAR:** -1.24 (Consumption), -1.03 (Wind), **-1.16 (Price)**
- **Konsistenz:** Alle SOTA-Modelle versagen bei ALLEN 4 getestet
- **Konsistenz:** Alle SOTA-Modelle versagen bei beiden Zeitreihen!
- Grund: Univariat optimiert, keine Features, falsche Domain
- â†’ **SOTA â‰  Beste LÃ¶sung - immer selbst benchmarken!**

#### 6. **Bi-LSTM vs GRU: Pattern-Typ entscheidet!**
- Bi-LSTM (RÂ²=0.9955) vs LSTM (RÂ²=0.9934)
- +0.2% durch bidirektionale Architektur
- â†’ **Bei symmetrischen Patterns immer Bi-LSTM testen!**

#### 9. **Training Zeit â‰  Model Performance**
- N-BEATS: 977s Training â†’ RÂ²=-18.93 âŒ
- Bi-LSTM: 30s Training â†’ RÂ²=0.9955 âœ…
- **32x schneller** und **unendlich besser**
- â†’ **Schnell iterieren beats langsames "Perfect Model"!**
- Alle Zeitreihen nicht-stationÃ¤r (KPSS p<0.01)
- SAR6. **StationaritÃ¤t ist kritisch fÃ¼r statistische Modelle**
- Alle Zeitreihen nicht-stationÃ¤r (KPSS p<0.01)
- SARIMA/VAR brauchen Differenzierung â†’ Verlust von Level-Info
- ML-Modelle kÃ¶nnen direkt mit Trends umgehen
- â†’ **Check Stationarity first!**

#### 7MA/VAR brauchen Differenzierung â†’ Verlust von Level-Info
- ML-Modelle kÃ¶nnen direkt mit Trends umgehen
- â†’ **Check Stationarity first!**
8
#### 11. **Multivariate Modelle sind fragil**
- VAR: Ein schlechter Zeitreihen-Input zerstÃ¶rt alles
- Granger-KausalitÃ¤t â‰  Forecast-Verbesserung
- â†’ **Use multivariate nur mit sehr cleanen Daten**

#### 12. **Metrik-Wahl ist kritisch**
- RÂ² gut fÃ¼r smooth series (Solar, Consumption)
- MAPE irrefÃ¼hrend bei Werten nahe 0 (Wind Offshore Stillstand)
- Bei Spikes: Hit-Rate besser als RMSE
- â†’ **Choose metrics based on business problem!**

#### 13. **Negative Prices sind Features, keine Errors**
- 827 FÃ¤lle (3.15%) bei Price
- Oversupply-Signal â†’ wichtig fÃ¼r Modell
- â†’ **Domain Knowledge beats Statistics!**

### ğŸ”® NÃ¤chste Schritte

1. âœ… **Solar Bi-LSTM:** Abgeschlossen (RÂ²=0.9955) - Archetyp 1 Champion!
2. âœ… **Consumption GRU:** Abgeschlossen (RÂ²=0.9874) - Archetyp 2 Champion! ğŸ†•
3. âœ… **Wind Onshore:** Getestet, 8 DL-Modelle (LSTM RÂ²=0.9548 vs RF 0.9997, SOTA versagt)
4. âœ… **Price:** Getestet, 8 DL-Modelle (GRU RÂ²=0.8906 vs LightGBM 0.9798, -9% Gap!) ğŸ†•
5. ğŸš§ **Wind Offshore:** DL-Testing ausstehend (Ã¤hnlich Wind Onshore erwartet)
6. ğŸ¯ **GRU-First Strategy:** GRU als Default fÃ¼r neue Zeitreihen testen
7. ğŸ”„ **Ensemble:** GRU + LightGBM kombinieren (temporal + features)
8. ğŸ“Š **ACF-Based Routing:** Automatische Modellwahl basierend auf ACF
9. ğŸŒ **Exogene Features:** Wetter-Daten (Wind, Solar-Irradiance) integrieren
10. ğŸ”§ **N-BEATS Debug:** Kann man SOTA-Modelle fixen? (evtl. nicht lohnend)

### ğŸ’¡ Open Questions fÃ¼r Diskussion

1. **Warum ist GRU bei Consumption besser als Bi-LSTM?**
   - Wochenmuster unidirektional â†’ Bi-LSTM bringt nichts?
   - Oder Bi-LSTM overfittet bei dieser Datenmenge?
   - â†’ **Generelle Regel: GRU fÃ¼r Wochen, Bi-LSTM fÃ¼r Tage?**

2. **Warum profitiert Consumption (3.7%) mehr von DL als Solar (1.2%)?**
   - ML bei Consumption schwÃ¤cher (0.95 vs 0.9838)
   - Komplexere Multi-Pattern-Struktur (Wochen + Tage)?
   - â†’ **DL-ROI steigt, wenn ML versagt?**

3. **Kann man N-BEATS/N-HiTS Ã¼berhaupt retten?**
   - Konsistent negativ bei Solar UND Consumption
   - LÃ¤ngere Sequences? Features hinzufÃ¼gen? Hyperparameter?
   - â†’ **Oder fundamental falsch fÃ¼r Energy Time Series?**

4. **GRU + LightGBM Ensemble = 0.99+?**
   - GRU lernt temporale Patterns (0.9874)
   - LightGBM lernt Feature-Interactions (0.95)
   - Verschiedene Fehler â†’ Kombination besser?
   - â†’ **Weighted Average oder Stacking testen?**

5. **ACF-Based Model Routing automatisieren?**
   ```
   if ACF(24h) > 0.7 and symmetrisch:
       model = Bi-LSTM
   elif ACF(168h) > ACF(24h):
       model = GRU
   elif ACF(24h) < 0.3:
       model = RandomForest
   else:
       model = LightGBM
   ```
   â†’ **Auto-ML fÃ¼r Architektur-Wahl?**

6. **Transfer Learning zwischen Zeitreihen?**
   - Solar-Bi-LSTM â†’ andere PV-Anlagen? â†’ âœ… Ja (gleicher Archetyp)
   - Consumption-GRU â†’ andere LÃ¤nder? â†’ âœ… Ja (gleiche Wochen-Struktur)
   - Solar â†’ Wind? â†’ âŒ Nein (unterschiedliche Archetypen)
   - â†’ **Archetyp-Matching fÃ¼r Transfer Learning!**

7. **Ist RÂ²=0.9997 bei Wind "zu gut"?**
   - Fast perfekt fÃ¼r chaotische Daten
   - Overfitting? Oder Test-Set zu einfach?
   - â†’ **Cross-Validation Ã¼ber mehrere Jahre nÃ¶tig?**

8. **Sollte man LSTM bei Wind Ã¼berhaupt versuchen?**
   - 10x Aufwand (GPU, Code, Tuning)
   - Ergebnis: 11% schlechter als RF
   - ROI klar negativ!
   - â†’ **ACF-Pre-Check macht DL-Training Ã¼berflÃ¼ssig?**

---

## BACKUP SLIDES

---

## Backup 1: Feature Importance Details

### Solar (LightGBM)

![Solar Feature Importance](results/figures/solar_extended_feature_importance.png)

**Top 10 Features:**
1. `lag_24` (33.2%) - 24h-Zyklus dominiert
2. `rolling_mean_24` (18.7%)
3. `hour` (12.4%) - Tageszeit
4. `lag_1` (8.9%)
5. `rolling_std_24` (6.1%)
6. `diff_24` (4.8%)
7. `month` (3.2%) - Jahreszeit
8. `lag_168` (2.9%) - Wochenmuster
9. `momentum_24h` (2.1%)
10. `rolling_mean_168` (1.8%)

**Interpretation:** 80% der Importance kommt von 24h-Pattern!

### Price (LightGBM)

![Price Feature Importance](results/figures/price_extended_feature_importance.png)

**Top 10 Features:**
1. `diff_1` (28.4%) - Momentum dominiert
2. `lag_1` (22.1%)
3. `momentum_3h` (11.8%)
4. `rolling_std_3` (9.2%) - VolatilitÃ¤t
5. `lag_2` (7.6%)
6. `diff_24` (5.4%)
7. `rolling_mean_3` (4.1%)
8. `hour` (3.8%)
9. `lag_24` (2.9%)
10. `rolling_std_24` (1.7%)

**Interpretation:** Kurzfristige Features (1-3h) dominieren - Preis ist mean-reverting!

---

## Backup 2: Computational Costs

| Modell | Training Time | Inference (1000 samples) | Hardware |
|--------|---------------|--------------------------|----------|
| LightGBM | **~2 min** | **<1s** | CPU |
| XGBoost | ~4 min | <1s | CPU |
| Random Forest | ~6 min | ~2s | CPU |
| SARIMA | ~15 min | ~5s | CPU |
| LSTM (optimized) | **~2 hours** | **~10s** | GPU (Colab T4) |
| VAR (Lag 24) | ~10 min | ~3s | CPU |

**ROI-Betrachtung:**
- LightGBM: Beste Performance/Zeit-Ratio
- LSTM: 60x langsamer fÃ¼r nur +2% RÂ²
- â†’ **In Production: LightGBM first choice**

---

## Backup 3: Alle verfÃ¼gbaren Figuren

```
ğŸ“‚ results/figures/
â”œâ”€â”€ model_comparison_rmse.png           # Alle Modelle RMSE
â”œâ”€â”€ model_comparison_all_metrics.png    # RÂ²/MAPE/RMSE
â”œâ”€â”€ best_per_category.png               # Beste pro Kategorie
â”‚
â”œâ”€â”€ solar_extended_01_timeline.png      # Solar Rohdaten
â”œâ”€â”€ solar_extended_09_final_comparison.png  # Solar alle Modelle
â”œâ”€â”€ solar_extended_feature_importance.png   # Solar Top Features
â”‚
â”œâ”€â”€ wind_offshore_01_timeline.png       # Wind Timeline
â”œâ”€â”€ wind_offshore_timeline_outage.png   # Wind mit Stillstand markiert
â”œâ”€â”€ wind_offshore_09_comparison.png     # Wind alle Modelle
â”‚
â”œâ”€â”€ price_extended_01_timeline.png      # Price Rohdaten
â”œâ”€â”€ price_extended_09_final_comparison.png  # Price alle Modelle
â”œâ”€â”€ price_extended_feature_importance.png   # Price Top Features
â”‚
â”œâ”€â”€ consumption_extended_01_timeline.png    # Consumption Rohdaten
â”œâ”€â”€ consumption_extended_09_final_comparison.png # Consumption Modelle
â”‚
â”œâ”€â”€ wind_onshore_extended_01_timeline.png   # Onshore Rohdaten
â””â”€â”€ wind_onshore_extended_09_final_comparison.png # Onshore Modelle
```

---

## Backup 4: Pipeline Scripts Ãœbersicht

```bash
# Alle vollstÃ¤ndigen Pipelines (Notebooks â†’ Skripte)
ğŸ“‚ scripts/
â”œâ”€â”€ run_solar_extended_pipeline.py          # Solar: VollstÃ¤ndig
â”œâ”€â”€ run_price_extended_pipeline.py          # Price: VollstÃ¤ndig  
â”œâ”€â”€ run_consumption_extended_pipeline.py    # Consumption: VollstÃ¤ndig
â”œâ”€â”€ run_wind_offshore_extended_pipeline.py  # Wind Off: VollstÃ¤ndig
â”œâ”€â”€ run_wind_onshore_extended_pipeline.py   # Wind On: VollstÃ¤ndig
â”‚
# LSTM Optimierungen (Colab Notebooks)
â”œâ”€â”€ LSTM_Optimization_Extended_Colab.ipynb  # âœ… Solar fertig
â”œâ”€â”€ LSTM_Optimization_Colab_wind_offshore.ipynb  # ğŸš§ In Arbeit
â””â”€â”€ optimize_lstm_models.py                 # Utility-Funktionen
```

**Jede Pipeline enthÃ¤lt:**
1. Data Loading & Exploration
2. Preprocessing & Feature Engineering (31 Features)
3. Train/Val/Test Split
4. Baseline Models (5x: Naive, Mean, Seasonal Naive, Drift, Moving Avg)
5. Statistical Models (SARIMA, ETS, SARIMAX)
6. ML Models (XGBoost, LightGBM, Random Forest, CatBoost)
7. Deep Learning (LSTM - in separaten Notebooks optimiert)
8. Results Export (CSV + PNG)

---

## ğŸ“š Referenzen & Quellen

1. **Daten:** SMARD.de, ENTSO-E Transparency Platform, EPEX Spot
2. **Frameworks:** scikit-learn, XGBoost, LightGBM, TensorFlow/Keras, statsmodels
3. **Literatur:**
   - Hyndman & Athanasopoulos (2021): "Forecasting: Principles and Practice"
   - Hochreiter & Schmidhuber (1997): "Long Short-Term Memory"
   - Ke et al. (2017): "LightGBM: A Highly Efficient Gradient Boosting Decision Tree"
4. **VAR/VECM:** LÃ¼tkepohl (2005): "New Introduction to Multiple Time Series Analysis"

---

# ğŸ¤ DANKE FÃœR IHRE AUFMERKSAMKEIT!

**Fragen? Diskussion?**

**Kontakt:** Siehe README.md  
**Code:** Alle Notebooks und Skripte im Repository verfÃ¼gbar  
**Daten:** `data/raw/` (5 CSV-Dateien)  
**Ergebnisse:** `results/` (Metriken + Figuren)

---

## PrÃ¤sentations-Notizen

### Timing (20 Min total)
- **Slides 1-3 (Daten + Preprocessing):** 4 Minuten
  - Slide 1: 1:30 Min - Datenbasis vorstellen
  - Slide 2: 1:30 Min - Feature Engineering erklÃ¤ren
  - Slide 3: 1:00 Min - Wind Offshore Problem zeigen
  
- **Slides 4-8 (Modell-Performance):** 10 Minuten
  - Slide 4: 2:00 Min - Solar als Best Case
  - Slide 5: 2:00 Min - Price als VolatilitÃ¤ts-Challenge
  - Slide 6: 2:00 Min - Wind Offshore als Problemfall
  - Slide 7: 2:00 Min - Consumption & Wind Onshore
  - Slide 8: 2:00 Min - LSTM Deep-Dive
  
- **Slides 9-10 (Kritische Diskussion):** 5 Minuten
  - Slide 9: 2:30 Min - VAR/VECM Analyse
  - Slide 10: 2:30 Min - Lessons Learned + Open Questions
  
- **Q&A:** 1 Minute Buffer

### Wichtige Diskussionspunkte
1. **"Warum ist ML so viel besser?"** â†’ Feature Engineering + Nicht-LinearitÃ¤t
2. **"Ist RÂ²=0.98 realistisch?"** â†’ Ja, aber nur weil `lag_24` so dominant ist
3. **"Wann LSTM nutzen?"** â†’ Nur bei >5 Jahren Daten oder sehr langen Dependencies
4. **"VAR sinnvoll?"** â†’ Theoretisch ja (Granger-KausalitÃ¤t), praktisch nein (RÂ²=0.28)
5. **"NÃ¤chste Schritte?"** â†’ Wetterdaten, Ensembles, Transformer
