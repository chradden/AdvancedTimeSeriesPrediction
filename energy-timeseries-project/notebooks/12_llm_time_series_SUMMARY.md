# ü§ñ Kapitel 12: Foundation Models f√ºr Time Series

## üìä Evaluationsergebnisse

### Chronos-T5-Small (Zero-Shot)
- **MAE**: 4,417.93 MW
- **RMSE**: 5,084.72 MW  
- **R¬≤**: -2.97
- **MAPE**: 49.94%
- **Inference**: 134s (56ms/sample)

### Vergleich mit traditionellen Modellen

| Modell | MAE (MW) | R¬≤ | MAPE (%) | Training | Typ |
|--------|----------|-----|----------|----------|-----|
| XGBoost (Tuned) | 249.03 | 0.9825 | 3.15 | 7.6 min | ML |
| LSTM | 251.53 | 0.9822 | 3.48 | 3.4 min | DL |
| GRU | 252.32 | 0.9820 | 3.49 | 4.7 min | DL |
| XGBoost (Baseline) | 269.47 | 0.9817 | 3.41 | 0.6 s | ML |
| **Chronos-T5-Small** | **4417.93** | **-2.97** | **49.94** | **Zero-Shot** | **FM** |

## üéØ Wichtigste Erkenntnisse

### ‚úÖ Foundation Models Vorteile
1. **Keine Training-Daten ben√∂tigt**: Zero-Shot Forecasting
2. **Generalisierung**: Funktioniert √ºber viele Dom√§nen
3. **Probabilistische Vorhersagen**: Unsicherheitsquantifizierung
4. **Rapid Prototyping**: Sofort einsetzbar

### ‚ö†Ô∏è Foundation Models Limitationen  
1. **Dom√§nenspezifische Performance**: 18x schlechter als XGBoost
2. **Inference-Zeit**: 56ms vs. <1ms bei ML-Modellen
3. **Ressourcen**: ~200MB Modellgr√∂√üe
4. **Keine Feature Engineering**: Nutzt nur historische Werte

## üìà Wann welches Modell?

### üèÜ XGBoost/LSTM/GRU verwenden wenn:
- ‚úÖ Reichlich dom√§nenspezifische Trainingsdaten vorhanden
- ‚úÖ Optimale Accuracy erforderlich  
- ‚úÖ Feature Engineering m√∂glich (Wetter, Kalender, etc.)
- ‚úÖ Niedrige Latenz wichtig
- ‚úÖ Interpretierbarkeit gefordert

### ü§ñ Chronos/Foundation Models verwenden wenn:
- ‚úÖ Wenig/keine Trainingsdaten
- ‚úÖ Mehrere unterschiedliche Zeitreihen  
- ‚úÖ Schnelles Prototyping
- ‚úÖ Probabilistische Vorhersagen ben√∂tigt
- ‚úÖ Dom√§nenwechsel h√§ufig

## üî¨ Technische Details

### Chronos Architecture
- **Basis**: T5 Transformer (Text-to-Text)
- **Pre-Training**: 100B+ Zeitreihenpunkte
- **Context Window**: 512 Tokens (168h in unserem Fall)
- **Prediction**: Autoregressive Generierung
- **Samples**: 20 probabilistische Trajektorien

### Weitere Foundation Models
- **TimeGPT** (Nixtla): GPT-√§hnliche Architektur
- **Lag-Llama** (ServiceNow): Llama-basiert
- **Moirai** (Salesforce): Multi-Scale

## üí° Best Practices

1. **Hybrid-Ansatz**: Chronos f√ºr Cold-Start, dann Fine-Tuning mit XGBoost
2. **Ensemble**: Kombiniere Zero-Shot + Domain-Specific Models
3. **Scaling**: Normalisiere Daten vor Chronos Inference
4. **Context**: Nutze mindestens 7 Tage Historie f√ºr Saisonalit√§t

## üöÄ Zukunft

Foundation Models werden besser sobald:
- Gr√∂√üere Modelle verf√ºgbar (T5-Large, -XL)
- Domain-Adaptation Methoden entwickelt  
- Multimodale Integration (Text + Time Series)
- Fine-Tuning f√ºr spezifische Dom√§nen

---

**Fazit**: Foundation Models sind vielversprechend, aber f√ºr dom√§nenspezifische Probleme mit reichlich Daten sind traditionelle ML/DL-Methoden noch √ºberlegen. Der Hauptvorteil liegt in der Zero-Shot-F√§higkeit f√ºr neue Dom√§nen ohne Training.
