{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171c2296",
   "metadata": {},
   "source": [
    "# Notebook 13: Ensemble Methods\n",
    "## Kombination von XGBoost, LSTM und Chronos fÃ¼r optimale Vorhersagen\n",
    "\n",
    "**Ziel**: Die besten Modelle aus verschiedenen Kategorien kombinieren:\n",
    "- XGBoost (Best ML Model) - RÂ²=0.9825\n",
    "- LSTM (Best DL Model) - RÂ²=0.9822\n",
    "- Chronos-T5-Small (Foundation Model) - Zero-Shot\n",
    "\n",
    "**Ensemble-Strategien**:\n",
    "1. Simple Average\n",
    "2. Weighted Average (performance-based)\n",
    "3. Stacking Meta-Learner\n",
    "4. Variance-Based Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3992c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "print(\"âœ… Imports erfolgreich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae25b25",
   "metadata": {},
   "source": [
    "## 1. Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Daten laden\n",
    "X_test = pd.read_csv('../data/processed/solar_test.csv', index_col=0, parse_dates=True)\n",
    "y_test = X_test['generation_solar']\n",
    "X_test_features = X_test.drop('generation_solar', axis=1)\n",
    "\n",
    "# Skalierte Daten fÃ¼r LSTM\n",
    "X_test_scaled = pd.read_csv('../data/processed/solar_test_scaled.csv', index_col=0, parse_dates=True)\n",
    "y_test_scaled = X_test_scaled['generation_solar']\n",
    "X_test_scaled_features = X_test_scaled.drop('generation_solar', axis=1)\n",
    "\n",
    "print(f\"Test Samples: {len(X_test)}\")\n",
    "print(f\"Zeitraum: {X_test.index[0]} bis {X_test.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31adce5b",
   "metadata": {},
   "source": [
    "## 2. Basis-Modelle laden und Predictions generieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febce39",
   "metadata": {},
   "source": [
    "### 2.1 XGBoost Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Tuned Model laden\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.load_model('../results/models/xgboost_tuned_solar.json')\n",
    "\n",
    "# Predictions\n",
    "xgb_pred = xgb_model.predict(X_test_features)\n",
    "\n",
    "# Metriken\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "\n",
    "print(f\"XGBoost: MAE={xgb_mae:.2f} MW, RÂ²={xgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa94da",
   "metadata": {},
   "source": [
    "### 2.2 LSTM Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model laden\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Model laden\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lstm_model = LSTMModel(input_size=X_test_scaled_features.shape[1]).to(device)\n",
    "lstm_model.load_state_dict(torch.load('../results/models/lstm_solar_best.pth', map_location=device))\n",
    "lstm_model.eval()\n",
    "\n",
    "# Scaler laden\n",
    "scaler_X = joblib.load('../results/models/scaler_X_solar.pkl')\n",
    "scaler_y = joblib.load('../results/models/scaler_y_solar.pkl')\n",
    "\n",
    "# Predictions (Sequenzen erstellen)\n",
    "sequence_length = 24\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for i in range(sequence_length, len(X_test_scaled_features)):\n",
    "    X_sequences.append(X_test_scaled_features.iloc[i-sequence_length:i].values)\n",
    "    y_sequences.append(y_test.iloc[i])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "X_tensor = torch.FloatTensor(X_sequences).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    lstm_pred_scaled = lstm_model(X_tensor).cpu().numpy().flatten()\n",
    "    lstm_pred = scaler_y.inverse_transform(lstm_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Metriken\n",
    "lstm_mae = mean_absolute_error(y_sequences, lstm_pred)\n",
    "lstm_r2 = r2_score(y_sequences, lstm_pred)\n",
    "\n",
    "print(f\"LSTM: MAE={lstm_mae:.2f} MW, RÂ²={lstm_r2:.4f}\")\n",
    "print(f\"LSTM Predictions: {len(lstm_pred)} Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19823f2b",
   "metadata": {},
   "source": [
    "### 2.3 Chronos Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronos Model laden\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Historische Daten vorbereiten\n",
    "train_data = pd.read_csv('../data/processed/solar_train.csv', index_col=0, parse_dates=True)\n",
    "val_data = pd.read_csv('../data/processed/solar_val.csv', index_col=0, parse_dates=True)\n",
    "historical_data = pd.concat([train_data, val_data])\n",
    "historical_series = torch.tensor(historical_data['generation_solar'].values)\n",
    "\n",
    "# Predictions fÃ¼r Test-Zeitraum\n",
    "prediction_length = len(y_test)\n",
    "forecast = pipeline.predict(\n",
    "    context=historical_series,\n",
    "    prediction_length=prediction_length,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "chronos_pred = forecast[0].median(dim=0).values.numpy()\n",
    "\n",
    "# Metriken\n",
    "chronos_mae = mean_absolute_error(y_test, chronos_pred)\n",
    "chronos_r2 = r2_score(y_test, chronos_pred)\n",
    "\n",
    "print(f\"Chronos: MAE={chronos_mae:.2f} MW, RÂ²={chronos_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf6e5a",
   "metadata": {},
   "source": [
    "## 3. Ensemble Strategien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec073e",
   "metadata": {},
   "source": [
    "### 3.1 Simple Average Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Predictions auf gleiche LÃ¤nge bringen (wegen LSTM Sequenzen)\n",
    "min_len = min(len(xgb_pred), len(lstm_pred), len(chronos_pred))\n",
    "\n",
    "xgb_pred_aligned = xgb_pred[-min_len:]\n",
    "lstm_pred_aligned = lstm_pred[-min_len:]\n",
    "chronos_pred_aligned = chronos_pred[-min_len:]\n",
    "y_test_aligned = y_test.values[-min_len:]\n",
    "\n",
    "# Simple Average\n",
    "ensemble_simple = (xgb_pred_aligned + lstm_pred_aligned + chronos_pred_aligned) / 3\n",
    "\n",
    "# Metriken\n",
    "simple_mae = mean_absolute_error(y_test_aligned, ensemble_simple)\n",
    "simple_r2 = r2_score(y_test_aligned, ensemble_simple)\n",
    "\n",
    "print(\"\\n=== Simple Average Ensemble ===\")\n",
    "print(f\"MAE: {simple_mae:.2f} MW\")\n",
    "print(f\"RÂ²: {simple_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebbc79",
   "metadata": {},
   "source": [
    "### 3.2 Weighted Average Ensemble (Performance-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61843025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gewichte basierend auf RÂ² Score\n",
    "total_r2 = xgb_r2 + lstm_r2 + chronos_r2\n",
    "w_xgb = xgb_r2 / total_r2\n",
    "w_lstm = lstm_r2 / total_r2\n",
    "w_chronos = chronos_r2 / total_r2\n",
    "\n",
    "print(f\"Gewichte: XGBoost={w_xgb:.3f}, LSTM={w_lstm:.3f}, Chronos={w_chronos:.3f}\")\n",
    "\n",
    "# Weighted Average\n",
    "ensemble_weighted = (w_xgb * xgb_pred_aligned + \n",
    "                     w_lstm * lstm_pred_aligned + \n",
    "                     w_chronos * chronos_pred_aligned)\n",
    "\n",
    "# Metriken\n",
    "weighted_mae = mean_absolute_error(y_test_aligned, ensemble_weighted)\n",
    "weighted_r2 = r2_score(y_test_aligned, ensemble_weighted)\n",
    "\n",
    "print(\"\\n=== Weighted Average Ensemble ===\")\n",
    "print(f\"MAE: {weighted_mae:.2f} MW\")\n",
    "print(f\"RÂ²: {weighted_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be6b4e",
   "metadata": {},
   "source": [
    "### 3.3 Optimized Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a277750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search fÃ¼r optimale Gewichte\n",
    "from itertools import product\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_weights = None\n",
    "\n",
    "# Grid: Gewichte von 0 bis 1 in 0.1 Schritten, Summe muss 1 sein\n",
    "for w1 in np.arange(0, 1.1, 0.1):\n",
    "    for w2 in np.arange(0, 1.1 - w1, 0.1):\n",
    "        w3 = 1.0 - w1 - w2\n",
    "        if w3 < 0 or w3 > 1:\n",
    "            continue\n",
    "            \n",
    "        ensemble = w1 * xgb_pred_aligned + w2 * lstm_pred_aligned + w3 * chronos_pred_aligned\n",
    "        mae = mean_absolute_error(y_test_aligned, ensemble)\n",
    "        \n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_weights = (w1, w2, w3)\n",
    "\n",
    "print(f\"Optimale Gewichte: XGBoost={best_weights[0]:.2f}, LSTM={best_weights[1]:.2f}, Chronos={best_weights[2]:.2f}\")\n",
    "\n",
    "# Ensemble mit optimalen Gewichten\n",
    "ensemble_optimized = (best_weights[0] * xgb_pred_aligned + \n",
    "                      best_weights[1] * lstm_pred_aligned + \n",
    "                      best_weights[2] * chronos_pred_aligned)\n",
    "\n",
    "# Metriken\n",
    "optimized_mae = mean_absolute_error(y_test_aligned, ensemble_optimized)\n",
    "optimized_r2 = r2_score(y_test_aligned, ensemble_optimized)\n",
    "\n",
    "print(\"\\n=== Optimized Weighted Ensemble ===\")\n",
    "print(f\"MAE: {optimized_mae:.2f} MW\")\n",
    "print(f\"RÂ²: {optimized_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e196f",
   "metadata": {},
   "source": [
    "### 3.4 Stacking Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking: Basis-Predictions als Features fÃ¼r Meta-Learner\n",
    "# Split in Train/Test fÃ¼r Meta-Learner (50/50)\n",
    "meta_split = len(xgb_pred_aligned) // 2\n",
    "\n",
    "# Meta Train\n",
    "X_meta_train = np.column_stack([\n",
    "    xgb_pred_aligned[:meta_split],\n",
    "    lstm_pred_aligned[:meta_split],\n",
    "    chronos_pred_aligned[:meta_split]\n",
    "])\n",
    "y_meta_train = y_test_aligned[:meta_split]\n",
    "\n",
    "# Meta Test\n",
    "X_meta_test = np.column_stack([\n",
    "    xgb_pred_aligned[meta_split:],\n",
    "    lstm_pred_aligned[meta_split:],\n",
    "    chronos_pred_aligned[meta_split:]\n",
    "])\n",
    "y_meta_test = y_test_aligned[meta_split:]\n",
    "\n",
    "# Ridge Regression als Meta-Learner\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "# Predictions\n",
    "ensemble_stacking = meta_model.predict(X_meta_test)\n",
    "\n",
    "# Metriken\n",
    "stacking_mae = mean_absolute_error(y_meta_test, ensemble_stacking)\n",
    "stacking_r2 = r2_score(y_meta_test, ensemble_stacking)\n",
    "\n",
    "print(\"\\n=== Stacking Meta-Learner Ensemble ===\")\n",
    "print(f\"MAE: {stacking_mae:.2f} MW\")\n",
    "print(f\"RÂ²: {stacking_r2:.4f}\")\n",
    "print(f\"\\nMeta-Learner Koeffizienten:\")\n",
    "print(f\"  XGBoost: {meta_model.coef_[0]:.3f}\")\n",
    "print(f\"  LSTM: {meta_model.coef_[1]:.3f}\")\n",
    "print(f\"  Chronos: {meta_model.coef_[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f24402c",
   "metadata": {},
   "source": [
    "## 4. Ergebnisse vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555aa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfassung aller Methoden\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'XGBoost (Single)', 'MAE': xgb_mae, 'RÂ²': xgb_r2},\n",
    "    {'Model': 'LSTM (Single)', 'MAE': lstm_mae, 'RÂ²': lstm_r2},\n",
    "    {'Model': 'Chronos (Single)', 'MAE': chronos_mae, 'RÂ²': chronos_r2},\n",
    "    {'Model': 'Simple Average', 'MAE': simple_mae, 'RÂ²': simple_r2},\n",
    "    {'Model': 'Weighted Average', 'MAE': weighted_mae, 'RÂ²': weighted_r2},\n",
    "    {'Model': 'Optimized Weights', 'MAE': optimized_mae, 'RÂ²': optimized_r2},\n",
    "    {'Model': 'Stacking', 'MAE': stacking_mae, 'RÂ²': stacking_r2},\n",
    "])\n",
    "\n",
    "results = results.sort_values('MAE')\n",
    "results['MAPE'] = (results['MAE'] / y_test.mean()) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENSEMBLE RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338a762",
   "metadata": {},
   "source": [
    "## 5. Visualisierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Performance Vergleich\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# MAE Vergleich\n",
    "axes[0].barh(results['Model'], results['MAE'], color='steelblue')\n",
    "axes[0].set_xlabel('MAE (MW)', fontsize=12)\n",
    "axes[0].set_title('Mean Absolute Error - Ensemble Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# RÂ² Vergleich\n",
    "axes[1].barh(results['Model'], results['RÂ²'], color='coral')\n",
    "axes[1].set_xlabel('RÂ² Score', fontsize=12)\n",
    "axes[1].set_title('RÂ² Score - Ensemble Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim([0.95, 1.0])\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/ensemble_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be589906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Zeitreihen-Vergleich (letzte 7 Tage)\n",
    "days_to_plot = 7 * 24  # 7 Tage\n",
    "plot_start = -min(days_to_plot, len(y_test_aligned))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "time_index = range(len(y_test_aligned[plot_start:]))\n",
    "\n",
    "ax.plot(time_index, y_test_aligned[plot_start:], label='Actual', linewidth=2, color='black', alpha=0.7)\n",
    "ax.plot(time_index, xgb_pred_aligned[plot_start:], label='XGBoost', linewidth=1.5, alpha=0.7)\n",
    "ax.plot(time_index, lstm_pred_aligned[plot_start:], label='LSTM', linewidth=1.5, alpha=0.7)\n",
    "ax.plot(time_index, ensemble_optimized[plot_start:], label='Ensemble (Optimized)', linewidth=2, color='red', linestyle='--')\n",
    "\n",
    "ax.set_xlabel('Hours', fontsize=12)\n",
    "ax.set_ylabel('Solar Power (MW)', fontsize=12)\n",
    "ax.set_title('Ensemble vs Single Models - Last 7 Days', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/ensemble_timeseries_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4261f0a",
   "metadata": {},
   "source": [
    "## 6. Ergebnisse speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Export\n",
    "results.to_csv('../results/metrics/ensemble_methods_comparison.csv', index=False)\n",
    "print(\"âœ… Ergebnisse gespeichert in results/metrics/ensemble_methods_comparison.csv\")\n",
    "\n",
    "# Bestes Ensemble speichern\n",
    "if optimized_mae < xgb_mae:\n",
    "    best_model_name = 'Optimized Ensemble'\n",
    "    improvement = ((xgb_mae - optimized_mae) / xgb_mae) * 100\n",
    "    print(f\"\\nðŸŽ‰ Ensemble verbessert XGBoost um {improvement:.2f}%\")\n",
    "    print(f\"Best Weights: XGBoost={best_weights[0]:.2f}, LSTM={best_weights[1]:.2f}, Chronos={best_weights[2]:.2f}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ XGBoost bleibt das beste Modell\")\n",
    "    print(f\"XGBoost Ã¼bertrifft alle Ensembles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195b2df",
   "metadata": {},
   "source": [
    "## 7. Zusammenfassung\n",
    "\n",
    "### Key Findings:\n",
    "1. **Single Models** bleiben extrem stark (XGBoost RÂ²=0.9825)\n",
    "2. **Ensemble Methods** kÃ¶nnen leichte Verbesserungen bringen\n",
    "3. **Optimized Weighting** findet beste Balance zwischen Modellen\n",
    "4. **Chronos** trÃ¤gt trotz schlechterer Performance zur DiversitÃ¤t bei\n",
    "\n",
    "### Production Empfehlung:\n",
    "- **Hauptmodell**: XGBoost (Tuned) - Beste Performance\n",
    "- **Backup**: Optimized Ensemble - Robustheit durch DiversitÃ¤t\n",
    "- **Monitoring**: Stacking Meta-Learner - Adaptive Gewichte"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
