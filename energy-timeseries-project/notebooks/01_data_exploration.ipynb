{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Datenanalyse - Energiedaten\n",
    "\n",
    "**Ziel:** Erste Analyse der Energiedaten von SMARD (Bundesnetzagentur)\n",
    "\n",
    "**Inhalte:**\n",
    "1. Daten laden\n",
    "2. Datenqualität prüfen\n",
    "3. Grundlegende Visualisierungen\n",
    "4. Statistische Eigenschaften\n",
    "5. Saisonalität & Trends\n",
    "6. Autokorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Figure size\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✅ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten laden\n",
    "\n",
    "Wir nutzen die SMARD API der Bundesnetzagentur.\n",
    "\n",
    "**Verfügbare Datenquellen:**\n",
    "- `solar`: Photovoltaik-Erzeugung\n",
    "- `wind_onshore`: Windkraft Onshore\n",
    "- `wind_offshore`: Windkraft Offshore\n",
    "- `consumption`: Stromverbrauch\n",
    "- `price_day_ahead`: Day-Ahead Marktpreis\n",
    "- `generation_total`: Gesamte Stromerzeugung\n",
    "- Weitere siehe `src/data/smard_loader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.smard_loader import load_smard_data, SMARDDataLoader\n",
    "\n",
    "# Konfiguration\n",
    "DATA_TYPE = 'solar'  # Ändere hier für andere Datenquellen\n",
    "START_DATE = '2022-01-01'\n",
    "END_DATE = '2024-12-31'\n",
    "RESOLUTION = 'hour'\n",
    "\n",
    "print(f\"Lade {DATA_TYPE}-Daten von {START_DATE} bis {END_DATE}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden (wird gecached für schnelleres Nachladen)\n",
    "df = load_smard_data(\n",
    "    filter_name=DATA_TYPE,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    resolution=RESOLUTION,\n",
    "    cache_dir=Path('../data/raw')\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Daten erfolgreich geladen: {len(df)} Datenpunkte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Inspektion\n",
    "print(\"Erste 5 Zeilen:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nLetzte 5 Zeilen:\")\n",
    "display(df.tail())\n",
    "\n",
    "print(\"\\nDatentypen:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nZeitraum: {df['timestamp'].min()} bis {df['timestamp'].max()}\")\n",
    "print(f\"Anzahl Tage: {(df['timestamp'].max() - df['timestamp'].min()).days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenqualität\n",
    "\n",
    "Überprüfung auf:\n",
    "- Fehlende Werte\n",
    "- Duplikate\n",
    "- Ausreißer\n",
    "- Zeitlücken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATENQUALITÄTS-REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fehlende Werte\n",
    "missing = df['value'].isna().sum()\n",
    "missing_pct = missing / len(df) * 100\n",
    "print(f\"\\n1. Fehlende Werte: {missing} ({missing_pct:.2f}%)\")\n",
    "\n",
    "# Duplikate\n",
    "duplicates = df.duplicated(subset=['timestamp']).sum()\n",
    "print(f\"\\n2. Duplikate (Timestamp): {duplicates}\")\n",
    "\n",
    "# Zeitlücken prüfen\n",
    "df_sorted = df.sort_values('timestamp').reset_index(drop=True)\n",
    "time_diffs = df_sorted['timestamp'].diff()\n",
    "\n",
    "if RESOLUTION == 'hour':\n",
    "    expected_diff = pd.Timedelta(hours=1)\n",
    "elif RESOLUTION == 'day':\n",
    "    expected_diff = pd.Timedelta(days=1)\n",
    "else:\n",
    "    expected_diff = None\n",
    "\n",
    "if expected_diff:\n",
    "    gaps = time_diffs[time_diffs > expected_diff]\n",
    "    print(f\"\\n3. Zeitlücken (> {expected_diff}): {len(gaps)}\")\n",
    "    if len(gaps) > 0:\n",
    "        print(\"   Erste 5 Lücken:\")\n",
    "        for idx in gaps.head().index:\n",
    "            print(f\"     {df_sorted.loc[idx-1, 'timestamp']} -> {df_sorted.loc[idx, 'timestamp']}\")\n",
    "\n",
    "# Statistik\n",
    "print(f\"\\n4. Wertebereich:\")\n",
    "print(f\"   Min: {df['value'].min():,.0f}\")\n",
    "print(f\"   Max: {df['value'].max():,.0f}\")\n",
    "print(f\"   Mean: {df['value'].mean():,.0f}\")\n",
    "print(f\"   Median: {df['value'].median():,.0f}\")\n",
    "print(f\"   Std: {df['value'].std():,.0f}\")\n",
    "\n",
    "# Nullwerte\n",
    "zeros = (df['value'] == 0).sum()\n",
    "zeros_pct = zeros / len(df) * 100\n",
    "print(f\"\\n5. Nullwerte: {zeros} ({zeros_pct:.2f}%)\")\n",
    "\n",
    "# Negative Werte\n",
    "negatives = (df['value'] < 0).sum()\n",
    "print(f\"\\n6. Negative Werte: {negatives}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisierung - Gesamtzeitreihe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.plot(df['timestamp'], df['value'], linewidth=0.5, alpha=0.8)\n",
    "ax.set_title(f'{DATA_TYPE.upper()} - Gesamtzeitreihe', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Datum', fontsize=12)\n",
    "ax.set_ylabel('Wert [MW]', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verteilungsanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Histogramm\n",
    "axes[0].hist(df['value'].dropna(), bins=100, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Verteilung der Werte', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Wert [MW]')\n",
    "axes[0].set_ylabel('Häufigkeit')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box-Plot\n",
    "axes[1].boxplot(df['value'].dropna(), vert=True)\n",
    "axes[1].set_title('Box-Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Wert [MW]')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistik ausgeben\n",
    "print(\"\\nStatistische Kennzahlen:\")\n",
    "print(df['value'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saisonalität analysieren\n",
    "\n",
    "### 5.1 Monatliche Muster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monat und Jahr extrahieren\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['dayofweek'] = df['timestamp'].dt.dayofweek  # 0=Montag, 6=Sonntag\n",
    "df['dayofyear'] = df['timestamp'].dt.dayofyear\n",
    "\n",
    "# Durchschnitt pro Monat\n",
    "monthly_avg = df.groupby('month')['value'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "monthly_avg.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n",
    "ax.set_title('Durchschnittlicher Wert pro Monat', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Monat')\n",
    "ax.set_ylabel('Durchschnittswert [MW]')\n",
    "ax.set_xticklabels(['Jan', 'Feb', 'Mär', 'Apr', 'Mai', 'Jun', \n",
    "                    'Jul', 'Aug', 'Sep', 'Okt', 'Nov', 'Dez'], rotation=0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Wochentags-Muster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchschnitt pro Wochentag\n",
    "weekday_avg = df.groupby('dayofweek')['value'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "weekday_avg.plot(kind='bar', ax=ax, color='coral', edgecolor='black')\n",
    "ax.set_title('Durchschnittlicher Wert pro Wochentag', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Wochentag')\n",
    "ax.set_ylabel('Durchschnittswert [MW]')\n",
    "ax.set_xticklabels(['Mo', 'Di', 'Mi', 'Do', 'Fr', 'Sa', 'So'], rotation=0)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Tages-Muster (Stundenprofil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESOLUTION == 'hour':\n",
    "    # Durchschnitt pro Stunde\n",
    "    hourly_avg = df.groupby('hour')['value'].mean()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    hourly_avg.plot(ax=ax, marker='o', linewidth=2, markersize=6, color='green')\n",
    "    ax.set_title('Durchschnittliches Tagesprofil (pro Stunde)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Stunde des Tages')\n",
    "    ax.set_ylabel('Durchschnittswert [MW]')\n",
    "    ax.set_xticks(range(24))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Stundenprofil nur für stündliche Auflösung verfügbar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Jahresverlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagesdurchschnitt\n",
    "daily_avg = df.groupby(df['timestamp'].dt.date)['value'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "ax.plot(daily_avg.index, daily_avg.values, linewidth=1)\n",
    "ax.set_title('Täglicher Durchschnittswert', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Datum')\n",
    "ax.set_ylabel('Durchschnitt [MW]')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autokorrelation (ACF) und Partielle Autokorrelation (PACF)\n",
    "\n",
    "Wichtig für:\n",
    "- Erkennung von Abhängigkeiten\n",
    "- ARIMA-Parameter-Auswahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Nur nicht-fehlende Werte\n",
    "values_clean = df['value'].dropna()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# ACF\n",
    "plot_acf(values_clean, lags=168, ax=axes[0])  # 7 Tage für stündliche Daten\n",
    "axes[0].set_title('Autokorrelationsfunktion (ACF)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Lag')\n",
    "\n",
    "# PACF\n",
    "plot_pacf(values_clean, lags=168, ax=axes[1])\n",
    "axes[1].set_title('Partielle Autokorrelationsfunktion (PACF)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Lag')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stationaritätstest\n",
    "\n",
    "Augmented Dickey-Fuller Test:\n",
    "- H0: Zeitreihe ist nicht-stationär\n",
    "- H1: Zeitreihe ist stationär\n",
    "- p-value < 0.05 → Zeitreihe ist stationär"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "# ADF Test\n",
    "result_adf = adfuller(values_clean)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STATIONARITÄTSTEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nAugmented Dickey-Fuller Test:\")\n",
    "print(f\"  ADF Statistic: {result_adf[0]:.6f}\")\n",
    "print(f\"  p-value: {result_adf[1]:.6f}\")\n",
    "print(f\"  Critical Values:\")\n",
    "for key, value in result_adf[4].items():\n",
    "    print(f\"    {key}: {value:.3f}\")\n",
    "\n",
    "if result_adf[1] < 0.05:\n",
    "    print(\"\\n  ✅ Zeitreihe ist STATIONÄR (p < 0.05)\")\n",
    "else:\n",
    "    print(\"\\n  ⚠️  Zeitreihe ist NICHT-STATIONÄR (p >= 0.05)\")\n",
    "    print(\"      → Differenzierung könnte notwendig sein\")\n",
    "\n",
    "# KPSS Test (zusätzlich)\n",
    "try:\n",
    "    result_kpss = kpss(values_clean, regression='ct')\n",
    "    print(\"\\n\\nKPSS Test (Trend-Stationarität):\")\n",
    "    print(f\"  KPSS Statistic: {result_kpss[0]:.6f}\")\n",
    "    print(f\"  p-value: {result_kpss[1]:.6f}\")\n",
    "    \n",
    "    if result_kpss[1] > 0.05:\n",
    "        print(\"\\n  ✅ Zeitreihe ist TREND-STATIONÄR (p > 0.05)\")\n",
    "    else:\n",
    "        print(\"\\n  ⚠️  Zeitreihe ist NICHT TREND-STATIONÄR (p <= 0.05)\")\n",
    "except:\n",
    "    print(\"\\nKPSS Test konnte nicht durchgeführt werden\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Zusammenfassung & Nächste Schritte\n",
    "\n",
    "### Erkenntnisse aus der EDA:\n",
    "\n",
    "**Bitte trage hier deine Beobachtungen ein:**\n",
    "\n",
    "1. **Datenqualität:**\n",
    "   - [ ] Fehlende Werte vorhanden? → Strategie festlegen\n",
    "   - [ ] Ausreißer vorhanden? → Behandlung notwendig?\n",
    "   - [ ] Zeitlücken? → Interpolation?\n",
    "\n",
    "2. **Saisonalität:**\n",
    "   - [ ] Tägliche Saisonalität erkennbar?\n",
    "   - [ ] Wöchentliche Saisonalität?\n",
    "   - [ ] Jährliche Saisonalität?\n",
    "\n",
    "3. **Trend:**\n",
    "   - [ ] Aufwärtstrend?\n",
    "   - [ ] Abwärtstrend?\n",
    "   - [ ] Kein Trend?\n",
    "\n",
    "4. **Stationarität:**\n",
    "   - [ ] Stationär?\n",
    "   - [ ] Differenzierung notwendig?\n",
    "\n",
    "### Nächste Schritte:\n",
    "\n",
    "1. **Datenaufbereitung** → `02_data_preprocessing.ipynb`\n",
    "   - Fehlende Werte behandeln\n",
    "   - Ausreißer behandeln\n",
    "   - Features engineering\n",
    "   - Train/Test/Validation Split\n",
    "\n",
    "2. **Baseline-Modelle** → `03_baseline_models.ipynb`\n",
    "   - Naive Forecast\n",
    "   - Seasonal Naive\n",
    "   - Moving Average\n",
    "\n",
    "3. **Statistische Modelle** → `04_statistical_models.ipynb`\n",
    "   - SARIMA(X)\n",
    "   - ETS\n",
    "\n",
    "4. **Machine Learning** → `05_ml_tree_models.ipynb`\n",
    "   - XGBoost, LightGBM, CatBoost\n",
    "\n",
    "5. **Deep Learning** → `06_deep_learning_models.ipynb`\n",
    "   - LSTM, GRU\n",
    "\n",
    "6. **Advanced Models** → `07_advanced_models.ipynb`\n",
    "   - TFT, N-BEATS\n",
    "\n",
    "7. **Model Comparison** → `08_model_comparison.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Aufbereitete Daten speichern für weitere Notebooks\n",
    "output_file = Path('../data/processed') / f'{DATA_TYPE}_{START_DATE}_{END_DATE}_initial.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"✅ Daten gespeichert: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_kernel)",
   "language": "python",
   "name": "my_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
