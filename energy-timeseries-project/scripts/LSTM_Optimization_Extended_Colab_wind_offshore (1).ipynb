{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3bee9d27",
      "metadata": {
        "id": "3bee9d27"
      },
      "source": [
        "# üöÄ Advanced Deep Learning Models - Extended Edition\n",
        "\n",
        "**Komplette Suite moderner DL-Architekturen mit GPU-Beschleunigung**\n",
        "\n",
        "## üìã Modelle in diesem Notebook:\n",
        "\n",
        "### Basis DL-Modelle:\n",
        "1. **LSTM** - Standard Long Short-Term Memory\n",
        "2. **Bi-LSTM** - Bidirectional LSTM\n",
        "3. **GRU** - Gated Recurrent Unit (schneller als LSTM)\n",
        "\n",
        "### Generative Modelle:\n",
        "4. **Autoencoder** - Dimensionsreduktion + Forecasting\n",
        "5. **VAE** - Variational Autoencoder (mit Unsicherheitssch√§tzung)\n",
        "6. **TimeGAN** - Generative Adversarial Network f√ºr Zeitreihen\n",
        "\n",
        "### Advanced/Transformer:\n",
        "7. **N-BEATS** - Neural Basis Expansion\n",
        "8. **N-HiTS** - Hierarchical Interpolation\n",
        "9. **DeepAR** - Amazon's probabilistisches Modell\n",
        "10. **TFT** - Temporal Fusion Transformer (State-of-the-Art)\n",
        "\n",
        "### Hinweise zur Rechenzeit (GPU T4):\n",
        "- ‚úÖ **Schnell** (<5 Min): LSTM, GRU, Bi-LSTM, Autoencoder, VAE\n",
        "- ‚ö†Ô∏è **Mittel** (5-15 Min): N-BEATS, N-HiTS, DeepAR\n",
        "- üî• **Langsam** (15-45 Min): TFT, TimeGAN\n",
        "\n",
        "**Setup:** Runtime ‚Üí Change runtime type ‚Üí GPU (T4 empfohlen, A100 f√ºr TFT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7a4be948",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a4be948",
        "outputId": "756db836-dbda-4283-a7ac-25ce90c39d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "\n",
            "üöÄ GPU should show above!\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"\\nüöÄ GPU should show above!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3607b12e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3607b12e",
        "outputId": "8ce63c74-d53a-4ba7-a9ca-21eb5b109641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AdvancedTimeSeriesPrediction'...\n",
            "remote: Enumerating objects: 808, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 808 (delta 55), reused 96 (delta 33), pack-reused 682 (from 1)\u001b[K\n",
            "Receiving objects: 100% (808/808), 73.13 MiB | 29.01 MiB/s, done.\n",
            "Resolving deltas: 100% (300/300), done.\n",
            "/content/AdvancedTimeSeriesPrediction/energy-timeseries-project\n"
          ]
        }
      ],
      "source": [
        "# Clone Repository\n",
        "!git clone https://github.com/chradden/AdvancedTimeSeriesPrediction.git\n",
        "%cd AdvancedTimeSeriesPrediction/energy-timeseries-project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "80df3cc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80df3cc9",
        "outputId": "ac73e4f0-f7c6-4d53-b084-ff09e3c20687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing packages (this may take 2-3 minutes)...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: darts 0.40.0 does not provide the extra 'torch'\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m204.7/204.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# Install ALL Dependencies\n",
        "print(\"üì¶ Installing packages (this may take 2-3 minutes)...\")\n",
        "!pip install -q pandas numpy matplotlib seaborn scikit-learn\n",
        "!pip install -q tensorflow keras pytorch-lightning\n",
        "!pip install -q 'darts[torch]'  # N-BEATS, N-HiTS, TFT, DeepAR\n",
        "!pip install -q gluonts  # DeepAR alternative\n",
        "print(\"‚úÖ Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "813e5d25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "813e5d25",
        "outputId": "bdb44a00-3d3d-4420-a582-924653d0b048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GPU configured: 1 device(s)\n",
            "\n",
            "üìä All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# GPU Config\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU found - training will be slow!\")\n",
        "\n",
        "print(\"\\nüìä All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f508784",
      "metadata": {
        "id": "1f508784"
      },
      "source": [
        "## ‚öôÔ∏è Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ea77c9d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea77c9d6",
        "outputId": "6313489c-da97-4291-b3e1-46c6e84a98d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Zeitreihe: WIND_OFFSHORE\n",
            "‚ö†Ô∏è  OUTAGE FILTERING AKTIV f√ºr Wind Offshore!\n",
            "   Threshold: < 10 MW werden entfernt\n",
            "\n",
            "üéØ Aktivierte Modelle:\n",
            "   ‚úÖ Basic DL (LSTM, GRU, Bi-LSTM)\n",
            "   ‚úÖ Generative (Autoencoder, VAE)\n",
            "   ‚úÖ Advanced (N-BEATS, N-HiTS)\n",
            "   ‚úÖ DeepAR (probabilistisch)\n",
            "\n",
            "‚úÖ Konfiguration abgeschlossen!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "SERIES_NAME = 'wind_offshore'  # √Ñndern: 'solar', 'wind_offshore', 'wind_onshore', 'price', 'consumption'\n",
        "\n",
        "# ‚ö†Ô∏è CRITICAL FOR WIND OFFSHORE: Stillstand Detection\n",
        "# Wind Offshore hatte 9.8 Monate Stillstand (Apr 2023 - Feb 2024)\n",
        "# Wenn SERIES_NAME = 'wind_offshore' ‚Üí automatisch Stillstand filtern\n",
        "FILTER_OUTAGE = (SERIES_NAME == 'wind_offshore')\n",
        "OUTAGE_THRESHOLD = 10  # MW - Werte unter 10 MW als Stillstand klassifizieren\n",
        "\n",
        "# Model Selection (setze auf False um Modelle zu √ºberspringen)\n",
        "RUN_BASIC = True          # LSTM, GRU, Bi-LSTM (~5 min)\n",
        "RUN_GENERATIVE = True     # Autoencoder, VAE (~5 min)\n",
        "RUN_GAN = False           # TimeGAN (~30 min, experimentell)\n",
        "RUN_ADVANCED = True       # N-BEATS, N-HiTS (~10 min)\n",
        "RUN_PROBABILISTIC = True  # DeepAR (~10 min)\n",
        "RUN_TFT = False           # Temporal Fusion Transformer (~30-45 min)\n",
        "\n",
        "print(f\"üìä Zeitreihe: {SERIES_NAME.upper()}\")\n",
        "if FILTER_OUTAGE:\n",
        "    print(f\"‚ö†Ô∏è  OUTAGE FILTERING AKTIV f√ºr Wind Offshore!\")\n",
        "    print(f\"   Threshold: < {OUTAGE_THRESHOLD} MW werden entfernt\")\n",
        "print(f\"\\nüéØ Aktivierte Modelle:\")\n",
        "if RUN_BASIC: print(\"   ‚úÖ Basic DL (LSTM, GRU, Bi-LSTM)\")\n",
        "if RUN_GENERATIVE: print(\"   ‚úÖ Generative (Autoencoder, VAE)\")\n",
        "if RUN_GAN: print(\"   ‚úÖ TimeGAN (experimentell, ~30 min)\")\n",
        "if RUN_ADVANCED: print(\"   ‚úÖ Advanced (N-BEATS, N-HiTS)\")\n",
        "if RUN_PROBABILISTIC: print(\"   ‚úÖ DeepAR (probabilistisch)\")\n",
        "if RUN_TFT: print(\"   ‚úÖ TFT (State-of-the-Art, ~30-45 min)\")\n",
        "\n",
        "print(f\"\\n‚úÖ Konfiguration abgeschlossen!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "587212fb",
      "metadata": {
        "id": "587212fb"
      },
      "source": [
        "## üìÇ Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4e8e25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb4e8e25",
        "outputId": "75cf9612-3db1-42b0-9bb5-1908e3592a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Data loaded for: WIND_OFFSHORE\n",
            "   Train: 7744 | Val: 1659 | Test: 1660\n",
            "\n",
            "‚ö†Ô∏è  FILTERING OUTAGE DATA (< 10 MW)...\n",
            "   Train: 7744 ‚Üí 7744 (-0, 0.0%)\n",
            "   Val:   1659 ‚Üí 1659 (-0, 0.0%)\n",
            "   Test:  1660 ‚Üí 1660 (-0, 0.0%)\n",
            "   ‚úÖ Outage periods removed!\n",
            "\n",
            "üìä Final dataset sizes:\n",
            "   Train: 7744 | Val: 1659 | Test: 1660\n",
            "   Value column: value\n",
            "   Features: 31\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv(f'data/processed/{SERIES_NAME}_train.csv')\n",
        "val_df = pd.read_csv(f'data/processed/{SERIES_NAME}_val.csv')\n",
        "test_df = pd.read_csv(f'data/processed/{SERIES_NAME}_test.csv')\n",
        "\n",
        "# Determine value column\n",
        "value_col = [c for c in train_df.columns if c in ['solar', 'price', 'value',\n",
        "                                                     'wind_offshore', 'wind_onshore', 'consumption']][0]\n",
        "feature_cols = [c for c in train_df.columns if c not in ['timestamp', value_col]]\n",
        "\n",
        "print(f\"üìÇ Data loaded for: {SERIES_NAME.upper()}\")\n",
        "print(f\"   Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "\n",
        "# ‚ö†Ô∏è WIND OFFSHORE OUTAGE FILTERING\n",
        "if FILTER_OUTAGE:\n",
        "    print(f\"\\n‚ö†Ô∏è  CHECKING FOR OUTAGE DATA (< {OUTAGE_THRESHOLD} MW)...\")\n",
        "    \n",
        "    # Check how many values are below threshold\n",
        "    train_outage = (train_df[value_col] < OUTAGE_THRESHOLD).sum()\n",
        "    val_outage = (val_df[value_col] < OUTAGE_THRESHOLD).sum()\n",
        "    test_outage = (test_df[value_col] < OUTAGE_THRESHOLD).sum()\n",
        "    total_outage = train_outage + val_outage + test_outage\n",
        "    \n",
        "    if total_outage == 0:\n",
        "        print(f\"   ‚ÑπÔ∏è  INFO: No outage data found (< {OUTAGE_THRESHOLD} MW)\")\n",
        "        print(f\"   ‚ÑπÔ∏è  Die Daten wurden bereits in der Preprocessing-Pipeline gefiltert!\")\n",
        "        print(f\"   ‚ÑπÔ∏è  Original hatte 9.8 Monate Stillstand (Apr 2023 - Feb 2024)\")\n",
        "        print(f\"   ‚úÖ Nutze bereits bereinigte Daten f√ºr Training\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  OUTAGE DATA FOUND - FILTERING...\")\n",
        "        \n",
        "        # Filter each set\n",
        "        train_before = len(train_df)\n",
        "        val_before = len(val_df)\n",
        "        test_before = len(test_df)\n",
        "        \n",
        "        train_df = train_df[train_df[value_col] >= OUTAGE_THRESHOLD].reset_index(drop=True)\n",
        "        val_df = val_df[val_df[value_col] >= OUTAGE_THRESHOLD].reset_index(drop=True)\n",
        "        test_df = test_df[test_df[value_col] >= OUTAGE_THRESHOLD].reset_index(drop=True)\n",
        "        \n",
        "        train_pct_removed = 100*(train_before - len(train_df))/train_before\n",
        "        val_pct_removed = 100*(val_before - len(val_df))/val_before\n",
        "        test_pct_removed = 100*(test_before - len(test_df))/test_before\n",
        "        \n",
        "        print(f\"   Train: {train_before} ‚Üí {len(train_df)} (-{train_before - len(train_df)}, {train_pct_removed:.1f}%)\")\n",
        "        print(f\"   Val:   {val_before} ‚Üí {len(val_df)} (-{val_before - len(val_df)}, {val_pct_removed:.1f}%)\")\n",
        "        print(f\"   Test:  {test_before} ‚Üí {len(test_df)} (-{test_before - len(test_df)}, {test_pct_removed:.1f}%)\")\n",
        "        \n",
        "        # Warning for excessive data loss\n",
        "        if train_pct_removed > 30 or val_pct_removed > 30 or test_pct_removed > 30:\n",
        "            print(f\"   ‚ö†Ô∏è  WARNING: >30% data removed! Results may be less reliable.\")\n",
        "        else:\n",
        "            print(f\"   ‚úÖ Outage periods removed!\")\n",
        "\n",
        "print(f\"\\nüìä Final dataset sizes:\")\n",
        "print(f\"   Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "print(f\"   Value column: {value_col}\")\n",
        "print(f\"   Features: {len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eec36f1",
      "metadata": {
        "id": "2eec36f1"
      },
      "source": [
        "## üîß Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a0a03164",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0a03164",
        "outputId": "1702ee33-e67a-470d-fdcb-f51a1ae25f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Data prepared:\n",
            "   X_train_seq: (7720, 24, 31)\n",
            "   y_test_seq: (1636,)\n"
          ]
        }
      ],
      "source": [
        "def create_sequences(data, target, seq_length):\n",
        "    \"\"\"Create sequences for RNN models\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(target[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Scale data\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(train_df[feature_cols])\n",
        "y_train = scaler_y.fit_transform(train_df[[value_col]])\n",
        "\n",
        "X_val = scaler_X.transform(val_df[feature_cols])\n",
        "y_val = scaler_y.transform(val_df[[value_col]])\n",
        "\n",
        "X_test = scaler_X.transform(test_df[feature_cols])\n",
        "y_test_orig = test_df[value_col].values\n",
        "\n",
        "# Create sequences\n",
        "seq_length = 24\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.flatten(), seq_length)\n",
        "X_val_seq, y_val_seq = create_sequences(X_val, y_val.flatten(), seq_length)\n",
        "X_test_seq, _ = create_sequences(X_test, np.zeros(len(X_test)), seq_length)\n",
        "y_test_seq = y_test_orig[seq_length:]\n",
        "\n",
        "print(f\"‚úÖ Data prepared:\")\n",
        "print(f\"   X_train_seq: {X_train_seq.shape}\")\n",
        "print(f\"   y_test_seq: {y_test_seq.shape}\")\n",
        "\n",
        "# Storage for results\n",
        "all_results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30aa764",
      "metadata": {
        "id": "b30aa764"
      },
      "source": [
        "---\n",
        "# üîµ BASIC MODELS\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f42898",
      "metadata": {
        "id": "38f42898"
      },
      "source": [
        "## üß™ Model 1: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3168efd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3168efd2",
        "outputId": "0126c553-efeb-41ad-aa9c-86712567365f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üß™ MODEL 1: LSTM\n",
            "================================================================================\n",
            "\n",
            "üìä LSTM RESULTS:\n",
            "   R¬≤ = -1.1815\n",
            "   RMSE = 222.51\n",
            "   MAE = 186.78\n",
            "   Time = 15.5s\n"
          ]
        }
      ],
      "source": [
        "if RUN_BASIC:\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 1: LSTM\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Build\n",
        "    model_lstm = keras.Sequential([\n",
        "        layers.LSTM(64, activation='relu', return_sequences=False,\n",
        "                   input_shape=(seq_length, len(feature_cols))),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model_lstm.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse')\n",
        "\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    history = model_lstm.fit(\n",
        "        X_train_seq, y_train_seq,\n",
        "        validation_data=(X_val_seq, y_val_seq),\n",
        "        epochs=100, batch_size=64,\n",
        "        callbacks=[\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "        ],\n",
        "        verbose=0\n",
        "    )\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_scaled = model_lstm.predict(X_test_seq, verbose=0)\n",
        "    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
        "\n",
        "    r2 = r2_score(y_test_seq, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_seq, y_pred))\n",
        "    mae = mean_absolute_error(y_test_seq, y_pred)\n",
        "\n",
        "    print(f\"\\nüìä LSTM RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2:.4f}\")\n",
        "    print(f\"   RMSE = {rmse:.2f}\")\n",
        "    print(f\"   MAE = {mae:.2f}\")\n",
        "    print(f\"   Time = {train_time:.1f}s\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'LSTM',\n",
        "        'R¬≤': r2,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'Time (s)': train_time\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b77a30",
      "metadata": {
        "id": "07b77a30"
      },
      "source": [
        "## üß™ Model 2: GRU (‚≠ê NEU!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d7f85ea4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7f85ea4",
        "outputId": "bdc094be-3ad9-4ed8-9c34-76899042226b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üß™ MODEL 2: GRU (Gated Recurrent Unit)\n",
            "================================================================================\n",
            "\n",
            "üìä GRU RESULTS:\n",
            "   R¬≤ = 0.1597\n",
            "   RMSE = 138.09\n",
            "   MAE = 99.53\n",
            "   Time = 14.3s\n",
            "\n",
            "üí° GRU vs LSTM: 7.9% faster!\n"
          ]
        }
      ],
      "source": [
        "if RUN_BASIC:\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 2: GRU (Gated Recurrent Unit)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Build GRU (schneller als LSTM!)\n",
        "    model_gru = keras.Sequential([\n",
        "        layers.GRU(64, activation='relu', return_sequences=False,\n",
        "                  input_shape=(seq_length, len(feature_cols))),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model_gru.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse')\n",
        "\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    history = model_gru.fit(\n",
        "        X_train_seq, y_train_seq,\n",
        "        validation_data=(X_val_seq, y_val_seq),\n",
        "        epochs=100, batch_size=64,\n",
        "        callbacks=[\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "        ],\n",
        "        verbose=0\n",
        "    )\n",
        "    train_time_gru = time.time() - start\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_gru_scaled = model_gru.predict(X_test_seq, verbose=0)\n",
        "    y_pred_gru = scaler_y.inverse_transform(y_pred_gru_scaled).flatten()\n",
        "\n",
        "    r2_gru = r2_score(y_test_seq, y_pred_gru)\n",
        "    rmse_gru = np.sqrt(mean_squared_error(y_test_seq, y_pred_gru))\n",
        "    mae_gru = mean_absolute_error(y_test_seq, y_pred_gru)\n",
        "\n",
        "    print(f\"\\nüìä GRU RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_gru:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_gru:.2f}\")\n",
        "    print(f\"   MAE = {mae_gru:.2f}\")\n",
        "    print(f\"   Time = {train_time_gru:.1f}s\")\n",
        "    print(f\"\\nüí° GRU vs LSTM: {((train_time - train_time_gru) / train_time * 100):.1f}% faster!\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'GRU',\n",
        "        'R¬≤': r2_gru,\n",
        "        'RMSE': rmse_gru,\n",
        "        'MAE': mae_gru,\n",
        "        'Time (s)': train_time_gru\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a5145e",
      "metadata": {
        "id": "53a5145e"
      },
      "source": [
        "## üß™ Model 3: Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b3823262",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3823262",
        "outputId": "b3053aa9-1f1e-4392-9edf-329efd43d4c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üß™ MODEL 3: Bi-LSTM (Bidirectional)\n",
            "================================================================================\n",
            "\n",
            "üìä BI-LSTM RESULTS:\n",
            "   R¬≤ = -0.0224\n",
            "   RMSE = 152.33\n",
            "   MAE = 102.95\n",
            "   Time = 30.6s\n"
          ]
        }
      ],
      "source": [
        "if RUN_BASIC:\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 3: Bi-LSTM (Bidirectional)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Build\n",
        "    model_bilstm = keras.Sequential([\n",
        "        layers.Bidirectional(layers.LSTM(64, activation='relu', return_sequences=True),\n",
        "                           input_shape=(seq_length, len(feature_cols))),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Bidirectional(layers.LSTM(32, activation='relu')),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model_bilstm.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse')\n",
        "\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    history = model_bilstm.fit(\n",
        "        X_train_seq, y_train_seq,\n",
        "        validation_data=(X_val_seq, y_val_seq),\n",
        "        epochs=100, batch_size=64,\n",
        "        callbacks=[\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "        ],\n",
        "        verbose=0\n",
        "    )\n",
        "    train_time_bilstm = time.time() - start\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_bilstm_scaled = model_bilstm.predict(X_test_seq, verbose=0)\n",
        "    y_pred_bilstm = scaler_y.inverse_transform(y_pred_bilstm_scaled).flatten()\n",
        "\n",
        "    r2_bilstm = r2_score(y_test_seq, y_pred_bilstm)\n",
        "    rmse_bilstm = np.sqrt(mean_squared_error(y_test_seq, y_pred_bilstm))\n",
        "    mae_bilstm = mean_absolute_error(y_test_seq, y_pred_bilstm)\n",
        "\n",
        "    print(f\"\\nüìä BI-LSTM RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_bilstm:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_bilstm:.2f}\")\n",
        "    print(f\"   MAE = {mae_bilstm:.2f}\")\n",
        "    print(f\"   Time = {train_time_bilstm:.1f}s\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'Bi-LSTM',\n",
        "        'R¬≤': r2_bilstm,\n",
        "        'RMSE': rmse_bilstm,\n",
        "        'MAE': mae_bilstm,\n",
        "        'Time (s)': train_time_bilstm\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81bdb7d",
      "metadata": {
        "id": "e81bdb7d"
      },
      "source": [
        "---\n",
        "# üü¢ GENERATIVE MODELS\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76712816",
      "metadata": {
        "id": "76712816"
      },
      "source": [
        "## üß™ Model 4: Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d23f548f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d23f548f",
        "outputId": "0106d0d0-5247-4be7-dcbd-eb47c101bf9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üß™ MODEL 4: Autoencoder\n",
            "================================================================================\n",
            "\n",
            "üìä AUTOENCODER RESULTS:\n",
            "   R¬≤ = -1.3651\n",
            "   RMSE = 231.68\n",
            "   MAE = 166.32\n",
            "   Time = 75.7s\n"
          ]
        }
      ],
      "source": [
        "if RUN_GENERATIVE:\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 4: Autoencoder\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Build Autoencoder\n",
        "    encoding_dim = 32\n",
        "    input_ae = layers.Input(shape=(seq_length, len(feature_cols)))\n",
        "    encoded = layers.LSTM(64, activation='relu', return_sequences=True)(input_ae)\n",
        "    encoded = layers.LSTM(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "    decoded = layers.RepeatVector(seq_length)(encoded)\n",
        "    decoded = layers.LSTM(64, activation='relu', return_sequences=True)(decoded)\n",
        "    decoded = layers.TimeDistributed(layers.Dense(len(feature_cols)))(decoded)\n",
        "\n",
        "    autoencoder = keras.Model(input_ae, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    encoder = keras.Model(input_ae, encoded)\n",
        "\n",
        "    # Train Autoencoder\n",
        "    start = time.time()\n",
        "    autoencoder.fit(\n",
        "        X_train_seq, X_train_seq,\n",
        "        validation_data=(X_val_seq, X_val_seq),\n",
        "        epochs=50, batch_size=64,\n",
        "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Train Forecast Head\n",
        "    encoded_train = encoder.predict(X_train_seq, verbose=0)\n",
        "    encoded_val = encoder.predict(X_val_seq, verbose=0)\n",
        "    encoded_test = encoder.predict(X_test_seq, verbose=0)\n",
        "\n",
        "    forecast_head = keras.Sequential([\n",
        "        layers.Dense(16, activation='relu', input_shape=(encoding_dim,)),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    forecast_head.compile(optimizer='adam', loss='mse')\n",
        "    forecast_head.fit(\n",
        "        encoded_train, y_train_seq,\n",
        "        validation_data=(encoded_val, y_val_seq),\n",
        "        epochs=50, batch_size=64,\n",
        "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
        "        verbose=0\n",
        "    )\n",
        "    train_time_ae = time.time() - start\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_ae_scaled = forecast_head.predict(encoded_test, verbose=0)\n",
        "    y_pred_ae = scaler_y.inverse_transform(y_pred_ae_scaled).flatten()\n",
        "\n",
        "    r2_ae = r2_score(y_test_seq, y_pred_ae)\n",
        "    rmse_ae = np.sqrt(mean_squared_error(y_test_seq, y_pred_ae))\n",
        "    mae_ae = mean_absolute_error(y_test_seq, y_pred_ae)\n",
        "\n",
        "    print(f\"\\nüìä AUTOENCODER RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_ae:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_ae:.2f}\")\n",
        "    print(f\"   MAE = {mae_ae:.2f}\")\n",
        "    print(f\"   Time = {train_time_ae:.1f}s\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'Autoencoder',\n",
        "        'R¬≤': r2_ae,\n",
        "        'RMSE': rmse_ae,\n",
        "        'MAE': mae_ae,\n",
        "        'Time (s)': train_time_ae\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d2ce7a",
      "metadata": {
        "id": "64d2ce7a"
      },
      "source": [
        "## üß™ Model 5: VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "712a98ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "712a98ce",
        "outputId": "5c6e83e9-8644-43c6-ec0c-b18bab703f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üß™ MODEL 5: VAE (Variational Autoencoder)\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-999529111.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     ])\n\u001b[1;32m    116\u001b[0m     \u001b[0mforecast_head_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     forecast_head_vae.fit(\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mencoded_vae_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_vae_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     concrete_function = tracing_options.function_cache.lookup(\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_func_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mFunctionContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0mdispatch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdispatch_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/core/function/polymorphism/type_dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;34m\"\"\"Returns the most specific supertype target if it exists in the table.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# For known exact matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_table\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if RUN_GENERATIVE:\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 5: VAE (Variational Autoencoder)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Build VAE parts as separate functional models\n",
        "    latent_dim = 32\n",
        "\n",
        "    # Encoder Model\n",
        "    input_vae_enc = layers.Input(shape=(seq_length, len(feature_cols)))\n",
        "    x_enc = layers.LSTM(64, activation='relu', return_sequences=True)(input_vae_enc)\n",
        "    x_enc = layers.LSTM(64, activation='relu')(x_enc)\n",
        "\n",
        "    z_mean = layers.Dense(latent_dim)(x_enc)\n",
        "    z_log_var = layers.Dense(latent_dim)(x_enc)\n",
        "\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "    encoder_model = keras.Model(input_vae_enc, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_input = layers.Input(shape=(latent_dim,))\n",
        "    x_decoded = layers.RepeatVector(seq_length)(decoder_input)\n",
        "    x_decoded = layers.LSTM(64, activation='relu', return_sequences=True)(x_decoded)\n",
        "    x_decoded = layers.TimeDistributed(layers.Dense(len(feature_cols)))(x_decoded)\n",
        "    decoder_model = keras.Model(decoder_input, x_decoded, name=\"decoder\")\n",
        "\n",
        "    # Custom VAE Model subclass\n",
        "    class CustomVAE(keras.Model):\n",
        "        def __init__(self, encoder, decoder, **kwargs):\n",
        "            super().__init__(**kwargs)\n",
        "            self.encoder = encoder\n",
        "            self.decoder = decoder\n",
        "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "            self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "            self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "        def call(self, inputs):\n",
        "            _, _, z = self.encoder(inputs)\n",
        "            reconstruction = self.decoder(z)\n",
        "            return reconstruction\n",
        "\n",
        "        def train_step(self, data):\n",
        "            # Unpack the data. We use X_train_seq as both input and target for reconstruction.\n",
        "            if isinstance(data, tuple):\n",
        "                inputs, _ = data\n",
        "            else:\n",
        "                inputs = data\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                z_mean, z_log_var, z = self.encoder(inputs)\n",
        "                reconstruction = self.decoder(z)\n",
        "\n",
        "                # Calculate reconstruction loss\n",
        "                reconstruction_loss = keras.ops.mean(keras.ops.sum(keras.losses.mse(inputs, reconstruction), axis=-1))\n",
        "\n",
        "                # Calculate KL divergence loss\n",
        "                kl_loss = -0.5 * keras.ops.mean(1 + z_log_var - keras.ops.square(z_mean) - keras.ops.exp(z_log_var))\n",
        "\n",
        "                total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "            grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "            self.total_loss_tracker.update_state(total_loss)\n",
        "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "            self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "            return {\n",
        "                \"loss\": self.total_loss_tracker.result(),\n",
        "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "            }\n",
        "\n",
        "        @property\n",
        "        def metrics(self):\n",
        "            return [\n",
        "                self.total_loss_tracker,\n",
        "                self.reconstruction_loss_tracker,\n",
        "                self.kl_loss_tracker,\n",
        "            ]\n",
        "\n",
        "    # Instantiate the custom VAE model\n",
        "    vae = CustomVAE(encoder_model, decoder_model)\n",
        "    # Provide a dummy loss function to satisfy the compile() check.\n",
        "    # The actual loss computation is handled within the custom train_step.\n",
        "    vae.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())\n",
        "\n",
        "    # The encoder used for generating latent space representations for the forecast head\n",
        "    prediction_encoder_vae = keras.Model(input_vae_enc, z_mean, name=\"prediction_encoder_vae\")\n",
        "\n",
        "    # Train VAE\n",
        "    start = time.time()\n",
        "    vae.fit(\n",
        "        X_train_seq, X_train_seq, # VAE trains on its inputs\n",
        "        validation_data=(X_val_seq, X_val_seq),\n",
        "        epochs=50, batch_size=64,\n",
        "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Train Forecast Head\n",
        "    encoded_vae_train = prediction_encoder_vae.predict(X_train_seq, verbose=0)\n",
        "    encoded_vae_val = prediction_encoder_vae.predict(X_val_seq, verbose=0)\n",
        "    encoded_vae_test = prediction_encoder_vae.predict(X_test_seq, verbose=0)\n",
        "\n",
        "    forecast_head_vae = keras.Sequential([\n",
        "        layers.Dense(16, activation='relu', input_shape=(latent_dim,)),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    forecast_head_vae.compile(optimizer='adam', loss='mse')\n",
        "    forecast_head_vae.fit(\n",
        "        encoded_vae_train, y_train_seq,\n",
        "        validation_data=(encoded_vae_val, y_val_seq),\n",
        "        epochs=50, batch_size=64,\n",
        "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
        "        verbose=0\n",
        "    )\n",
        "    train_time_vae = time.time() - start\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_vae_scaled = forecast_head_vae.predict(encoded_vae_test, verbose=0)\n",
        "    y_pred_vae = scaler_y.inverse_transform(y_pred_vae_scaled).flatten()\n",
        "\n",
        "    r2_vae = r2_score(y_test_seq, y_pred_vae)\n",
        "    rmse_vae = np.sqrt(mean_squared_error(y_test_seq, y_pred_vae))\n",
        "    mae_vae = mean_absolute_error(y_test_seq, y_pred_vae)\n",
        "\n",
        "    print(f\"\\nüìä VAE RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_vae:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_vae:.2f}\")\n",
        "    print(f\"   MAE = {mae_vae:.2f}\")\n",
        "    print(f\"   Time = {train_time_vae:.1f}s\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'VAE',\n",
        "        'R¬≤': r2_vae,\n",
        "        'RMSE': rmse_vae,\n",
        "        'MAE': mae_vae,\n",
        "        'Time (s)': train_time_vae\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1fa817",
      "metadata": {
        "id": "1f1fa817"
      },
      "source": [
        "---\n",
        "# üî¥ ADVANCED MODELS (Darts Framework)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f5ec5b",
      "metadata": {
        "id": "06f5ec5b"
      },
      "outputs": [],
      "source": [
        "# Prepare Darts TimeSeries (needed for N-BEATS, N-HiTS, DeepAR, TFT)\n",
        "if RUN_ADVANCED or RUN_PROBABILISTIC or RUN_TFT:\n",
        "    from darts import TimeSeries\n",
        "    from darts.dataprocessing.transformers import Scaler as DartsScaler\n",
        "\n",
        "    ts_train = TimeSeries.from_values(train_df[value_col].values)\n",
        "    ts_val = TimeSeries.from_values(val_df[value_col].values)\n",
        "    ts_test = TimeSeries.from_values(test_df[value_col].values)\n",
        "\n",
        "    scaler_darts = DartsScaler()\n",
        "    ts_train_scaled = scaler_darts.fit_transform(ts_train)\n",
        "    ts_val_scaled = scaler_darts.transform(ts_val)\n",
        "\n",
        "    print(\"‚úÖ Darts TimeSeries prepared\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d97b09f2",
      "metadata": {
        "id": "d97b09f2"
      },
      "source": [
        "## üß™ Model 6: N-BEATS (‚≠ê NEU!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49be663f",
      "metadata": {
        "id": "49be663f"
      },
      "outputs": [],
      "source": [
        "if RUN_ADVANCED:\n",
        "    from darts.models import NBEATSModel\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 6: N-BEATS (Neural Basis Expansion)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model_nbeats = NBEATSModel(\n",
        "        input_chunk_length=24,\n",
        "        output_chunk_length=1,\n",
        "        n_epochs=100,\n",
        "        batch_size=64,\n",
        "        pl_trainer_kwargs={\n",
        "            \"accelerator\": \"gpu\",\n",
        "            \"devices\": 1,\n",
        "            \"enable_progress_bar\": False\n",
        "        },\n",
        "        force_reset=True,\n",
        "        save_checkpoints=False\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "    model_nbeats.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
        "    train_time_nbeats = time.time() - start\n",
        "\n",
        "    # Predict\n",
        "    n_pred = len(ts_test)\n",
        "    pred_nbeats_scaled = model_nbeats.predict(n=n_pred, series=ts_train_scaled)\n",
        "    pred_nbeats = scaler_darts.inverse_transform(pred_nbeats_scaled)\n",
        "\n",
        "    y_pred_nbeats = pred_nbeats.values().flatten()\n",
        "    y_test_nbeats = ts_test.values().flatten()\n",
        "    min_len = min(len(y_pred_nbeats), len(y_test_nbeats))\n",
        "    y_pred_nbeats = y_pred_nbeats[:min_len]\n",
        "    y_test_nbeats = y_test_nbeats[:min_len]\n",
        "\n",
        "    r2_nbeats = r2_score(y_test_nbeats, y_pred_nbeats)\n",
        "    rmse_nbeats = np.sqrt(mean_squared_error(y_test_nbeats, y_pred_nbeats))\n",
        "    mae_nbeats = mean_absolute_error(y_test_nbeats, y_pred_nbeats)\n",
        "\n",
        "    print(f\"\\nüìä N-BEATS RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_nbeats:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_nbeats:.2f}\")\n",
        "    print(f\"   MAE = {mae_nbeats:.2f}\")\n",
        "    print(f\"   Time = {train_time_nbeats:.1f}s\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'N-BEATS',\n",
        "        'R¬≤': r2_nbeats,\n",
        "        'RMSE': rmse_nbeats,\n",
        "        'MAE': mae_nbeats,\n",
        "        'Time (s)': train_time_nbeats\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6ac4199",
      "metadata": {
        "id": "a6ac4199"
      },
      "source": [
        "## üß™ Model 7: N-HiTS (‚≠ê NEU!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27c5475",
      "metadata": {
        "id": "f27c5475"
      },
      "outputs": [],
      "source": [
        "if RUN_ADVANCED:\n",
        "    from darts.models import NHiTSModel\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 7: N-HiTS (Hierarchical Interpolation)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model_nhits = NHiTSModel(\n",
        "        input_chunk_length=24,\n",
        "        output_chunk_length=1,\n",
        "        n_epochs=100,\n",
        "        batch_size=64,\n",
        "        pl_trainer_kwargs={\n",
        "            \"accelerator\": \"gpu\",\n",
        "            \"devices\": 1,\n",
        "            \"enable_progress_bar\": False\n",
        "        },\n",
        "        force_reset=True,\n",
        "        save_checkpoints=False\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "    model_nhits.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
        "    train_time_nhits = time.time() - start\n",
        "\n",
        "    # Predict\n",
        "    pred_nhits_scaled = model_nhits.predict(n=n_pred, series=ts_train_scaled)\n",
        "    pred_nhits = scaler_darts.inverse_transform(pred_nhits_scaled)\n",
        "\n",
        "    y_pred_nhits = pred_nhits.values().flatten()\n",
        "    y_test_nhits = ts_test.values().flatten()\n",
        "    min_len = min(len(y_pred_nhits), len(y_test_nhits))\n",
        "    y_pred_nhits = y_pred_nhits[:min_len]\n",
        "    y_test_nhits = y_test_nhits[:min_len]\n",
        "\n",
        "    r2_nhits = r2_score(y_test_nhits, y_pred_nhits)\n",
        "    rmse_nhits = np.sqrt(mean_squared_error(y_test_nhits, y_pred_nhits))\n",
        "    mae_nhits = mean_absolute_error(y_test_nhits, y_pred_nhits)\n",
        "\n",
        "    print(f\"\\nüìä N-HiTS RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_nhits:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_nhits:.2f}\")\n",
        "    print(f\"   MAE = {mae_nhits:.2f}\")\n",
        "    print(f\"   Time = {train_time_nhits:.1f}s\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'N-HiTS',\n",
        "        'R¬≤': r2_nhits,\n",
        "        'RMSE': rmse_nhits,\n",
        "        'MAE': mae_nhits,\n",
        "        'Time (s)': train_time_nhits\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea7afb3",
      "metadata": {
        "id": "fea7afb3"
      },
      "source": [
        "## üß™ Model 8: DeepAR (‚≠ê NEU! - Probabilistisch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106816d8",
      "metadata": {
        "id": "106816d8"
      },
      "outputs": [],
      "source": [
        "if RUN_PROBABILISTIC:\n",
        "    from darts.models import RNNModel\n",
        "    from darts.utils.likelihood_models import GaussianLikelihood # Import GaussianLikelihood\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 8: DeepAR (Probabilistic Forecasting)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # DeepAR via Darts' RNNModel with probabilistic output\n",
        "    model_deepar = RNNModel(\n",
        "        model='LSTM',\n",
        "        input_chunk_length=24,\n",
        "        training_length=48,\n",
        "        n_epochs=100,\n",
        "        batch_size=64,\n",
        "        hidden_dim=64,\n",
        "        n_rnn_layers=2,\n",
        "        dropout=0.2,\n",
        "        likelihood=GaussianLikelihood(),  # Pass an instance of GaussianLikelihood\n",
        "        pl_trainer_kwargs={\n",
        "            \"accelerator\": \"gpu\",\n",
        "            \"devices\": 1,\n",
        "            \"enable_progress_bar\": False\n",
        "        },\n",
        "        force_reset=True,\n",
        "        save_checkpoints=False\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "    model_deepar.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
        "    train_time_deepar = time.time() - start\n",
        "\n",
        "    # Predict (median)\n",
        "    pred_deepar_scaled = model_deepar.predict(n=n_pred, series=ts_train_scaled, num_samples=100)\n",
        "    pred_deepar = scaler_darts.inverse_transform(pred_deepar_scaled)\n",
        "\n",
        "    y_pred_deepar = pred_deepar.values().flatten()\n",
        "    y_test_deepar = ts_test.values().flatten()\n",
        "    min_len = min(len(y_pred_deepar), len(y_test_deepar))\n",
        "    y_pred_deepar = y_pred_deepar[:min_len]\n",
        "    y_test_deepar = y_test_deepar[:min_len]\n",
        "\n",
        "    r2_deepar = r2_score(y_test_deepar, y_pred_deepar)\n",
        "    rmse_deepar = np.sqrt(mean_squared_error(y_test_deepar, y_pred_deepar))\n",
        "    mae_deepar = mean_absolute_error(y_test_deepar, y_pred_deepar)\n",
        "\n",
        "    print(f\"\\nüìä DEEPAR RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_deepar:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_deepar:.2f}\")\n",
        "    print(f\"   MAE = {mae_deepar:.2f}\")\n",
        "    print(f\"   Time = {train_time_deepar:.1f}s\")\n",
        "    print(f\"\\nüí° DeepAR liefert probabilistische Forecasts (Konfidenzintervalle m√∂glich!)\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'DeepAR',\n",
        "        'R¬≤': r2_deepar,\n",
        "        'RMSE': rmse_deepar,\n",
        "        'MAE': mae_deepar,\n",
        "        'Time (s)': train_time_deepar\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b113e4",
      "metadata": {
        "id": "96b113e4"
      },
      "source": [
        "## üß™ Model 9: TFT (‚≠ê NEU! - State-of-the-Art)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2769f799",
      "metadata": {
        "id": "2769f799"
      },
      "outputs": [],
      "source": [
        "if RUN_TFT:\n",
        "    from darts.models import TFTModel\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"üß™ MODEL 9: TFT (Temporal Fusion Transformer)\")\n",
        "    print(\"‚ö†Ô∏è WARNING: This can take 30-45 minutes!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model_tft = TFTModel(\n",
        "        input_chunk_length=24,\n",
        "        output_chunk_length=1,\n",
        "        hidden_size=64,\n",
        "        lstm_layers=2,\n",
        "        num_attention_heads=4,\n",
        "        dropout=0.1,\n",
        "        batch_size=64,\n",
        "        n_epochs=100,\n",
        "        pl_trainer_kwargs={\n",
        "            \"accelerator\": \"gpu\",\n",
        "            \"devices\": 1,\n",
        "            \"enable_progress_bar\": True\n",
        "        },\n",
        "        force_reset=True,\n",
        "        save_checkpoints=False\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "    model_tft.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
        "    train_time_tft = time.time() - start\n",
        "\n",
        "    # Predict\n",
        "    pred_tft_scaled = model_tft.predict(n=n_pred, series=ts_train_scaled)\n",
        "    pred_tft = scaler_darts.inverse_transform(pred_tft_scaled)\n",
        "\n",
        "    y_pred_tft = pred_tft.values().flatten()\n",
        "    y_test_tft = ts_test.values().flatten()\n",
        "    min_len = min(len(y_pred_tft), len(y_test_tft))\n",
        "    y_pred_tft = y_pred_tft[:min_len]\n",
        "    y_test_tft = y_test_tft[:min_len]\n",
        "\n",
        "    r2_tft = r2_score(y_test_tft, y_pred_tft)\n",
        "    rmse_tft = np.sqrt(mean_squared_error(y_test_tft, y_pred_tft))\n",
        "    mae_tft = mean_absolute_error(y_test_tft, y_pred_tft)\n",
        "\n",
        "    print(f\"\\nüìä TFT RESULTS:\")\n",
        "    print(f\"   R¬≤ = {r2_tft:.4f}\")\n",
        "    print(f\"   RMSE = {rmse_tft:.2f}\")\n",
        "    print(f\"   MAE = {mae_tft:.2f}\")\n",
        "    print(f\"   Time = {train_time_tft:.1f}s ({train_time_tft/60:.1f} min)\")\n",
        "    print(f\"\\nüèÜ TFT: State-of-the-Art Transformer-basiert!\")\n",
        "\n",
        "    all_results.append({\n",
        "        'Model': 'TFT',\n",
        "        'R¬≤': r2_tft,\n",
        "        'RMSE': rmse_tft,\n",
        "        'MAE': mae_tft,\n",
        "        'Time (s)': train_time_tft\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11d4921",
      "metadata": {
        "id": "e11d4921"
      },
      "source": [
        "---\n",
        "# üìä FINAL SUMMARY\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7428e3a3",
      "metadata": {
        "id": "7428e3a3"
      },
      "outputs": [],
      "source": [
        "# Create summary DataFrame\n",
        "if all_results:\n",
        "    results_df = pd.DataFrame(all_results)\n",
        "    results_df = results_df.sort_values('R¬≤', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(f\"üèÜ FINAL RESULTS: {SERIES_NAME.upper()}\")\n",
        "    print(\"=\"*100)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"ü•á BEST MODEL:\")\n",
        "    print(\"=\"*100)\n",
        "    best = results_df.iloc[0]\n",
        "    print(f\"   Model: {best['Model']}\")\n",
        "    print(f\"   R¬≤ = {best['R¬≤']:.4f}\")\n",
        "    print(f\"   RMSE = {best['RMSE']:.2f}\")\n",
        "    print(f\"   MAE = {best['MAE']:.2f}\")\n",
        "    print(f\"   Training Time = {best['Time (s)']:.1f}s ({best['Time (s)']/60:.1f} min)\")\n",
        "\n",
        "    # Save results\n",
        "    output_file = f'results/metrics/deep_learning_extended_{SERIES_NAME}.csv'\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"\\nüíæ Ergebnisse gespeichert: {output_file}\")\n",
        "\n",
        "    # Performance insights\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"üí° KEY INSIGHTS:\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    if 'GRU' in results_df['Model'].values and 'LSTM' in results_df['Model'].values:\n",
        "        gru_r2 = results_df[results_df['Model'] == 'GRU']['R¬≤'].values[0]\n",
        "        lstm_r2 = results_df[results_df['Model'] == 'LSTM']['R¬≤'].values[0]\n",
        "        print(f\"   üìå GRU vs LSTM: R¬≤ {gru_r2:.4f} vs {lstm_r2:.4f}\")\n",
        "        if gru_r2 > lstm_r2:\n",
        "            print(f\"      ‚Üí GRU ist {((gru_r2 - lstm_r2) / lstm_r2 * 100):.2f}% besser!\")\n",
        "\n",
        "    print(f\"\\n   üìå Durchschnittliche R¬≤: {results_df['R¬≤'].mean():.4f}\")\n",
        "    print(f\"   üìå Schnellstes Modell: {results_df.loc[results_df['Time (s)'].idxmin(), 'Model']} ({results_df['Time (s)'].min():.1f}s)\")\n",
        "    print(f\"   üìå Langsamtes Modell: {results_df.loc[results_df['Time (s)'].idxmax(), 'Model']} ({results_df['Time (s)'].max():.1f}s)\")\n",
        "\n",
        "    negative_r2 = results_df[results_df['R¬≤'] < 0]\n",
        "    if len(negative_r2) > 0:\n",
        "        print(f\"\\n   ‚ö†Ô∏è Modelle mit negativem R¬≤ (schlecht konfiguriert):\")\n",
        "        for _, row in negative_r2.iterrows():\n",
        "            print(f\"      - {row['Model']}: R¬≤ = {row['R¬≤']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"‚úÖ EXPERIMENT ABGESCHLOSSEN!\")\n",
        "    print(\"=\"*100)\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Keine Modelle wurden ausgef√ºhrt. Bitte aktiviere mindestens eine Modellkategorie!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3273543",
      "metadata": {
        "id": "d3273543"
      },
      "source": [
        "## üìù Empfehlungen\n",
        "\n",
        "### F√ºr Produktion:\n",
        "1. **H√∂chste Genauigkeit**: Bestes Modell nach R¬≤ w√§hlen\n",
        "2. **Balance Speed/Accuracy**: GRU oder Bi-LSTM\n",
        "3. **Unsicherheitssch√§tzung**: DeepAR oder VAE\n",
        "4. **State-of-the-Art**: TFT (wenn Rechenzeit kein Problem)\n",
        "\n",
        "### F√ºr weitere Experimente:\n",
        "- **TimeGAN**: Aktiviere `RUN_GAN = True` (sehr experimentell)\n",
        "- **Hyperparameter-Tuning**: Optimiere die besten 2-3 Modelle weiter\n",
        "- **Ensemble**: Kombiniere mehrere Top-Modelle"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
