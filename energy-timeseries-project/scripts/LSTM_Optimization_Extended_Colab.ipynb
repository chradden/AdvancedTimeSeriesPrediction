{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bee9d27",
   "metadata": {},
   "source": [
    "# ğŸš€ Advanced Deep Learning Models - Extended Edition\n",
    "\n",
    "**Komplette Suite moderner DL-Architekturen mit GPU-Beschleunigung**\n",
    "\n",
    "## ğŸ“‹ Modelle in diesem Notebook:\n",
    "\n",
    "### Basis DL-Modelle:\n",
    "1. **LSTM** - Standard Long Short-Term Memory\n",
    "2. **Bi-LSTM** - Bidirectional LSTM\n",
    "3. **GRU** - Gated Recurrent Unit (schneller als LSTM)\n",
    "\n",
    "### Generative Modelle:\n",
    "4. **Autoencoder** - Dimensionsreduktion + Forecasting\n",
    "5. **VAE** - Variational Autoencoder (mit UnsicherheitsschÃ¤tzung)\n",
    "6. **TimeGAN** - Generative Adversarial Network fÃ¼r Zeitreihen\n",
    "\n",
    "### Advanced/Transformer:\n",
    "7. **N-BEATS** - Neural Basis Expansion\n",
    "8. **N-HiTS** - Hierarchical Interpolation\n",
    "9. **DeepAR** - Amazon's probabilistisches Modell\n",
    "10. **TFT** - Temporal Fusion Transformer (State-of-the-Art)\n",
    "\n",
    "### Hinweise zur Rechenzeit (GPU T4):\n",
    "- âœ… **Schnell** (<5 Min): LSTM, GRU, Bi-LSTM, Autoencoder, VAE\n",
    "- âš ï¸ **Mittel** (5-15 Min): N-BEATS, N-HiTS, DeepAR\n",
    "- ğŸ”¥ **Langsam** (15-45 Min): TFT, TimeGAN\n",
    "\n",
    "**Setup:** Runtime â†’ Change runtime type â†’ GPU (T4 empfohlen, A100 fÃ¼r TFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4be948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"\\nğŸš€ GPU should show above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Repository\n",
    "!git clone https://github.com/chradden/AdvancedTimeSeriesPrediction.git\n",
    "%cd AdvancedTimeSeriesPrediction/energy-timeseries-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ALL Dependencies\n",
    "print(\"ğŸ“¦ Installing packages (this may take 2-3 minutes)...\")\n",
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn\n",
    "!pip install -q tensorflow keras pytorch-lightning\n",
    "!pip install -q 'darts[torch]'  # N-BEATS, N-HiTS, TFT, DeepAR\n",
    "!pip install -q gluonts  # DeepAR alternative\n",
    "print(\"âœ… Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# GPU Config\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU found - training will be slow!\")\n",
    "\n",
    "print(\"\\nğŸ“Š All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f508784",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "SERIES_NAME = 'solar'  # Ã„ndern: 'solar', 'wind_offshore', 'wind_onshore', 'price', 'consumption'\n",
    "\n",
    "# Model Selection (setze auf False um Modelle zu Ã¼berspringen)\n",
    "RUN_BASIC = True          # LSTM, GRU, Bi-LSTM (~5 min)\n",
    "RUN_GENERATIVE = True     # Autoencoder, VAE (~5 min)\n",
    "RUN_GAN = False           # TimeGAN (~30 min, experimentell)\n",
    "RUN_ADVANCED = True       # N-BEATS, N-HiTS (~10 min)\n",
    "RUN_PROBABILISTIC = True  # DeepAR (~10 min)\n",
    "RUN_TFT = False           # Temporal Fusion Transformer (~30-45 min)\n",
    "\n",
    "print(f\"ğŸ“Š Zeitreihe: {SERIES_NAME.upper()}\")\n",
    "print(f\"\\nğŸ¯ Aktivierte Modelle:\")\n",
    "if RUN_BASIC: print(\"   âœ… Basic DL (LSTM, GRU, Bi-LSTM)\")\n",
    "if RUN_GENERATIVE: print(\"   âœ… Generative (Autoencoder, VAE)\")\n",
    "if RUN_GAN: print(\"   âœ… TimeGAN (experimentell, ~30 min)\")\n",
    "if RUN_ADVANCED: print(\"   âœ… Advanced (N-BEATS, N-HiTS)\")\n",
    "if RUN_PROBABILISTIC: print(\"   âœ… DeepAR (probabilistisch)\")\n",
    "if RUN_TFT: print(\"   âœ… TFT (State-of-the-Art, ~30-45 min)\")\n",
    "\n",
    "print(f\"\\nâœ… Konfiguration abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587212fb",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(f'data/processed/{SERIES_NAME}_train.csv')\n",
    "val_df = pd.read_csv(f'data/processed/{SERIES_NAME}_val.csv')\n",
    "test_df = pd.read_csv(f'data/processed/{SERIES_NAME}_test.csv')\n",
    "\n",
    "# Determine value column\n",
    "value_col = [c for c in train_df.columns if c in ['solar', 'price', 'value',\n",
    "                                                     'wind_offshore', 'wind_onshore', 'consumption']][0]\n",
    "feature_cols = [c for c in train_df.columns if c not in ['timestamp', value_col]]\n",
    "\n",
    "print(f\"ğŸ“‚ Data loaded for: {SERIES_NAME.upper()}\")\n",
    "print(f\"   Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(f\"   Value column: {value_col}\")\n",
    "print(f\"   Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec36f1",
   "metadata": {},
   "source": [
    "## ğŸ”§ Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a03164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, seq_length):\n",
    "    \"\"\"Create sequences for RNN models\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(target[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Scale data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(train_df[feature_cols])\n",
    "y_train = scaler_y.fit_transform(train_df[[value_col]])\n",
    "\n",
    "X_val = scaler_X.transform(val_df[feature_cols])\n",
    "y_val = scaler_y.transform(val_df[[value_col]])\n",
    "\n",
    "X_test = scaler_X.transform(test_df[feature_cols])\n",
    "y_test_orig = test_df[value_col].values\n",
    "\n",
    "# Create sequences\n",
    "seq_length = 24\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train.flatten(), seq_length)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val, y_val.flatten(), seq_length)\n",
    "X_test_seq, _ = create_sequences(X_test, np.zeros(len(X_test)), seq_length)\n",
    "y_test_seq = y_test_orig[seq_length:]\n",
    "\n",
    "print(f\"âœ… Data prepared:\")\n",
    "print(f\"   X_train_seq: {X_train_seq.shape}\")\n",
    "print(f\"   y_test_seq: {y_test_seq.shape}\")\n",
    "\n",
    "# Storage for results\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30aa764",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ”µ BASIC MODELS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f42898",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 1: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_BASIC:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 1: LSTM\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build\n",
    "    model_lstm = keras.Sequential([\n",
    "        layers.LSTM(64, activation='relu', return_sequences=False, \n",
    "                   input_shape=(seq_length, len(feature_cols))),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model_lstm.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse')\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model_lstm.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        validation_data=(X_val_seq, y_val_seq),\n",
    "        epochs=100, batch_size=64,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_scaled = model_lstm.predict(X_test_seq, verbose=0)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
    "    \n",
    "    r2 = r2_score(y_test_seq, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_seq, y_pred))\n",
    "    mae = mean_absolute_error(y_test_seq, y_pred)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š LSTM RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2:.4f}\")\n",
    "    print(f\"   RMSE = {rmse:.2f}\")\n",
    "    print(f\"   MAE = {mae:.2f}\")\n",
    "    print(f\"   Time = {train_time:.1f}s\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'LSTM',\n",
    "        'RÂ²': r2,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Time (s)': train_time\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b77a30",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 2: GRU (â­ NEU!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f85ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_BASIC:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 2: GRU (Gated Recurrent Unit)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build GRU (schneller als LSTM!)\n",
    "    model_gru = keras.Sequential([\n",
    "        layers.GRU(64, activation='relu', return_sequences=False,\n",
    "                  input_shape=(seq_length, len(feature_cols))),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model_gru.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse')\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model_gru.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        validation_data=(X_val_seq, y_val_seq),\n",
    "        epochs=100, batch_size=64,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    train_time_gru = time.time() - start\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_gru_scaled = model_gru.predict(X_test_seq, verbose=0)\n",
    "    y_pred_gru = scaler_y.inverse_transform(y_pred_gru_scaled).flatten()\n",
    "    \n",
    "    r2_gru = r2_score(y_test_seq, y_pred_gru)\n",
    "    rmse_gru = np.sqrt(mean_squared_error(y_test_seq, y_pred_gru))\n",
    "    mae_gru = mean_absolute_error(y_test_seq, y_pred_gru)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š GRU RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_gru:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_gru:.2f}\")\n",
    "    print(f\"   MAE = {mae_gru:.2f}\")\n",
    "    print(f\"   Time = {train_time_gru:.1f}s\")\n",
    "    print(f\"\\nğŸ’¡ GRU vs LSTM: {((train_time - train_time_gru) / train_time * 100):.1f}% faster!\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'GRU',\n",
    "        'RÂ²': r2_gru,\n",
    "        'RMSE': rmse_gru,\n",
    "        'MAE': mae_gru,\n",
    "        'Time (s)': train_time_gru\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5145e",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 3: Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3823262",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_BASIC:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 3: Bi-LSTM (Bidirectional)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build\n",
    "    model_bilstm = keras.Sequential([\n",
    "        layers.Bidirectional(layers.LSTM(64, activation='relu', return_sequences=True),\n",
    "                           input_shape=(seq_length, len(feature_cols))),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Bidirectional(layers.LSTM(32, activation='relu')),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model_bilstm.compile(optimizer=keras.optimizers.Adam(0.001), loss='mse')\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model_bilstm.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        validation_data=(X_val_seq, y_val_seq),\n",
    "        epochs=100, batch_size=64,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    train_time_bilstm = time.time() - start\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_bilstm_scaled = model_bilstm.predict(X_test_seq, verbose=0)\n",
    "    y_pred_bilstm = scaler_y.inverse_transform(y_pred_bilstm_scaled).flatten()\n",
    "    \n",
    "    r2_bilstm = r2_score(y_test_seq, y_pred_bilstm)\n",
    "    rmse_bilstm = np.sqrt(mean_squared_error(y_test_seq, y_pred_bilstm))\n",
    "    mae_bilstm = mean_absolute_error(y_test_seq, y_pred_bilstm)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š BI-LSTM RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_bilstm:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_bilstm:.2f}\")\n",
    "    print(f\"   MAE = {mae_bilstm:.2f}\")\n",
    "    print(f\"   Time = {train_time_bilstm:.1f}s\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'Bi-LSTM',\n",
    "        'RÂ²': r2_bilstm,\n",
    "        'RMSE': rmse_bilstm,\n",
    "        'MAE': mae_bilstm,\n",
    "        'Time (s)': train_time_bilstm\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81bdb7d",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸŸ¢ GENERATIVE MODELS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76712816",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 4: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GENERATIVE:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 4: Autoencoder\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build Autoencoder\n",
    "    encoding_dim = 32\n",
    "    input_ae = layers.Input(shape=(seq_length, len(feature_cols)))\n",
    "    encoded = layers.LSTM(64, activation='relu', return_sequences=True)(input_ae)\n",
    "    encoded = layers.LSTM(encoding_dim, activation='relu')(encoded)\n",
    "    \n",
    "    decoded = layers.RepeatVector(seq_length)(encoded)\n",
    "    decoded = layers.LSTM(64, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = layers.TimeDistributed(layers.Dense(len(feature_cols)))(decoded)\n",
    "    \n",
    "    autoencoder = keras.Model(input_ae, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    encoder = keras.Model(input_ae, encoded)\n",
    "    \n",
    "    # Train Autoencoder\n",
    "    start = time.time()\n",
    "    autoencoder.fit(\n",
    "        X_train_seq, X_train_seq,\n",
    "        validation_data=(X_val_seq, X_val_seq),\n",
    "        epochs=50, batch_size=64,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Train Forecast Head\n",
    "    encoded_train = encoder.predict(X_train_seq, verbose=0)\n",
    "    encoded_val = encoder.predict(X_val_seq, verbose=0)\n",
    "    encoded_test = encoder.predict(X_test_seq, verbose=0)\n",
    "    \n",
    "    forecast_head = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(encoding_dim,)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    forecast_head.compile(optimizer='adam', loss='mse')\n",
    "    forecast_head.fit(\n",
    "        encoded_train, y_train_seq,\n",
    "        validation_data=(encoded_val, y_val_seq),\n",
    "        epochs=50, batch_size=64,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "    train_time_ae = time.time() - start\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_ae_scaled = forecast_head.predict(encoded_test, verbose=0)\n",
    "    y_pred_ae = scaler_y.inverse_transform(y_pred_ae_scaled).flatten()\n",
    "    \n",
    "    r2_ae = r2_score(y_test_seq, y_pred_ae)\n",
    "    rmse_ae = np.sqrt(mean_squared_error(y_test_seq, y_pred_ae))\n",
    "    mae_ae = mean_absolute_error(y_test_seq, y_pred_ae)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š AUTOENCODER RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_ae:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_ae:.2f}\")\n",
    "    print(f\"   MAE = {mae_ae:.2f}\")\n",
    "    print(f\"   Time = {train_time_ae:.1f}s\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'Autoencoder',\n",
    "        'RÂ²': r2_ae,\n",
    "        'RMSE': rmse_ae,\n",
    "        'MAE': mae_ae,\n",
    "        'Time (s)': train_time_ae\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2ce7a",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 5: VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GENERATIVE:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 5: VAE (Variational Autoencoder)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build VAE\n",
    "    latent_dim = 32\n",
    "    input_vae = layers.Input(shape=(seq_length, len(feature_cols)))\n",
    "    x = layers.LSTM(64, activation='relu', return_sequences=True)(input_vae)\n",
    "    x = layers.LSTM(64, activation='relu')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "    \n",
    "    decoder_input = layers.Input(shape=(latent_dim,))\n",
    "    x_decoded = layers.RepeatVector(seq_length)(decoder_input)\n",
    "    x_decoded = layers.LSTM(64, activation='relu', return_sequences=True)(x_decoded)\n",
    "    x_decoded = layers.TimeDistributed(layers.Dense(len(feature_cols)))(x_decoded)\n",
    "    \n",
    "    decoder = keras.Model(decoder_input, x_decoded)\n",
    "    outputs = decoder(z)\n",
    "    vae = keras.Model(input_vae, outputs)\n",
    "    \n",
    "    reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(input_vae, outputs), axis=-1))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "    vae_loss = reconstruction_loss + kl_loss\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    \n",
    "    encoder_vae = keras.Model(input_vae, z_mean)\n",
    "    \n",
    "    # Train VAE\n",
    "    start = time.time()\n",
    "    vae.fit(\n",
    "        X_train_seq, X_train_seq,\n",
    "        validation_data=(X_val_seq, X_val_seq),\n",
    "        epochs=50, batch_size=64,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Train Forecast Head\n",
    "    encoded_vae_train = encoder_vae.predict(X_train_seq, verbose=0)\n",
    "    encoded_vae_val = encoder_vae.predict(X_val_seq, verbose=0)\n",
    "    encoded_vae_test = encoder_vae.predict(X_test_seq, verbose=0)\n",
    "    \n",
    "    forecast_head_vae = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(latent_dim,)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    forecast_head_vae.compile(optimizer='adam', loss='mse')\n",
    "    forecast_head_vae.fit(\n",
    "        encoded_vae_train, y_train_seq,\n",
    "        validation_data=(encoded_vae_val, y_val_seq),\n",
    "        epochs=50, batch_size=64,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=0\n",
    "    )\n",
    "    train_time_vae = time.time() - start\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_vae_scaled = forecast_head_vae.predict(encoded_vae_test, verbose=0)\n",
    "    y_pred_vae = scaler_y.inverse_transform(y_pred_vae_scaled).flatten()\n",
    "    \n",
    "    r2_vae = r2_score(y_test_seq, y_pred_vae)\n",
    "    rmse_vae = np.sqrt(mean_squared_error(y_test_seq, y_pred_vae))\n",
    "    mae_vae = mean_absolute_error(y_test_seq, y_pred_vae)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š VAE RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_vae:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_vae:.2f}\")\n",
    "    print(f\"   MAE = {mae_vae:.2f}\")\n",
    "    print(f\"   Time = {train_time_vae:.1f}s\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'VAE',\n",
    "        'RÂ²': r2_vae,\n",
    "        'RMSE': rmse_vae,\n",
    "        'MAE': mae_vae,\n",
    "        'Time (s)': train_time_vae\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1fa817",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ”´ ADVANCED MODELS (Darts Framework)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Darts TimeSeries (needed for N-BEATS, N-HiTS, DeepAR, TFT)\n",
    "if RUN_ADVANCED or RUN_PROBABILISTIC or RUN_TFT:\n",
    "    from darts import TimeSeries\n",
    "    from darts.dataprocessing.transformers import Scaler as DartsScaler\n",
    "    \n",
    "    ts_train = TimeSeries.from_values(train_df[value_col].values)\n",
    "    ts_val = TimeSeries.from_values(val_df[value_col].values)\n",
    "    ts_test = TimeSeries.from_values(test_df[value_col].values)\n",
    "    \n",
    "    scaler_darts = DartsScaler()\n",
    "    ts_train_scaled = scaler_darts.fit_transform(ts_train)\n",
    "    ts_val_scaled = scaler_darts.transform(ts_val)\n",
    "    \n",
    "    print(\"âœ… Darts TimeSeries prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b09f2",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 6: N-BEATS (â­ NEU!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ADVANCED:\n",
    "    from darts.models import NBEATSModel\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 6: N-BEATS (Neural Basis Expansion)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_nbeats = NBEATSModel(\n",
    "        input_chunk_length=24,\n",
    "        output_chunk_length=1,\n",
    "        n_epochs=100,\n",
    "        batch_size=64,\n",
    "        pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\": 1,\n",
    "            \"enable_progress_bar\": False\n",
    "        },\n",
    "        force_reset=True,\n",
    "        save_checkpoints=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model_nbeats.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
    "    train_time_nbeats = time.time() - start\n",
    "    \n",
    "    # Predict\n",
    "    n_pred = len(ts_test)\n",
    "    pred_nbeats_scaled = model_nbeats.predict(n=n_pred, series=ts_train_scaled)\n",
    "    pred_nbeats = scaler_darts.inverse_transform(pred_nbeats_scaled)\n",
    "    \n",
    "    y_pred_nbeats = pred_nbeats.values().flatten()\n",
    "    y_test_nbeats = ts_test.values().flatten()\n",
    "    min_len = min(len(y_pred_nbeats), len(y_test_nbeats))\n",
    "    y_pred_nbeats = y_pred_nbeats[:min_len]\n",
    "    y_test_nbeats = y_test_nbeats[:min_len]\n",
    "    \n",
    "    r2_nbeats = r2_score(y_test_nbeats, y_pred_nbeats)\n",
    "    rmse_nbeats = np.sqrt(mean_squared_error(y_test_nbeats, y_pred_nbeats))\n",
    "    mae_nbeats = mean_absolute_error(y_test_nbeats, y_pred_nbeats)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š N-BEATS RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_nbeats:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_nbeats:.2f}\")\n",
    "    print(f\"   MAE = {mae_nbeats:.2f}\")\n",
    "    print(f\"   Time = {train_time_nbeats:.1f}s\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'N-BEATS',\n",
    "        'RÂ²': r2_nbeats,\n",
    "        'RMSE': rmse_nbeats,\n",
    "        'MAE': mae_nbeats,\n",
    "        'Time (s)': train_time_nbeats\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac4199",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 7: N-HiTS (â­ NEU!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ADVANCED:\n",
    "    from darts.models import NHiTSModel\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 7: N-HiTS (Hierarchical Interpolation)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_nhits = NHiTSModel(\n",
    "        input_chunk_length=24,\n",
    "        output_chunk_length=1,\n",
    "        n_epochs=100,\n",
    "        batch_size=64,\n",
    "        pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\": 1,\n",
    "            \"enable_progress_bar\": False\n",
    "        },\n",
    "        force_reset=True,\n",
    "        save_checkpoints=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model_nhits.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
    "    train_time_nhits = time.time() - start\n",
    "    \n",
    "    # Predict\n",
    "    pred_nhits_scaled = model_nhits.predict(n=n_pred, series=ts_train_scaled)\n",
    "    pred_nhits = scaler_darts.inverse_transform(pred_nhits_scaled)\n",
    "    \n",
    "    y_pred_nhits = pred_nhits.values().flatten()\n",
    "    y_test_nhits = ts_test.values().flatten()\n",
    "    min_len = min(len(y_pred_nhits), len(y_test_nhits))\n",
    "    y_pred_nhits = y_pred_nhits[:min_len]\n",
    "    y_test_nhits = y_test_nhits[:min_len]\n",
    "    \n",
    "    r2_nhits = r2_score(y_test_nhits, y_pred_nhits)\n",
    "    rmse_nhits = np.sqrt(mean_squared_error(y_test_nhits, y_pred_nhits))\n",
    "    mae_nhits = mean_absolute_error(y_test_nhits, y_pred_nhits)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š N-HiTS RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_nhits:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_nhits:.2f}\")\n",
    "    print(f\"   MAE = {mae_nhits:.2f}\")\n",
    "    print(f\"   Time = {train_time_nhits:.1f}s\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'N-HiTS',\n",
    "        'RÂ²': r2_nhits,\n",
    "        'RMSE': rmse_nhits,\n",
    "        'MAE': mae_nhits,\n",
    "        'Time (s)': train_time_nhits\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7afb3",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 8: DeepAR (â­ NEU! - Probabilistisch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106816d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PROBABILISTIC:\n",
    "    from darts.models import RNNModel\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 8: DeepAR (Probabilistic Forecasting)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # DeepAR via Darts' RNNModel with probabilistic output\n",
    "    model_deepar = RNNModel(\n",
    "        model='LSTM',\n",
    "        input_chunk_length=24,\n",
    "        training_length=48,\n",
    "        n_epochs=100,\n",
    "        batch_size=64,\n",
    "        hidden_dim=64,\n",
    "        n_rnn_layers=2,\n",
    "        dropout=0.2,\n",
    "        likelihood='gaussian',  # Probabilistic!\n",
    "        pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\": 1,\n",
    "            \"enable_progress_bar\": False\n",
    "        },\n",
    "        force_reset=True,\n",
    "        save_checkpoints=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model_deepar.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
    "    train_time_deepar = time.time() - start\n",
    "    \n",
    "    # Predict (median)\n",
    "    pred_deepar_scaled = model_deepar.predict(n=n_pred, series=ts_train_scaled, num_samples=100)\n",
    "    pred_deepar = scaler_darts.inverse_transform(pred_deepar_scaled)\n",
    "    \n",
    "    y_pred_deepar = pred_deepar.values().flatten()\n",
    "    y_test_deepar = ts_test.values().flatten()\n",
    "    min_len = min(len(y_pred_deepar), len(y_test_deepar))\n",
    "    y_pred_deepar = y_pred_deepar[:min_len]\n",
    "    y_test_deepar = y_test_deepar[:min_len]\n",
    "    \n",
    "    r2_deepar = r2_score(y_test_deepar, y_pred_deepar)\n",
    "    rmse_deepar = np.sqrt(mean_squared_error(y_test_deepar, y_pred_deepar))\n",
    "    mae_deepar = mean_absolute_error(y_test_deepar, y_pred_deepar)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š DEEPAR RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_deepar:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_deepar:.2f}\")\n",
    "    print(f\"   MAE = {mae_deepar:.2f}\")\n",
    "    print(f\"   Time = {train_time_deepar:.1f}s\")\n",
    "    print(f\"\\nğŸ’¡ DeepAR liefert probabilistische Forecasts (Konfidenzintervalle mÃ¶glich!)\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'DeepAR',\n",
    "        'RÂ²': r2_deepar,\n",
    "        'RMSE': rmse_deepar,\n",
    "        'MAE': mae_deepar,\n",
    "        'Time (s)': train_time_deepar\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b113e4",
   "metadata": {},
   "source": [
    "## ğŸ§ª Model 9: TFT (â­ NEU! - State-of-the-Art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TFT:\n",
    "    from darts.models import TFTModel\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ§ª MODEL 9: TFT (Temporal Fusion Transformer)\")\n",
    "    print(\"âš ï¸ WARNING: This can take 30-45 minutes!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_tft = TFTModel(\n",
    "        input_chunk_length=24,\n",
    "        output_chunk_length=1,\n",
    "        hidden_size=64,\n",
    "        lstm_layers=2,\n",
    "        num_attention_heads=4,\n",
    "        dropout=0.1,\n",
    "        batch_size=64,\n",
    "        n_epochs=100,\n",
    "        pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\": 1,\n",
    "            \"enable_progress_bar\": True\n",
    "        },\n",
    "        force_reset=True,\n",
    "        save_checkpoints=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    model_tft.fit(series=ts_train_scaled, val_series=ts_val_scaled, verbose=False)\n",
    "    train_time_tft = time.time() - start\n",
    "    \n",
    "    # Predict\n",
    "    pred_tft_scaled = model_tft.predict(n=n_pred, series=ts_train_scaled)\n",
    "    pred_tft = scaler_darts.inverse_transform(pred_tft_scaled)\n",
    "    \n",
    "    y_pred_tft = pred_tft.values().flatten()\n",
    "    y_test_tft = ts_test.values().flatten()\n",
    "    min_len = min(len(y_pred_tft), len(y_test_tft))\n",
    "    y_pred_tft = y_pred_tft[:min_len]\n",
    "    y_test_tft = y_test_tft[:min_len]\n",
    "    \n",
    "    r2_tft = r2_score(y_test_tft, y_pred_tft)\n",
    "    rmse_tft = np.sqrt(mean_squared_error(y_test_tft, y_pred_tft))\n",
    "    mae_tft = mean_absolute_error(y_test_tft, y_pred_tft)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š TFT RESULTS:\")\n",
    "    print(f\"   RÂ² = {r2_tft:.4f}\")\n",
    "    print(f\"   RMSE = {rmse_tft:.2f}\")\n",
    "    print(f\"   MAE = {mae_tft:.2f}\")\n",
    "    print(f\"   Time = {train_time_tft:.1f}s ({train_time_tft/60:.1f} min)\")\n",
    "    print(f\"\\nğŸ† TFT: State-of-the-Art Transformer-basiert!\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'Model': 'TFT',\n",
    "        'RÂ²': r2_tft,\n",
    "        'RMSE': rmse_tft,\n",
    "        'MAE': mae_tft,\n",
    "        'Time (s)': train_time_tft\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d4921",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“Š FINAL SUMMARY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df = results_df.sort_values('RÂ²', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"ğŸ† FINAL RESULTS: {SERIES_NAME.upper()}\")\n",
    "    print(\"=\"*100)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ğŸ¥‡ BEST MODEL:\")\n",
    "    print(\"=\"*100)\n",
    "    best = results_df.iloc[0]\n",
    "    print(f\"   Model: {best['Model']}\")\n",
    "    print(f\"   RÂ² = {best['RÂ²']:.4f}\")\n",
    "    print(f\"   RMSE = {best['RMSE']:.2f}\")\n",
    "    print(f\"   MAE = {best['MAE']:.2f}\")\n",
    "    print(f\"   Training Time = {best['Time (s)']:.1f}s ({best['Time (s)']/60:.1f} min)\")\n",
    "    \n",
    "    # Save results\n",
    "    output_file = f'results/metrics/deep_learning_extended_{SERIES_NAME}.csv'\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nğŸ’¾ Ergebnisse gespeichert: {output_file}\")\n",
    "    \n",
    "    # Performance insights\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ğŸ’¡ KEY INSIGHTS:\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    if 'GRU' in results_df['Model'].values and 'LSTM' in results_df['Model'].values:\n",
    "        gru_r2 = results_df[results_df['Model'] == 'GRU']['RÂ²'].values[0]\n",
    "        lstm_r2 = results_df[results_df['Model'] == 'LSTM']['RÂ²'].values[0]\n",
    "        print(f\"   ğŸ“Œ GRU vs LSTM: RÂ² {gru_r2:.4f} vs {lstm_r2:.4f}\")\n",
    "        if gru_r2 > lstm_r2:\n",
    "            print(f\"      â†’ GRU ist {((gru_r2 - lstm_r2) / lstm_r2 * 100):.2f}% besser!\")\n",
    "    \n",
    "    print(f\"\\n   ğŸ“Œ Durchschnittliche RÂ²: {results_df['RÂ²'].mean():.4f}\")\n",
    "    print(f\"   ğŸ“Œ Schnellstes Modell: {results_df.loc[results_df['Time (s)'].idxmin(), 'Model']} ({results_df['Time (s)'].min():.1f}s)\")\n",
    "    print(f\"   ğŸ“Œ Langsamtes Modell: {results_df.loc[results_df['Time (s)'].idxmax(), 'Model']} ({results_df['Time (s)'].max():.1f}s)\")\n",
    "    \n",
    "    negative_r2 = results_df[results_df['RÂ²'] < 0]\n",
    "    if len(negative_r2) > 0:\n",
    "        print(f\"\\n   âš ï¸ Modelle mit negativem RÂ² (schlecht konfiguriert):\")\n",
    "        for _, row in negative_r2.iterrows():\n",
    "            print(f\"      - {row['Model']}: RÂ² = {row['RÂ²']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"âœ… EXPERIMENT ABGESCHLOSSEN!\")\n",
    "    print(\"=\"*100)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Keine Modelle wurden ausgefÃ¼hrt. Bitte aktiviere mindestens eine Modellkategorie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3273543",
   "metadata": {},
   "source": [
    "## ğŸ“ Empfehlungen\n",
    "\n",
    "### FÃ¼r Produktion:\n",
    "1. **HÃ¶chste Genauigkeit**: Bestes Modell nach RÂ² wÃ¤hlen\n",
    "2. **Balance Speed/Accuracy**: GRU oder Bi-LSTM\n",
    "3. **UnsicherheitsschÃ¤tzung**: DeepAR oder VAE\n",
    "4. **State-of-the-Art**: TFT (wenn Rechenzeit kein Problem)\n",
    "\n",
    "### FÃ¼r weitere Experimente:\n",
    "- **TimeGAN**: Aktiviere `RUN_GAN = True` (sehr experimentell)\n",
    "- **Hyperparameter-Tuning**: Optimiere die besten 2-3 Modelle weiter\n",
    "- **Ensemble**: Kombiniere mehrere Top-Modelle"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
