{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18c80ba",
   "metadata": {},
   "source": [
    "# üöÄ LSTM Optimization - Wind Offshore - Google Colab GPU Edition\n",
    "\n",
    "**Systematisches LSTM-Tuning mit GPU-Beschleunigung f√ºr Wind Offshore**\n",
    "\n",
    "**Setup:**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU (T4 oder A100)\n",
    "- ~10-50x schneller als CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e99428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"\\nüöÄ GPU should show above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ddd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Repository\n",
    "!git clone https://github.com/chradden/AdvancedTimeSeriesPrediction.git\n",
    "%cd AdvancedTimeSeriesPrediction/energy-timeseries-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718db6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn tensorflow keras pytorch-lightning darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import time\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# GPU Config\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU configured: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found - training will be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d2567e",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration - Wind Offshore\n",
    "\n",
    "**Zeitreihe: Wind Offshore**\n",
    "- Offshore-Windenergie-Erzeugung\n",
    "- ‚ö†Ô∏è Beachte: 9-monatige Stillstandsperiode (Apr 2023 - Jan 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f405d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SERIES_NAME = 'wind_offshore'\n",
    "\n",
    "print(f\"üìä Zeitreihe: {SERIES_NAME.upper()}\")\n",
    "print(f\"‚úÖ Konfiguration abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e142487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "train_df = pd.read_csv(f'data/processed/{SERIES_NAME}_train.csv')\n",
    "val_df = pd.read_csv(f'data/processed/{SERIES_NAME}_val.csv')\n",
    "test_df = pd.read_csv(f'data/processed/{SERIES_NAME}_test.csv')\n",
    "\n",
    "print(f\"üìÇ Loading data for: {SERIES_NAME.upper()}\")\n",
    "print(f\"   Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(f\"   Columns: {train_df.columns.tolist()[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine value column\n",
    "value_col = 'wind_offshore'\n",
    "feature_cols = [c for c in train_df.columns if c not in ['timestamp', value_col]]\n",
    "\n",
    "print(f\"Value column: {value_col}\")\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deac571",
   "metadata": {},
   "source": [
    "## üîß Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6160ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, seq_length):\n",
    "    \"\"\"Create sequences for LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(target[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Scale data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(train_df[feature_cols])\n",
    "y_train = scaler_y.fit_transform(train_df[[value_col]])\n",
    "\n",
    "X_val = scaler_X.transform(val_df[feature_cols])\n",
    "y_val = scaler_y.transform(val_df[[value_col]])\n",
    "\n",
    "X_test = scaler_X.transform(test_df[feature_cols])\n",
    "y_test_orig = test_df[value_col].values\n",
    "\n",
    "print(f\"‚úÖ Data scaled: X_train shape = {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4639809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "seq_length = 24\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train.flatten(), seq_length)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val, y_val.flatten(), seq_length)\n",
    "X_test_seq, _ = create_sequences(X_test, np.zeros(len(X_test)), seq_length)\n",
    "y_test_seq = y_test_orig[seq_length:]\n",
    "\n",
    "print(f\"‚úÖ Sequences created:\")\n",
    "print(f\"   X_train_seq: {X_train_seq.shape}\")\n",
    "print(f\"   X_val_seq: {X_val_seq.shape}\")\n",
    "print(f\"   X_test_seq: {X_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef632986",
   "metadata": {},
   "source": [
    "## üß™ Experiment 1: Baseline LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Baseline LSTM\n",
    "model = keras.Sequential([\n",
    "    layers.LSTM(64, activation='relu', return_sequences=False, input_shape=(seq_length, len(feature_cols))),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Baseline LSTM model built\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Baseline LSTM\n",
    "print(\"üöÄ Training Baseline LSTM...\")\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "train_time = time.time() - start\n",
    "print(f\"\\n‚úÖ Training completed in {train_time:.1f}s ({train_time/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ced58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Baseline LSTM\n",
    "y_pred_scaled = model.predict(X_test_seq, verbose=0)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_seq, y_pred))\n",
    "mae = mean_absolute_error(y_test_seq, y_pred)\n",
    "r2 = r2_score(y_test_seq, y_pred)\n",
    "\n",
    "print(f\"\\nüìä BASELINE LSTM RESULTS:\")\n",
    "print(f\"   R¬≤ = {r2:.4f}\")\n",
    "print(f\"   RMSE = {rmse:.2f} MW\")\n",
    "print(f\"   MAE = {mae:.2f} MW\")\n",
    "print(f\"   Time = {train_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4bb978",
   "metadata": {},
   "source": [
    "## üß™ Experiment 2: Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eac302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Bi-LSTM\n",
    "model_bilstm = keras.Sequential([\n",
    "    layers.Bidirectional(layers.LSTM(64, activation='relu', return_sequences=True), \n",
    "                        input_shape=(seq_length, len(feature_cols))),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Bidirectional(layers.LSTM(32, activation='relu')),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_bilstm.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "print(\"‚úÖ Bi-LSTM model built\")\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bi-LSTM\n",
    "print(\"üöÄ Training Bi-LSTM...\")\n",
    "start = time.time()\n",
    "\n",
    "history_bilstm = model_bilstm.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "train_time_bilstm = time.time() - start\n",
    "print(f\"\\n‚úÖ Bi-LSTM training completed in {train_time_bilstm:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576821e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Bi-LSTM\n",
    "y_pred_bilstm_scaled = model_bilstm.predict(X_test_seq, verbose=0)\n",
    "y_pred_bilstm = scaler_y.inverse_transform(y_pred_bilstm_scaled).flatten()\n",
    "\n",
    "rmse_bilstm = np.sqrt(mean_squared_error(y_test_seq, y_pred_bilstm))\n",
    "mae_bilstm = mean_absolute_error(y_test_seq, y_pred_bilstm)\n",
    "r2_bilstm = r2_score(y_test_seq, y_pred_bilstm)\n",
    "\n",
    "print(f\"\\nüìä BI-LSTM RESULTS:\")\n",
    "print(f\"   R¬≤ = {r2_bilstm:.4f}\")\n",
    "print(f\"   RMSE = {rmse_bilstm:.2f} MW\")\n",
    "print(f\"   MAE = {mae_bilstm:.2f} MW\")\n",
    "print(f\"   Time = {train_time_bilstm:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a00ff",
   "metadata": {},
   "source": [
    "## üß™ Experiment 3: Autoencoder-Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Autoencoder\n",
    "encoding_dim = 32\n",
    "\n",
    "# Encoder\n",
    "input_ae = layers.Input(shape=(seq_length, len(feature_cols)))\n",
    "encoded = layers.LSTM(64, activation='relu', return_sequences=True)(input_ae)\n",
    "encoded = layers.LSTM(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = layers.RepeatVector(seq_length)(encoded)\n",
    "decoded = layers.LSTM(64, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = layers.TimeDistributed(layers.Dense(len(feature_cols)))(decoded)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = keras.Model(input_ae, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Encoder Model\n",
    "encoder = keras.Model(input_ae, encoded)\n",
    "\n",
    "print(\"‚úÖ Autoencoder built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f97943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Autoencoder\n",
    "print(\"üöÄ Training Autoencoder...\")\n",
    "start = time.time()\n",
    "\n",
    "history_ae = autoencoder.fit(\n",
    "    X_train_seq, X_train_seq,\n",
    "    validation_data=(X_val_seq, X_val_seq),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "train_time_ae = time.time() - start\n",
    "print(f\"\\n‚úÖ Autoencoder training completed in {train_time_ae:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bee706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Forecast Head\n",
    "encoded_train = encoder.predict(X_train_seq, verbose=0)\n",
    "encoded_val = encoder.predict(X_val_seq, verbose=0)\n",
    "encoded_test = encoder.predict(X_test_seq, verbose=0)\n",
    "\n",
    "forecast_head = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(encoding_dim,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "forecast_head.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "forecast_head.fit(\n",
    "    encoded_train, y_train_seq,\n",
    "    validation_data=(encoded_val, y_val_seq),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Forecast head trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Autoencoder-Forecast\n",
    "y_pred_ae_scaled = forecast_head.predict(encoded_test, verbose=0)\n",
    "y_pred_ae = scaler_y.inverse_transform(y_pred_ae_scaled).flatten()\n",
    "\n",
    "rmse_ae = np.sqrt(mean_squared_error(y_test_seq, y_pred_ae))\n",
    "mae_ae = mean_absolute_error(y_test_seq, y_pred_ae)\n",
    "r2_ae = r2_score(y_test_seq, y_pred_ae)\n",
    "\n",
    "print(f\"\\nüìä AUTOENCODER-FORECAST RESULTS:\")\n",
    "print(f\"   R¬≤ = {r2_ae:.4f}\")\n",
    "print(f\"   RMSE = {rmse_ae:.2f} MW\")\n",
    "print(f\"   MAE = {mae_ae:.2f} MW\")\n",
    "print(f\"   Time = {train_time_ae:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e5318",
   "metadata": {},
   "source": [
    "## üß™ Experiment 4: VAE-Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c74530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VAE\n",
    "latent_dim = 32\n",
    "\n",
    "# Encoder\n",
    "input_vae = layers.Input(shape=(seq_length, len(feature_cols)))\n",
    "x = layers.LSTM(64, activation='relu', return_sequences=True)(input_vae)\n",
    "x = layers.LSTM(64, activation='relu')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)\n",
    "\n",
    "# Sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "x_decoded = layers.RepeatVector(seq_length)(decoder_input)\n",
    "x_decoded = layers.LSTM(64, activation='relu', return_sequences=True)(x_decoded)\n",
    "x_decoded = layers.TimeDistributed(layers.Dense(len(feature_cols)))(x_decoded)\n",
    "\n",
    "decoder = keras.Model(decoder_input, x_decoded)\n",
    "outputs = decoder(z)\n",
    "\n",
    "vae = keras.Model(input_vae, outputs)\n",
    "\n",
    "# VAE Loss\n",
    "reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(input_vae, outputs), axis=-1))\n",
    "kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "vae_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# Encoder Model\n",
    "encoder_vae = keras.Model(input_vae, z_mean)\n",
    "\n",
    "print(\"‚úÖ VAE built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VAE\n",
    "print(\"üöÄ Training VAE...\")\n",
    "start = time.time()\n",
    "\n",
    "history_vae = vae.fit(\n",
    "    X_train_seq, X_train_seq,\n",
    "    validation_data=(X_val_seq, X_val_seq),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "train_time_vae = time.time() - start\n",
    "print(f\"\\n‚úÖ VAE training completed in {train_time_vae:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbe2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Forecast Head for VAE\n",
    "encoded_vae_train = encoder_vae.predict(X_train_seq, verbose=0)\n",
    "encoded_vae_val = encoder_vae.predict(X_val_seq, verbose=0)\n",
    "encoded_vae_test = encoder_vae.predict(X_test_seq, verbose=0)\n",
    "\n",
    "forecast_head_vae = keras.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(latent_dim,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "forecast_head_vae.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "forecast_head_vae.fit(\n",
    "    encoded_vae_train, y_train_seq,\n",
    "    validation_data=(encoded_vae_val, y_val_seq),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ VAE forecast head trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97936fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VAE-Forecast\n",
    "y_pred_vae_scaled = forecast_head_vae.predict(encoded_vae_test, verbose=0)\n",
    "y_pred_vae = scaler_y.inverse_transform(y_pred_vae_scaled).flatten()\n",
    "\n",
    "rmse_vae = np.sqrt(mean_squared_error(y_test_seq, y_pred_vae))\n",
    "mae_vae = mean_absolute_error(y_test_seq, y_pred_vae)\n",
    "r2_vae = r2_score(y_test_seq, y_pred_vae)\n",
    "\n",
    "print(f\"\\n‚òï VAE-FORECAST RESULTS:\")\n",
    "print(f\"   R¬≤ = {r2_vae:.4f}\")\n",
    "print(f\"   RMSE = {rmse_vae:.2f} MW\")\n",
    "print(f\"   MAE = {mae_vae:.2f} MW\")\n",
    "print(f\"   Time = {train_time_vae:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cd608",
   "metadata": {},
   "source": [
    "## üß™ Experiment 5: N-BEATS (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Darts if needed\n",
    "!pip install -q darts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Darts\n",
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler as DartsScaler\n",
    "\n",
    "# Create Darts TimeSeries\n",
    "ts_train = TimeSeries.from_values(train_df[value_col].values)\n",
    "ts_val = TimeSeries.from_values(val_df[value_col].values)\n",
    "ts_test = TimeSeries.from_values(test_df[value_col].values)\n",
    "\n",
    "# Scale\n",
    "scaler_darts = DartsScaler()\n",
    "ts_train_scaled = scaler_darts.fit_transform(ts_train)\n",
    "ts_val_scaled = scaler_darts.transform(ts_val)\n",
    "\n",
    "print(\"‚úÖ Darts TimeSeries created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build N-BEATS\n",
    "model_nbeats = NBEATSModel(\n",
    "    input_chunk_length=24,\n",
    "    output_chunk_length=1,\n",
    "    n_epochs=100,\n",
    "    batch_size=64,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"devices\": 1,\n",
    "        \"enable_progress_bar\": True\n",
    "    },\n",
    "    force_reset=True,\n",
    "    save_checkpoints=True\n",
    ")\n",
    "\n",
    "print(\"üîß N-BEATS model configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a586947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train N-BEATS\n",
    "print(\"üöÄ Training N-BEATS (this will be FAST on GPU!)...\")\n",
    "start = time.time()\n",
    "\n",
    "model_nbeats.fit(\n",
    "    series=ts_train_scaled,\n",
    "    val_series=ts_val_scaled,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_time_nbeats = time.time() - start\n",
    "print(f\"\\n‚úÖ N-BEATS training completed in {train_time_nbeats:.1f}s ({train_time_nbeats/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with N-BEATS\n",
    "n_pred = len(ts_test)\n",
    "pred_nbeats_scaled = model_nbeats.predict(n=n_pred, series=ts_train_scaled)\n",
    "pred_nbeats = scaler_darts.inverse_transform(pred_nbeats_scaled)\n",
    "\n",
    "# Extract values\n",
    "y_pred_nbeats = pred_nbeats.values().flatten()\n",
    "y_test_nbeats = ts_test.values().flatten()\n",
    "\n",
    "# Ensure same length\n",
    "min_len = min(len(y_pred_nbeats), len(y_test_nbeats))\n",
    "y_pred_nbeats = y_pred_nbeats[:min_len]\n",
    "y_test_nbeats = y_test_nbeats[:min_len]\n",
    "\n",
    "# Evaluate\n",
    "rmse_nbeats = np.sqrt(mean_squared_error(y_test_nbeats, y_pred_nbeats))\n",
    "mae_nbeats = mean_absolute_error(y_test_nbeats, y_pred_nbeats)\n",
    "r2_nbeats = r2_score(y_test_nbeats, y_pred_nbeats)\n",
    "\n",
    "print(f\"\\nüìä N-BEATS RESULTS:\")\n",
    "print(f\"   R¬≤ = {r2_nbeats:.4f}\")\n",
    "print(f\"   RMSE = {rmse_nbeats:.2f}\")\n",
    "print(f\"   MAE = {mae_nbeats:.2f}\")\n",
    "print(f\"   Time = {train_time_nbeats:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90b759",
   "metadata": {},
   "source": [
    "## üß™ Experiment 6: N-HiTS (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import N-HiTS\n",
    "from darts.models import NHiTSModel\n",
    "\n",
    "# Build N-HiTS\n",
    "model_nhits = NHiTSModel(\n",
    "    input_chunk_length=24,\n",
    "    output_chunk_length=1,\n",
    "    n_epochs=100,\n",
    "    batch_size=64,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"devices\": 1,\n",
    "        \"enable_progress_bar\": True\n",
    "    },\n",
    "    force_reset=True,\n",
    "    save_checkpoints=True\n",
    ")\n",
    "\n",
    "print(\"üîß N-HiTS model configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train N-HiTS\n",
    "print(\"üöÄ Training N-HiTS...\")\n",
    "start = time.time()\n",
    "\n",
    "model_nhits.fit(\n",
    "    series=ts_train_scaled,\n",
    "    val_series=ts_val_scaled,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_time_nhits = time.time() - start\n",
    "print(f\"\\n‚úÖ N-HiTS training completed in {train_time_nhits:.1f}s ({train_time_nhits/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f30f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with N-HiTS\n",
    "pred_nhits_scaled = model_nhits.predict(n=n_pred, series=ts_train_scaled)\n",
    "pred_nhits = scaler_darts.inverse_transform(pred_nhits_scaled)\n",
    "\n",
    "# Extract values\n",
    "y_pred_nhits = pred_nhits.values().flatten()\n",
    "y_test_nhits = ts_test.values().flatten()\n",
    "\n",
    "# Ensure same length\n",
    "min_len = min(len(y_pred_nhits), len(y_test_nhits))\n",
    "y_pred_nhits = y_pred_nhits[:min_len]\n",
    "y_test_nhits = y_test_nhits[:min_len]\n",
    "\n",
    "# Evaluate\n",
    "rmse_nhits = np.sqrt(mean_squared_error(y_test_nhits, y_pred_nhits))\n",
    "mae_nhits = mean_absolute_error(y_test_nhits, y_pred_nhits)\n",
    "r2_nhits = r2_score(y_test_nhits, y_pred_nhits)\n",
    "\n",
    "print(f\"\\nüìä N-HiTS RESULTS:\")\n",
    "print(f\"   R¬≤ = {r2_nhits:.4f}\")\n",
    "print(f\"   RMSE = {rmse_nhits:.2f}\")\n",
    "print(f\"   MAE = {mae_nhits:.2f}\")\n",
    "print(f\"   Time = {train_time_nhits:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0ec41",
   "metadata": {},
   "source": [
    "## üìä Summary - All Models\n",
    "\n",
    "Zusammenfassung aller Modelle f√ºr Wind Offshore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary DataFrame\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'Baseline LSTM', 'R¬≤': r2, 'RMSE': rmse, 'MAE': mae, 'Time (s)': train_time},\n",
    "    {'Model': 'Bi-LSTM', 'R¬≤': r2_bilstm, 'RMSE': rmse_bilstm, 'MAE': mae_bilstm, 'Time (s)': train_time_bilstm},\n",
    "    {'Model': 'Autoencoder', 'R¬≤': r2_ae, 'RMSE': rmse_ae, 'MAE': mae_ae, 'Time (s)': train_time_ae},\n",
    "    {'Model': 'VAE', 'R¬≤': r2_vae, 'RMSE': rmse_vae, 'MAE': mae_vae, 'Time (s)': train_time_vae},\n",
    "    {'Model': 'N-BEATS', 'R¬≤': r2_nbeats, 'RMSE': rmse_nbeats, 'MAE': mae_nbeats, 'Time (s)': train_time_nbeats},\n",
    "    {'Model': 'N-HiTS', 'R¬≤': r2_nhits, 'RMSE': rmse_nhits, 'MAE': mae_nhits, 'Time (s)': train_time_nhits}\n",
    "])\n",
    "\n",
    "results = results.sort_values('R¬≤', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"üìä WIND OFFSHORE - ALL MODELS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "print(\"\\n‚úÖ Bestes Modell:\", results.iloc[0]['Model'])\n",
    "print(f\"   R¬≤ = {results.iloc[0]['R¬≤']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "results.to_csv('results/metrics/deep_learning_comprehensive_wind_offshore.csv', index=False)\n",
    "print(\"\\nüíæ Ergebnisse gespeichert: results/metrics/deep_learning_comprehensive_wind_offshore.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
