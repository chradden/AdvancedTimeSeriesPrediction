# Energie-Zeitreihen-Analyse & -Vorhersage âš¡ðŸ”‹

**Advanced Time Series Prediction Project**

> Comprehensive comparison of time series forecasting methods applied to German energy data

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Production-success.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![Avg RÂ²](https://img.shields.io/badge/Avg%20RÂ²-0.978-brightgreen.svg)]()

## ðŸš€ Quick Start

### Launch the Web Dashboard

```bash
docker-compose up
```

**Open**:
- ðŸŽ¯ **Prognose-UI**: 
  - Localhost: http://localhost:8000/ui
  - Codespace: https://<codespace-name>-8000.app.github.dev/ui
- ðŸ“ˆ **Grafana Monitoring**: 
  - Localhost: http://localhost:3000 (admin/admin)
  - Codespace: https://<codespace-name>-3000.app.github.dev (admin/admin)
- ðŸ”§ **API Docs**: 
  - Localhost: http://localhost:8000/docs
  - Codespace: https://<codespace-name>-8000.app.github.dev/docs

## ðŸŽ¯ Project Results

| Dataset | Best Model | RÂ² Score | MAE | MAPE | Status |
|---------|------------|----------|-----|------|--------|
| ðŸŒŠ Wind Offshore | XGBoost | **0.996** | 16 MW | 2.0% | ðŸ† Spectacular |
| ðŸ­ Consumption | XGBoost | **0.996** | 484 MW | 0.9% | ðŸŸ¢ Production |
| â˜€ï¸ Solar | XGBoost | **0.980** | 255 MW | 3.2% | ðŸŸ¢ Production |
| ðŸ’¨ Wind Onshore | XGBoost | **0.969** | 252 MW | 6.1% | ðŸŸ¢ Production |
| ðŸ’° Price | XGBoost | **0.952** | 7.25 â‚¬/MWh | 11.1% | ðŸŸ¡ Research |

**ðŸŽ‰ Average RÂ² across all datasets: 0.978** â†’ Produktionsreife erreicht!

## ðŸ“Š Ãœbersicht

Dieses Projekt analysiert Energiezeitreihen der deutschen Stromversorgung mit verschiedenen State-of-the-Art Forecasting-Methoden:

- **Datenquelle:** [SMARD](https://www.smard.de/home) (Bundesnetzagentur)
- **Zeitreihen:** Stromerzeugung (Solar, Wind), Verbrauch, Preise
- **Zeitraum:** 2022-2024 (3 Jahre stÃ¼ndliche Daten)
- **Ziel:** Vergleich von statistischen, ML- und Deep-Learning-Modellen

## ðŸ—‚ï¸ Projektstruktur

```
energy-timeseries-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Rohdaten von SMARD API (gecached)
â”‚   â”œâ”€â”€ processed/        # Aufbereitete Daten
â”‚   â””â”€â”€ external/         # ZusÃ¤tzliche Daten (Wetter, Feiertage)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb       # âœ… Explorative Datenanalyse
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb     # âœ… Datenaufbereitung & Feature Engineering
â”‚   â”œâ”€â”€ 03_baseline_models.ipynb        # âœ… Baseline-Modelle (Naive, Seasonal)
â”‚   â”œâ”€â”€ 04_statistical_models.ipynb     # âœ… SARIMA, ETS
â”‚   â”œâ”€â”€ 05_ml_tree_models.ipynb         # âœ… XGBoost, LightGBM, CatBoost
â”‚   â”œâ”€â”€ 06_deep_learning_models.ipynb   # âœ… LSTM, GRU, Bi-LSTM
â”‚   â”œâ”€â”€ 07_generative_models.ipynb      # âœ… VAE, GAN, DeepAR
â”‚   â”œâ”€â”€ 08_advanced_models.ipynb        # âœ… TFT, N-BEATS
â”‚   â”œâ”€â”€ 09_model_comparison.ipynb       # âœ… Vergleich aller Modelle
â”‚   â”œâ”€â”€ 10_multi_series_analysis.ipynb  # âœ… 5 Zeitreihen parallel
â”‚   â”œâ”€â”€ 11_xgboost_tuning.ipynb         # âœ… XGBoost Hyperparameter-Optimierung
â”‚   â”œâ”€â”€ 12_llm_time_series_models.ipynb # âœ… Foundation Models (Chronos)
â”‚   â”œâ”€â”€ 09_model_comparison.ipynb       # âœ… Finaler Modellvergleich
â”‚   â”œâ”€â”€ 10_multi_series_analysis.ipynb  # âœ… Multi-Series Pipeline (alle 5 DatensÃ¤tze)
â”‚   â””â”€â”€ 11_xgboost_tuning.ipynb         # âœ… Hyperparameter-Optimierung
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/             # Daten-Loading (SMARD API) & Preprocessing
â”‚   â”œâ”€â”€ models/           # Model-Implementierungen
â”‚   â”œâ”€â”€ visualization/    # Plotting-Funktionen
â”‚   â””â”€â”€ evaluation/       # Metriken & Evaluation (MAE, RMSE, RÂ², MAPE)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/          # Plots & Visualisierungen
â”‚   â””â”€â”€ metrics/          # Performance-Metriken (CSV)
â”‚       â”œâ”€â”€ RESULTS_SUMMARY.md                 # Zusammenfassung aller Ergebnisse
â”‚       â”œâ”€â”€ INTERPRETATION_UND_NEXT_STEPS.md   # Interpretation & nÃ¤chste Schritte
â”‚       â”œâ”€â”€ PROJECT_COMPLETION_REPORT.md       # Finale Projekt-Dokumentation
â”‚       â””â”€â”€ multi_series_comparison_UPDATED.csv # Multi-Series Finale Ergebnisse
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ PROJEKTPLAN_ENERGIE_ZEITREIHEN.md   # Detaillierter Plan
```

## ðŸš€ Quick Start

### 1. Installation

```bash
# Repository klonen
cd c:\Users\Christian\Coding\AdvancedTimeSeriesPrediction
cd energy-timeseries-project

# Virtual Environment erstellen (empfohlen)
python -m venv venv
.\venv\Scripts\activate  # Windows

# Dependencies installieren
pip install -r requirements.txt

# Jupyter Notebook starten
jupyter notebook
```

### 2. Erste Schritte

Ã–ffne `notebooks/01_data_exploration.ipynb` und fÃ¼hre die Zellen aus!

Das Notebook wird:
- âœ… Daten von SMARD API laden (automatisches Caching)
- âœ… Explorative Datenanalyse durchfÃ¼hren
- âœ… SaisonalitÃ¤t & Trends visualisieren
- âœ… StationaritÃ¤tstests durchfÃ¼hren

## ðŸ“ˆ Geplante Modelle

### Baseline
- âœ… Naive Forecast
- âœ… Seasonal Naive
- âœ… Moving Average

### Statistische Modelle
- âœ… ARIMA
- âœ… SARIMA
- âœ… SARIMAX (mit exogenen Variablen)
- âœ… ETS (Exponential Smoothing)

### Machine Learning
- âœ… XGBoost
- âœ… LightGBM
- âœ… CatBoost
- âœ… Random Forest

## ðŸ“ˆ Implementierte Modelle

### âœ… Baseline Models
- Naive Forecast
- Seasonal Naive  
- Moving Average

### âœ… Statistische Modelle
- ARIMA / SARIMA
- SARIMAX (mit exogenen Variablen)
- ETS (Exponential Smoothing)

### âœ… Machine Learning (Winner ðŸ†)
- **XGBoost** â†’ Best overall (RÂ² = 0.978)
- LightGBM â†’ Close second
- CatBoost
- Random Forest

### âœ… Deep Learning
- LSTM (Long Short-Term Memory)
- GRU (Gated Recurrent Unit)
- Bidirectional LSTM

### âœ… Generative Models
- Autoencoders fÃ¼r Anomalie-Erkennung
- VAEs (Variational Autoencoders)
- GANs (Generative Adversarial Networks)
- DeepAR (Probabilistische Vorhersagen)

### âœ… Advanced Deep Learning
- Temporal Fusion Transformer (TFT)
- N-BEATS
- N-HiTS

### âœ… Foundation Models (LLMs)
- **Chronos** (Amazon): T5-based zero-shot forecasting
- **TimeGPT** (Nixtla): GPT-Ã¤hnliche Architektur
- **Lag-Llama** (ServiceNow): Llama-basiert
- **Moirai** (Salesforce): Multi-Scale Transformer

**Ergebnis**: Foundation Models zeigen beeindruckende Zero-Shot-FÃ¤higkeiten, aber bei domÃ¤nenspezifischen Problemen mit reichlich Trainingsdaten sind XGBoost/LSTM noch Ã¼berlegen (XGBoost: MAE=249MW vs. Chronos: MAE=4418MW). Hauptvorteil: Rapid Prototyping ohne Training.

## ðŸ“Š Evaluation-Metriken

Alle Modelle werden verglichen anhand von:

- **MAE** (Mean Absolute Error) â†’ PrimÃ¤re Metrik
- **RMSE** (Root Mean Squared Error) â†’ Outlier-SensitivitÃ¤t
- **RÂ² Score** â†’ ErklÃ¤rte Varianz (0-1, hÃ¶her = besser)
- **MAPE** (Mean Absolute Percentage Error) â†’ Relative Fehler
- **Trainingszeit** â†’ Effizienz
- **Inferenzzeit** â†’ Produktionseinsatz

## ðŸ” Wichtige Erkenntnisse

### Feature Engineering ist entscheidend
- **31 Features** entwickelt: Zeit-Features, zyklische Encodings, Lags (1h-7d), Rolling Stats
- 18 fehlende Features fÃ¼hrten zu 15% Performance-Drop (RÂ² 0.83 â†’ 0.98)

### Test-Split-Strategie kritisch
- Naive "letzte 30 Tage" fÃ¼hrte bei Wind Offshore zu RÂ²=0.00 (100% Nullwerte im Test)
- **Smart Test Splits**: Datensatz-spezifische Perioden mit reprÃ¤sentativer Verteilung
- Wind Offshore: Oct 2022 statt Jan 2024 â†’ RÂ² von 0.00 auf 0.996 ðŸš€

### Model Performance
- **XGBoost dominiert**: Gewinnt bei allen 5 DatensÃ¤tzen
- Deep Learning: Vergleichbare Accuracy, aber 10x lÃ¤ngeres Training
- Statistical Models: Gut fÃ¼r Interpretation, schwÃ¤cher bei Multivariaten Daten

### Data Quality Matters
- Wind Offshore hatte 9 Monate Downtime (Mai 2023 - Jan 2024)
- Automatische DatenqualitÃ¤tsprÃ¼fung verhindert falsche Splits

## ðŸ”§ Verwendete Tools & Libraries

### Daten & Preprocessing
- `pandas`, `numpy`, `scipy`
- `sklearn.preprocessing`
- `holidays` (deutsche Feiertage)

### Visualisierung
- `matplotlib`, `seaborn`, `plotly`

### Statistische Modelle
- `statsmodels` (ARIMA, SARIMA)
- `pmdarima` (auto_arima)

### Machine Learning
- `scikit-learn`
- `xgboost`, `lightgbm`, `catboost`

### Deep Learning
- `pytorch`, `tensorflow`
- `darts` (Forecasting-Framework)
- `pytorch-forecasting` (TFT)
- `neuralforecast` (N-BEATS, N-HiTS)

### Optimierung
- `optuna` (Hyperparameter-Tuning)

## ðŸ“š Datenquellen

### PrimÃ¤re Quelle: SMARD
API der Bundesnetzagentur: https://www.smard.de/home

**VerfÃ¼gbare Zeitreihen:**
- âœ… Photovoltaik-Erzeugung
- âœ… Wind Onshore
- âœ… Wind Offshore
- âœ… Stromverbrauch Deutschland
- âœ… Day-Ahead Strompreise
- âœ… Gesamterzeugung
- Und weitere...

**AuflÃ¶sung:** StÃ¼ndlich, tÃ¤glich, wÃ¶chentlich, monatlich

### Alternative Quellen
- [Energy-Charts](https://www.energy-charts.info/?l=de&c=DE) (Fraunhofer ISE)
- [Bundesnetzagentur Datenportal](https://www.bundesnetzagentur.de/DE/Fachthemen/Datenportal/start.html)

### Externe Daten (optional)
- Wetterdaten: [Open-Meteo](https://open-meteo.com/)
- Feiertage: Python `holidays` Library

## ðŸŽ¯ Projektziele & Status

1. âœ… **DatenverstÃ¤ndnis:** Tiefe explorative Analyse der Energiedaten  
2. âœ… **Methodenvergleich:** Systematischer Vergleich von 20+ Modellen  
3. âœ… **Best Practice:** Reproduzierbare, gut dokumentierte Analyse mit 11 Notebooks  
4. âœ… **Praktische Relevanz:** Produktionsreife Modelle fÃ¼r Energiesektor (RÂ² > 0.95)  
5. âœ… **Technische Tiefe:** State-of-the-Art Feature Engineering & Smart Test Splits

**Status: PROJEKT ABGESCHLOSSEN** âœ…

## ðŸ“ Projekt-Verlauf & Lessons Learned

### Phase 1: Datenexploration & Baseline (Notebooks 01-03)
- [x] Projektstruktur erstellt
- [x] SMARD API-Integration (automatisches Caching)
- [x] Explorative Datenanalyse (SeasonalitÃ¤t, Trends, StationaritÃ¤t)
- [x] Preprocessing & Feature Engineering (31 Features)
- [x] Train/Test/Validation Split
- [x] Baseline-Modelle (Naive, Seasonal, MA)

### Phase 2: Klassische ML & Stats (Notebooks 04-05)
- [x] Statistische Modelle (SARIMA, ETS)
- [x] ML Tree Models (XGBoost, LightGBM, CatBoost)
- [x] **Key Finding:** XGBoost bestes Modell fÃ¼r Solar (RÂ² = 0.98)

### Phase 3: Deep Learning (Notebooks 06-08)
- [x] Grundlagen: LSTM, GRU, Bi-LSTM
- [x] Generative Models: VAE, GAN, DeepAR
- [x] Advanced: TFT, N-BEATS, N-HiTS
- [x] **Key Finding:** Vergleichbare Accuracy, aber 10x lÃ¤ngeres Training

### Phase 4: Multi-Series & Optimization (Notebooks 09-11)
- [x] Model Comparison Solar (9 Model-Kategorien)
- [x] Multi-Series Analysis (alle 5 DatensÃ¤tze)
- [x] Hyperparameter Tuning (XGBoost)

### Phase 5: Critical Debugging ðŸ›
**Problem 1:** Solar RÂ² Drop (0.98 â†’ 0.83)  
- **Root Cause:** 18 fehlende Features in Notebook 10  
- **Solution:** create_features() auf 31 Features erweitert  
- **Result:** RÂ² = 0.98 âœ…

**Problem 2:** Wind Offshore Catastrophic Failure (RÂ² = 0.00)  
- **Root Cause:** Test-Split in 9-Monats-Downtime (100% Nullwerte)  
- **Solution:** Smart Test Split Strategy implementiert  
- **Result:** RÂ² = 0.996 ðŸš€  
- **Lesson:** DatenqualitÃ¤t > Algorithmus

### Phase 6: Production Deployment
- [x] Multi-Series Pipeline (run_complete_multi_series.py)
- [x] Alle 5 DatensÃ¤tze mit finalen Features & Smart Splits
- [x] Comprehensive Documentation (3 Markdown Reports, 10 Debug Scripts)
- [x] **Result:** Avg RÂ² = 0.978 across all datasets âœ…

## ðŸ“‚ Key Files & Documentation

### Notebooks (Execution Order)
1. [01_data_exploration.ipynb](notebooks/01_data_exploration.ipynb) - EDA
2. [02_data_preprocessing.ipynb](notebooks/02_data_preprocessing.ipynb) - Feature Engineering  
3. [03_baseline_models.ipynb](notebooks/03_baseline_models.ipynb) - Simple Baselines
4. [04_statistical_models.ipynb](notebooks/04_statistical_models.ipynb) - SARIMA, ETS
5. [05_ml_tree_models.ipynb](notebooks/05_ml_tree_models.ipynb) - XGBoost, LightGBM  
6. [06_deep_learning_models.ipynb](notebooks/06_deep_learning_models.ipynb) - LSTM, GRU
7. [07_generative_models.ipynb](notebooks/07_generative_models.ipynb) - VAE, GAN, DeepAR
8. [08_advanced_models.ipynb](notebooks/08_advanced_models.ipynb) - TFT, N-BEATS  
9. [09_model_comparison.ipynb](notebooks/09_model_comparison.ipynb) - Solar Comparison
10. [10_multi_series_analysis.ipynb](notebooks/10_multi_series_analysis.ipynb) - All 5 Datasets
11. [11_xgboost_tuning.ipynb](notebooks/11_xgboost_tuning.ipynb) - Hyperparameter Optimization

### Reports & Documentation
- [RESULTS_SUMMARY.md](results/metrics/RESULTS_SUMMARY.md) - Zusammenfassung aller Modell-Ergebnisse
- [INTERPRETATION_UND_NEXT_STEPS.md](results/metrics/INTERPRETATION_UND_NEXT_STEPS.md) - Interpretation & Roadmap
- [PROJECT_COMPLETION_REPORT.md](results/metrics/PROJECT_COMPLETION_REPORT.md) - Finale Projekt-Dokumentation mit Debugging-Details
- [SESSION_2_DEBUGGING.md](SESSION_2_DEBUGGING.md) - Detaillierte Debugging-Session
- [multi_series_comparison_UPDATED.csv](results/metrics/multi_series_comparison_UPDATED.csv) - Finale Ergebnisse

### Scripts
- [quickstart.py](quickstart.py) - Schneller Einstieg & Daten-Download
- [run_complete_multi_series.py](run_complete_multi_series.py) - Production Pipeline  
- 10 Debug/Validation Scripts (siehe PROJECT_COMPLETION_REPORT.md)

## ðŸš€ Reproduktion der Ergebnisse

```bash
# 1. Environment Setup
cd energy-timeseries-project
pip install -r requirements.txt

# 2. Data Download
python quickstart.py  # LÃ¤dt alle 5 DatensÃ¤tze von SMARD

# 3a. Run Full Pipeline (empfohlen)
python run_complete_multi_series.py

# 3b. OR: Run Notebooks sequentiell
jupyter notebook
# Notebooks 01-11 der Reihe nach ausfÃ¼hren
```

**Expected Runtime:**  
- Full Pipeline: ~30-45 Minuten  
- Individual Notebooks: 5-10 Minuten each  
- Deep Learning Notebooks: 15-20 Minuten each

## ðŸ’¡ Key Takeaways

1. **Feature Engineering > Model Complexity**  
   31 sorgfÃ¤ltig konstruierte Features schlagen komplexe Deep Learning Modelle

2. **Data Quality is King**  
   Smart Test Splits & Datenvalidierung sind kritisch fÃ¼r valide Ergebnisse

3. **XGBoost ist der praktische Gewinner**  
   Best Performance + Fast Training + Easy Deployment = Production Ready

4. **Deep Learning hat seinen Platz**  
   Wenn Daten >100k und KomplexitÃ¤t hoch â†’ LSTM/TFT kÃ¶nnen lohnen

5. **Documentation Matters**  
   10 Debug-Scripts + 3 Reports ermÃ¶glichen vollstÃ¤ndige Reproduzierbarkeit

## ðŸ“ž Kontakt & WeiterfÃ¼hrendes

**Datenquelle:** [SMARD - Bundesnetzagentur](https://www.smard.de/home)  
**Energy Charts:** [Fraunhofer ISE](https://www.energy-charts.info/?l=de&c=DE)

---

**Projekt-Status:** âœ… PRODUCTION READY  
**Letzte Aktualisierung:** 2026-01-22  
**Durchschnittliche RÂ²-Score:** 0.978
- [ ] Hyperparameter-Tuning
- [ ] Finale Dokumentation & Visualisierung

## ðŸ”— Referenzen

### Kursmaterial
- [TimeSeriesPrediction Repository](../TimeSeriesPrediction)
- Week02: SARIMA, Week04: Trees, Week05: LSTM
- Week08: VAEs, GANs, DeepAR âœ…
- Week09: Transformers, Week10: N-BEATS

### Erfolgreiche Projekte
- [Energy Timeseries Project](https://github.com/Timson1235/energy-timeseries-project) (VDE Prize Winner)
- [Solar Prediction](https://github.com/AnnaValentinaHirsch/solar-prediction)
- [German Energy Analysis](https://github.com/worldmansist/German-energy-Time-Series-analysis-)



## ðŸ“„ Lizenz

Dieses Projekt ist fÃ¼r Bildungszwecke erstellt.

---

**Status:** âœ… Alle 9 Notebooks erstellt - Bereit zum AusfÃ¼hren!  
**Letzte Aktualisierung:** 2026-01-21
