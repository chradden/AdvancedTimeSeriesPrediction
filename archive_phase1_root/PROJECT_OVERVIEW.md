# Advanced Time Series Prediction - ProjektÃ¼bersicht

**Stand:** Januar 2026  
**Status:** Produktionsreif mit erweiterten Pipelines

## ğŸ“Š Projektbeschreibung

Umfassendes Machine-Learning-Projekt zur Vorhersage von Energiezeitreihen (Solar, Wind Offshore, Wind Onshore, Consumption, Price) mit mehreren Modellkategorien und produktionsreifer API.

## ğŸ¯ Aktuelle Strategie

### 1. **Automatisierte Pipelines** (Empfohlen fÃ¼r schnelle DurchlÃ¤ufe)
Alle Datenquellen haben jetzt standardisierte Extended Pipelines mit 9 Phasen:

**VerfÃ¼gbare Skripte:**
- `scripts/run_solar_extended_pipeline.py`
- `scripts/run_wind_offshore_extended_pipeline.py`
- `scripts/run_wind_onshore_extended_pipeline.py`
- `scripts/run_consumption_extended_pipeline.py`
- `scripts/run_price_extended_pipeline.py`

**9 Phasen pro Pipeline:**
1. Data Exploration
2. Preprocessing & Feature Engineering
3. Baseline Models (Naive, Seasonal Naive, Moving Average, Drift, Mean)
4. Statistical Models (ARIMA, SARIMA, ETS)
5. ML Tree Models (Random Forest, XGBoost, LightGBM, CatBoost)
6. Deep Learning (RNN, LSTM, GRU)
7. Generative Models (Overview, in Notebooks detailliert)
8. Advanced Models (N-BEATS, N-HiTS)
9. Final Comparison & Visualizations

**Vorteile:**
- âœ… Reproduzierbar
- âœ… Schneller als Notebooks
- âœ… Automatische Metrics & Plots
- âœ… CSV-Export fÃ¼r alle Modelle

### 2. **Jupyter Notebooks** (FÃ¼r detaillierte Analysen)
FÃ¼r jede Datenquelle gibt es 9 thematische Notebooks:

**Struktur (am Beispiel Solar):**
```
notebooks/solar/
â”œâ”€â”€ 01_data_exploration.ipynb
â”œâ”€â”€ 02_data_preprocessing.ipynb
â”œâ”€â”€ 03_baseline_models.ipynb
â”œâ”€â”€ 04_statistical_models.ipynb
â”œâ”€â”€ 05_ml_tree_models.ipynb
â”œâ”€â”€ 06_deep_learning_models.ipynb
â”œâ”€â”€ 07_generative_models.ipynb
â”œâ”€â”€ 08_advanced_models.ipynb
â””â”€â”€ 09_model_comparison.ipynb
```

**Weitere Serien:**
- `notebooks/wind_offshore/` (5 Notebooks)
- `notebooks/wind_onshore/` (9 Notebooks)
- `notebooks/price/` (9 Notebooks)

### 3. **Production API**
FastAPI-basierte REST-API fÃ¼r 24h-Forecasts:

**Dateien:**
- `api.py` - Haupt-API (empfohlen)
- `api_simple.py` - Vereinfachte Version
- `api_client_example.py` - Client-Beispiele

**Endpoints:**
- `POST /predict/solar` - 24h Solar-Forecast
- `POST /predict/wind_offshore` - 24h Wind-Forecast
- `POST /predict/consumption` - 24h Verbrauchs-Forecast
- `GET /health` - Health Check

**Start:**
```bash
uvicorn api:app --host 0.0.0.0 --port 8000
```

### 4. **Monitoring & Dashboards**
- Prometheus + Grafana Setup
- Echtzeit-Metriken
- Visualisierung von Predictions vs. Actuals

## ğŸ“ Projektstruktur

```
energy-timeseries-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original SMARD-Daten
â”‚   â””â”€â”€ processed/              # Aufbereitete Train/Val/Test-Splits
â”œâ”€â”€ scripts/                    # Automatisierte Pipelines
â”‚   â”œâ”€â”€ run_*_extended_pipeline.py
â”‚   â”œâ”€â”€ run_*_advanced_testing.py
â”‚   â””â”€â”€ test_*.py
â”œâ”€â”€ notebooks/                  # Jupyter-Notebooks pro Serie
â”‚   â”œâ”€â”€ solar/
â”‚   â”œâ”€â”€ wind_offshore/
â”‚   â”œâ”€â”€ wind_onshore/
â”‚   â””â”€â”€ price/
â”œâ”€â”€ src/                        # Source-Code-Module
â”‚   â”œâ”€â”€ data/                   # Datenlade- & Preprocessing-Tools
â”‚   â”œâ”€â”€ models/                 # Modellimplementierungen
â”‚   â”œâ”€â”€ evaluation/             # Metriken & Evaluation
â”‚   â””â”€â”€ visualization/          # Plot-Funktionen
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # Generierte Plots
â”‚   â””â”€â”€ metrics/                # CSV/JSON-Ergebnisse
â”œâ”€â”€ archive/                    # Archivierte alte Entwicklungen
â”‚   â”œâ”€â”€ old_scripts/            # Debug-/Analyse-Skripte
â”‚   â”œâ”€â”€ old_docs/               # Session-Logs
â”‚   â””â”€â”€ old_root_files/         # Veraltete Root-Skripte
â”œâ”€â”€ monitoring/                 # Prometheus/Grafana-Configs
â”œâ”€â”€ docs/                       # Aktuelle Dokumentation
â”œâ”€â”€ api.py                      # Production API
â””â”€â”€ requirements.txt
```

## ğŸš€ Quick Start

### Option 1: Automatisierte Pipeline ausfÃ¼hren
```bash
cd energy-timeseries-project
python scripts/run_solar_extended_pipeline.py
```

Ergebnisse:
- `results/metrics/solar_all_models_extended.csv`
- `results/figures/solar_extended_09_comparison.png`

### Option 2: Notebooks interaktiv
```bash
jupyter lab
# Ã–ffne notebooks/solar/01_data_exploration.ipynb
```

### Option 3: API starten
```bash
cd energy-timeseries-project
uvicorn api:app --reload
# Ã–ffne http://localhost:8000/docs
```

## ğŸ“ˆ Ergebnisse & Performance

**Best Models (Stand: Januar 2026):**
- **Solar:** LightGBM (RÂ² â‰ˆ 0.98, RMSE â‰ˆ 1000 MW)
- **Wind Offshore:** LightGBM (RÂ² â‰ˆ 0.85)
- **Wind Onshore:** XGBoost/LightGBM (RÂ² â‰ˆ 0.92)
- **Price:** LightGBM (RÂ² â‰ˆ 0.98, RMSE â‰ˆ 9 EUR/MWh)

Details: `results/metrics/*_all_models_extended.csv`

## ğŸ› ï¸ Technologie-Stack

**Core Libraries:**
- pandas, numpy, scipy
- scikit-learn (1.7+)
- xgboost, lightgbm, catboost
- statsmodels, pmdarima
- torch, tensorflow/keras
- darts (N-BEATS, N-HiTS)
- FastAPI, uvicorn

**Visualisierung:**
- matplotlib, seaborn, plotly
- Grafana + Prometheus

## ğŸ“š Wichtige Dokumentation

**Hauptdokumente:**
- `README.md` - Projekt-README
- `QUICKSTART.md` - Schnelleinstieg
- `MASTERPLAN.md` - Gesamtstrategie
- `STRUCTURE.md` - Detaillierte Struktur

**In `docs/`:**
- `FINAL_PROJECT_SUMMARY.md` - Finaler Projektbericht
- `PROJECT_COMPLETION_REPORT.md` - Abschlussbericht
- `GRAFANA_DASHBOARD_GUIDE_DE.md` - Dashboard-Anleitung
- `MONITORING_SETUP.md` - Monitoring-Setup
- `REALTIME_MONITORING_GUIDE.md` - Echtzeit-Monitoring

**In `notebooks/`:**
- `README.md` - Notebook-Ãœbersicht
- `WO_SIND_DIE_ERGEBNISSE.md` - Wo finde ich Ergebnisse?
- `RESULTS_VIEWER.ipynb` - Interaktiver Ergebnis-Viewer

## ğŸ—‚ï¸ Archivierte Entwicklungen

Alte Debug-/Analyse-Skripte und Session-Logs befinden sich in:
- `energy-timeseries-project/archive/`
- `archive_root/` (Root-Level)

Diese sind fÃ¼r die produktive Nutzung nicht mehr relevant, wurden aber fÃ¼r die Historie bewahrt.

## ğŸ“ Akademischer Hintergrund

Dieses Projekt kombiniert modernste Zeitreihen-Methoden:
- Classical Statistics (ARIMA, ETS)
- Tree Boosting (XGBoost, LightGBM, CatBoost)
- Deep Learning (LSTM, GRU)
- Neural Architectures (N-BEATS, N-HiTS)
- Foundation Models (Chronos - experimentell)

## ğŸ“ NÃ¤chste Schritte

1. **FÃ¼r neue Analysen:** Nutze `scripts/run_*_extended_pipeline.py`
2. **FÃ¼r Experimente:** Kopiere & modifiziere Notebooks
3. **FÃ¼r Production:** Nutze `api.py` mit Docker/Docker-Compose
4. **FÃ¼r Monitoring:** Starte Grafana-Stack mit `start_monitoring.sh`

---

**Letzte Aktualisierung:** 31. Januar 2026
